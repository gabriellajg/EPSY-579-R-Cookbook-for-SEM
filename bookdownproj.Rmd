--- 
title: "R Cookbook for Structural Equation Modeling"
author: "Ge Jiang"
date: "QUERIES, University of Illinois at Urbana-Champaign"
site: bookdown::bookdown_site
---

# Course

Structural Equation Modeling (SEM) is a general class of multivariate techniques that models relationships between latent variables and observed variables (“measurement models”) and relationships among latent variables (“structural models”) simultaneously. Students will learn the theoretical background of SEM as well as the techniques using programming language R. Topics covered in this class include mediation/moderation model; confirmatory factor analysis; model fit evaluation; multi-group SEM; latent growth modeling; MTMM model; and SEM with categorical variables. 4 graduate hours. No professional credit. Prerequisite: EPSY 580 and EPSY 581, or equivalents.

This site is supposed to serve as a repository for R codes used in lab sessions of a graduate-level method course in Spring 2022. 

*Disclaimer: Opinions are my own and not the views of my employer.

<!--chapter:end:index.Rmd-->

# Into to R

In this lab, we will learn the basic operations of R. 

Let's first meet the commenter in R: 

\#\: I am a comment, indicated by a number sign (also called a pound sign, or, a hashtag).

<!------------------------------>
## R as a calculator
<!------------------------------>

In many ways, R is just a fancy calculator: 

```{r}
2 + 3
```

* To run this command ON A MAC, highlight it and press COMMAND+ENTER.

* ON A PC, press CTRL+R.

1. If you 'run' the comments, it will automatically run the next executable line 
2. comments after the command will show in the console as well

* In R, you can perform:

```{r, results='hide'}
2 + 1 #addition
7 - 3 #subtraction
2 * 4 #multiplication
8 / 2 #division
```

You can also work with exponents:

```{r, results='hide'}
4^2 #4 to the 2nd power
4**2 #same thing
```

Square Root:

```{r, results='hide'}
sqrt(16)
```

And perform a variety of other operations.

Here's a helpful table:

```{r, eval=FALSE}
Arithmetic Operators

#===========#==================#===========#
# Operator  #   Meaning        # Example   #
#===========#==================#===========#
#    +      #   Addition       # 2 + 2     #
#-----------#------------------#-----------#
#    -      #   Subtraction    # 5 - 3     #
#-----------#------------------#-----------#
#    *      # Multiplication   # 3 * 4     #
#-----------#------------------#-----------#
#    /      #   Division       # 12 / 3    #
#-----------#------------------#-----------#
#  ^ or **  #    Power         # 3^3; 2**4 #
#-----------#------------------#-----------#
#  sqrt()   #   square root    # sqrt(16)  #
#-----------#------------------#-----------#
#  abs()    # absolute value   # abs(-5)   #
#-----------#------------------#-----------#
```
Like any calculator, order of operations counts in R:

```{r, results='hide'}
3*6+5/4
(3*6)+(5/4) #same

3*(6+5)/4   #different
3*((6+5)/4) #same as above
```

* Remember PEMDAS?
* (Parentheses, Exponents, Multiplication, Division, Addition, Subtraction)
* Given two or more operations in a single expression, PEMDAS tells you the order of the calculation. 

<!------------------------------>
## Formal Rules for Indexing Objects in R
<!------------------------------>

* There are many clever ways to index and retrieve subsets of objects in R, as we shall see, but all of them boil down to 3 formal rules.

1. By supplying a vector of integers indicating the number(s) of the elements/rows/columns to be subsetted.
a. A vector of POSITIVE INTEGERS indicates the elements to be selected.

* Vectors can be indexed:

```{r,results='hide'}
stringvec <- c("Chen", "Julia", "Lee", "Mike", "Winston", "Coach")
stringvec[c(1,2,3)]
```

b. A vector of NEGATIVE INTEGERS indicates the elements NOT to be selected (to be removed).

```{r,results='hide'}
stringvec[c(-1,-2,-3)]
```

2. By supplying a character vector indicating the names() of the elements/rows/columns to be selected.
* (row/colnames for table objects).

3. By supplying a logical vector of TRUE and FALSE (T and F) of the same length as the vector or dimension to be subsetted. 

In this case, elements flagged as TRUE will be selected and those flagged as FALSE will be omitted.

COROLLARY: A vector may be indexed in any of these three ways 
OR BY SUPPLYING AS AN INDEX ANY OBJECT OR OPERATION THAT RETURNS ONE OF THESE THREE THINGS.

Let us demonstrate each of these things in turn:

<!------------------------------>
## Examples
<!------------------------------>

1a. Positive integers indicating element numbers.

```{r,results='hide'}
stringvec[c(1,3,5)] #Returns 1st, 3rd, and 5th elements
```

1b. Negative integers indicating element numbers to be omitted:

```{r,results='hide'}
stringvec[-c(2,4,6)]
```

* Note that this is because

```{r,results='hide'}
-c(2,4,6)
```

* Negates all three numbers.

* Also note that:

```{r,results='hide',eval=FALSE}
stringvec[c(1,-2,3)]
```

* Returns an error.
* this is because selecting certain (positive) numbers already implies omitting others, so the negative integer is confusing and redundant.

2. Character vector corresponding to element names.

* Let's give our object some names:

```{r,results='hide'}
names(stringvec) <- paste("Friend", 1:length(stringvec), sep="")
stringvec

stringvec["Friend1"]
stringvec[c("Friend3","Friend5")]
stringvec[paste("Friend", c(1, 2, 5), sep="")]
```

3.	Logical Vector:

* Let's say we want to select "Chen", "Lee", "Winston", and "Coach".

```{r,results='hide'}
stringvec[c(T, F, T, F, T, T)]
```

* Now let's create a vector that stores each character's gender:

```{r,results='hide'}
gender <- factor(c(1, 2, 1, 2, 1, 1), levels = c(1,2), labels = c("Male", "Female"))
```

* Now we can select "Chen", "Lee", "Winston", and "Coach" by simply entering:

```{r,results='hide'}
stringvec[gender == "Male"]
```

* Or we could select Julia and Mike using:

```{r,results='hide'}
stringvec[gender == "Female"]
```

* We could get even more creative ...

```{r,results='hide'}
stringvec[(gender == "Female" | stringvec == "Chen")]
```

* Why do all of these things work and actually return sensible results?
* It's because they all return logical vectors of the appropriate length, with
#TRUE values in the slots we want.
* We can demonstrate this by running these commands outside of the braces:

```{r,results='hide'}
gender == "Male"
gender == "Female"
```

* Even though this is a completely separate variable, these commands return logical vectors of the appropriate length,
* with TRUE and FALSE values in the appropriate places.

```{r,results='hide'}
(gender == "Female" | stringvec == "Chen")
```

* Here again, same thing.

* Although different types of objects we will discuss have different numbers of dimensions and different formats,
*  if you remember these THREE WAYS TO SUBSET AN OBJECT (integers = element index, characters = element name, logical = flag element as TRUE), you will be a master at subsetting any object in R.

<!--chapter:end:02-exercise.Rmd-->

# Lavaan Lab 1 Path Analysis Model

```{r set-options, echo=FALSE, cache=FALSE, message=FALSE}
library(knitr)
options(width = 1800)
opts_chunk$set(cache=TRUE)
```

In this lab, we will learn how to: 

+ install a package called lavaan in R
+ perform path analysis using the lavaan package

## Reading-In and Working With Realistic Datasets In R

#### To begin, we will read the file that we will use for our SEM lab (eatingDisorderSimData.csv).

Try running this function, as written:

```{r, eval = FALSE}
file.choose()
```

Using the GUI (graphical user interface) window that pops up,
select the file eatingDisorderSimData.csv

This should produce a file path like this (note: below is a Mac version):

```{r, eval = FALSE}
/Your/File/Path/eatingDisorderSimData.csv
```

You can copy this path into the read.csv and put it in the file = argument of the function: 

+ read.csv() is a function for reading in .csv files.
+ Assign the name labData to the dataset in R using <-

```{r, eval = FALSE}
labData <- read.csv(file = "/Users/gejiang/Box Sync/MacSync/Teaching/590SEM/Spring 2022/Week 4/R/eatingDisorderSimData.csv", header = TRUE)
```

Important Argument:
header =

+ if header = TRUE, indicates that your dataset has column names that are to be read in separate from the data.
+ if header = FALSE, indicates that your dataset does NOT have column names, and therefore the first row of the dataset should be read as data.

#### Or you could NEST the file.choose() function inside the read.csv function

```{r, eval = FALSE}
labData <- read.csv(file = file.choose(), header = T)
```

Because file.choose() returns the file path, putting this inside the read.csv function is the same as writing the path inside the function!

#### Pros and Cons of writing the full file path vs. using read.csv(file = file.choose(), header = T)

If you write down the full file path and put it in the function, then the next time you run this R script you can easily read in your data without searching through your directories and folders.

However, if you move your file to a different folder in the future, you'll need to change the directory path in your R script.

file.choose() is very easy and user-friendly.

Using this method allows you to find your datafile even if you've moved it to a different folder.

However, it is slightly more effortful to go in and select your folder each time.

#### Gabriella recommends:

Set your working directory to the directory that contains the dataset, and simply load your data by typing the name of the .csv file: 

```{r, eval = T}
setwd("~/Box Sync/MacSync/Teaching/590SEM/Spring 2022/Week 4/R")

labData <- read.csv(file = "eatingDisorderSimData.csv", header = T, sep = ",")
```

This serves to save all your future analyses in your working directory. 

read.csv() is related to a broader function called read.table.

The read.table function has a sep = argument
sep = 

+ If sep = "," this indicates a comma-separated (.csv) file
+ If sep = " " this indicates a tab-delimited ("white space" delimited) file, such as a .txt

#### Finally, point and click always works...

```{r, eval = FALSE}
library(readr)
eatingDisorderSimData <- read_csv("eatingDisorderSimData.csv")
View(eatingDisorderSimData)
```


<!------------------------------>
## Sample Covariance Matrices using the cov() function 
<!------------------------------>

#### Quick review:

```{r, eval = T}
str(labData) #structure
head(labData) #first few lines
colnames(labData) #column names
```

+ How many observations are in this dataset?
+ Number of observations = number of rows, with 1 person per row 

```{r, eval = T}
nrow(labData) #1339
```

let's save this number as n
```{r, eval = T}
n <- nrow(labData)
```

Let's look at the sample covariance matrix of these variables using the cov() function:

```{r, eval = T}
cov(labData)
```

let's save this sample cov as capital S:
```{r, eval = T}
S = cov(labData)
```

If we wanted, we could look at a subset of the dataset, e.g.,:

```{r, eval = T}
cov(labData[,c("BMI", "SelfEsteem", "Accu")])
```

This is often useful if our analysis will only contain certain variables.

If only two variables:

```{r, eval = T}
cov(labData$BMI, labData$SelfEsteem)
```

If only one variable (variance):

```{r, eval = T}
cov(labData$BMI, labData$BMI)
```

<!------------------------------>
## Installing Packages 
<!------------------------------>

We will mostly be using the lavaan package to perform SEM analyses, so let's use the install.packages() function to install it first

```{r, eval = F}
install.packages("lavaan")
```

lavaan stands for LAtent VAriable ANalysis using R.

lavaan website: http://lavaan.ugent.be

Check out the tutorials and examples!

<!------------------------------>
## Loading Packages (Libraries) That You Have Installed 
<!------------------------------>

AFTER YOU'VE INSTALLED A PACKAGE ONE TIME, YOU DON'T HAVE TO EVER INSTALL IT AGAIN, UNLESS YOU DELETE AND REINSTALL R FOR SOME REASON.

HOWEVER, NOW THAT THESE FUNCTIONS ARE INSTALLED IN R ON YOUR MACHINE, YOU MUST LOAD THE LIBRARY EVERY TIME YOU OPEN R AND WISH TO USE IT.

To do this, use the library() function:

```{r, eval = T}
library(lavaan)
```

This is lavaan 0.6-9
lavaan is FREE software! Please report any bugs.

Don't worry about the "BETA" warning, this package is awesome! 

This may seem like a pain, but roll with it. The good news is that once you do it, you have access to a whole library of SEM functions.

If you boot up R and receive error msgs like "could not find function "sem""
IT IS PROBABLY BECAUSE YOU HAVEN'T LOADED THE lavaan PACKAGE. 

Check out the help page of a particular function, say sem():

```{r, eval = T}
help(sem)
?sem
```

<!------------------------------>
## Using Lavaan For Path Models
<!------------------------------>

Every analysis in lavaan has three main parts.

+ Part I: Writing the Model Syntax
+ Part II: Analyzing the Model Using Your Dataset
+ Part III: Examining the results.

### PART I: Follow the set of equations we wrote in class:

Self-Efficacy = BMI + Self-Esteem + Disturbance

Bulimic Symptoms = BMI + Self-Esteem + Self-Efficacy + Disturbance

Restrictive Symptoms = BMI + Self-Esteem + Self-Efficacy + Disturbance

Overall Risk = BMI + Self-Esteem + Self-Efficacy + Acculturation + Disturbance

Let's write some model syntax:

```{r, eval = T}
ex1PathSyntax <- " 			 #opening a quote
  # Tilda ~ : Regression 
  # M ~ X regression (X predicts M)
  # Each line corresponds to an equation 
  # Disturbance is automatically included for each regression 
  # (i.e. no extra term needed)
  
  DietSE ~ BMI + SelfEsteem      #DietSE is predicted by BMI and SelfEsteem 
	Bulimia ~ DietSE + BMI + SelfEsteem
	Restrictive ~ DietSE + BMI + SelfEsteem
	Risk ~ DietSE + BMI + SelfEsteem + Accu
"  
```


Things to note here:

+ We are calling our saved model syntax object ex1PathSyntax
+ We assign it using <- as usual
+ Then we open a quotation "
+ Then we write each part of the model on separate lines.
+ Then we close the quotation "
+ The variables names need to match those in the dataset (case matters!)
+ Add comments inside the model syntax using hashtag


### PART II Let's run our model!

To run this model, we will start by using the sem() function.

Sensible defaults for estimating CFA models like assumptions of linear regression, so we don’t actually have to write some constraints into the model above

Alternatively, one can use lavaan() function [with the fewest default settings] or cfa() function [with similar defaults as sem() function]

To use lavaan(), you have to specify all 22 parameters in the model. 

#### ex1fit

You can run the sem() function using two different sources of data:

1. The raw dataset, using:

```{r, eval = F}
lavaan::sem(model = modelSyntax, data = yourDataset)
```

example:

```{r, eval = F}
ex1fit <- lavaan::sem(model = ex1PathSyntax, data = labData)
```

If you encounter errors like: 

Error in if ((!is.matrix(model)) | ncol(model) != 3) stop("model argument must be a 3-column matrix") : 
  argument is of length zero

IT IS PROBABLY BECAUSE YOU HAVEN'T LOADED THE lavaan PACKAGE. 

To make sure you are using the sem() function from the lavaan package, add PackageName:: before a function: 

```{r, eval = T}
ex1fit <- lavaan::sem(model = ex1PathSyntax, data = labData)
```

Then we can obtain complete results using the summary() function:

```{r}
summary(ex1fit)
```

2. The covariance matrix, using:

```{r, eval = F}
lavaan::sem(model = modelSyntax, sample.cov = yourCovarianceMatrix, sample.nobs = numberOfObservationsInYourDataset)
```

This is to illustrate that WITH COMPLETE DATA, you can run SEM analyses using only covariances as input and obtain the same results as with raw data! 

This positions SEM for meta-analysis and replication studies. 

example:

```{r}
ex1fit_S <- lavaan::sem(model = ex1PathSyntax, sample.cov = S, sample.nobs = n)
summary(ex1fit_S)
```

The . before a variable name refers to its disturbance.

e.g., .Bulimia refers to the disturbance of Bulimia, not Bulimia itself

You should get exactly the same output in ex1fit and ex1fit_S. 

Wait, Gabriella, the df is not 6....

This is because sem() by default assumes that disturbances of endogenous variables covary among themselves (which, in our model, are not correlated at all!)

The estimates of disturbance covariances are presented under "Covariances" in the output:

```{r, eval=FALSE}
Covariances:
                   Estimate  Std.Err  z-value  P(>|z|)
.Bulimia ~~                                          
  .Restrictive       0.536    0.029   18.389    0.000
  .Risk              0.814    0.034   23.983    0.000
.Restrictive ~~                                      
  .Risk              0.785    0.034   22.996    0.000
```


#### ex1PathSyntax_noCov

To change those defaults, one needs to explicitly fix those disturbance covariances at 0 (this is a strong assumption, I know...): 

http://lavaan.ugent.be/tutorial/syntax2.html

```{r}
ex1PathSyntax_noCov <- " 			 #opening a quote
  # ~~ indicates a two-headed arrow (variance or covariance)
  # 0* in front of the 2nd variable fixes the covariance at 0
  
  DietSE ~ BMI + SelfEsteem      #DietSE is predicted by BMI and SelfEsteem 
	Bulimia ~ DietSE + BMI + SelfEsteem
	Restrictive ~ DietSE + BMI + SelfEsteem
	Risk ~ DietSE + BMI + SelfEsteem + Accu

	#Disturbance covariances (fixed at 0):
	DietSE ~~ 0*Bulimia  
	DietSE ~~ 0*Restrictive  
	DietSE ~~ 0*Risk     
	Bulimia ~~ 0*Restrictive
	Bulimia ~~ 0*Risk
	Restrictive ~~ 0*Risk
	
	# These lines above say that there is no covariance among the disturbances of all endogenous variables
"  

ex1fit_noCov <- lavaan::sem(model = ex1PathSyntax_noCov, data = labData)
summary(ex1fit_noCov)
```

```{r, eval=FALSE}
df = 6 and 

Covariances:
                  Estimate  Std.Err  z-value  P(>|z|)
.DietSE ~~                                           
  .Bulimia           0.000                           
  .Restrictive       0.000                           
  .Risk              0.000                           
.Bulimia ~~                                          
  .Restrictive       0.000                           
  .Risk              0.000                           
.Restrictive ~~                                      
  .Risk              0.000                           
```

Wait, where are the variances and covariances of exogenous variables?

They are not included in the output because they are estimated PERFECTLY

#### ex1fit_noCov_freeX

fixed.x=FALSE asks for the variances/covariances/means of the exogenous variables to be freely estimated instead of being fixed at the values found from the sample

This usually makes no difference from ex1fit_noCov, except that it prints more lines

```{r}
ex1fit_noCov_freeX <- lavaan::sem(model = ex1PathSyntax_noCov, data = labData, fixed.x = FALSE)
summary(ex1fit_noCov_freeX)
```

#### ex1fit_noCov_lavaan

As a bonus, here is how you would write the model syntax if you use lavaan() instead of sem()...

```{r}
ex1PathSyntax_lavaan <- " 			 #opening a quote
  # ~~ indicates a two-headed arrow (variance or covariance)

  #regression coefficients (12)
  DietSE ~ BMI + SelfEsteem      
	Bulimia ~ DietSE + BMI + SelfEsteem
	Restrictive ~ DietSE + BMI + SelfEsteem
	Risk ~ DietSE + BMI + SelfEsteem + Accu
	
	#variances of exogenous variables (3)
	BMI ~~ BMI
	SelfEsteem ~~ SelfEsteem
	Accu ~~ Accu

  #disturbance variances (4)
	DietSE ~~ DietSE
	Bulimia ~~ Bulimia
	Restrictive ~~ Restrictive
	Risk ~~ Risk

	#covariances among exogenous variables (3)
	BMI ~~ SelfEsteem
	BMI ~~ Accu
	SelfEsteem ~~ Accu

  #total: 22 parameters
"  
ex1fit_noCov_lavaan <- lavaan(model = ex1PathSyntax_lavaan, data = labData)
summary(ex1fit_noCov_lavaan)
```

which yields the same output as ex1fit_noCov_freeX. 

### Sigma Matrices

Let's have a look at the model-implied covarinace matrix from our final model ex1fit_noCov_freeX and save it as Sigma: 

```{r}
fitted(ex1fit_noCov_freeX)
Sigma <- fitted(ex1fit_noCov_freeX)$cov
```

How close is Sigma to S? 

+ Rearrange the rows and columns of Sigma (important!) and take the difference

```{r}
diff = Sigma[colnames(S), colnames(S)] - S
round(diff, 3)
```

How about the default model that include disturbance covariances?

```{r}
Sigma0 <- fitted(ex1fit)$cov
diff0 = Sigma0[colnames(S), colnames(S)] - S
round(diff0, 3)
```

#### Gabriella's Practical Tips:

+ To begin with, constraint the disturbance covariances to be 0 ; 
+ Keep the model if the model fits the data well;
+ Relax the constraints the disturbance covariances if the initial model did not fit well. 

### PART III: Summarizing Our Analysis:

There are some useful options we can ask for with summary():

```{r, eval = FALSE}
summary(ex1fit_noCov_freeX, fit.measures = T) #include model fit measures
summary(ex1fit_noCov_freeX, standardized = T) #This includes standardized estimates. std.all contains usual regression standardization.
summary(ex1fit_noCov_freeX, ci = T)  #Include confidence intervals

# Add them all!
```

If we JUST want the parameter estimates:
```{r}
parameterEstimates(ex1fit_noCov_freeX)
parameterEstimates(ex1fit_noCov_freeX, standardized = T) #include standardized solution....
```

For standardized solutions, there is also this function:
```{r}
standardizedSolution(ex1fit_noCov_freeX, type = "std.all") 
```

How does it work?
```{r}
?standardizedSolution
```


<!------------------------------>
## Plotting SEM model
<!------------------------------>

```{r}
# install.packages("semPlot")
library(semPlot)

# Plot!
semPaths(ex1fit_noCov_freeX)
```

```{r}
# estimates instead of paths only
semPaths(ex1fit_noCov_freeX, what='est', 
         edge.label.cex=1.25, curvePivot = TRUE, 
         fade=FALSE)
```

```{r}
# standardized solutions
semPaths(ex1fit_noCov_freeX, what='std', 
         edge.label.cex=1.25, curvePivot = TRUE, 
         fade=FALSE)
```


```{r}
semPaths(ex1fit_noCov_freeX, what='est', 
         rotation = 2, # default rotation = 1 with four options
         edge.label.cex=1.25, curvePivot = TRUE, 
         fade=FALSE)
```

### customize it your way

```{r}
semPaths(ex1fit_noCov_freeX, whatLabels="est", # plot model not parm ests
         rotation = 2, # default rotation = 1 with four options
         asize = 5, # arrows' size
         esize = 2, # width of paths' lines / curves
         edge.label.cex = 0.8, # font size of regr'n coeffs
         sizeMan = 10, # font size of manifest variable names
         nCharNodes = 0,
         nCharEdges = 0, # don't limit variable name lengths
         fade = FALSE, # don't weight path width to reflect strength
         curvePivot = TRUE, # make straight edges instead of round ones
         curve = 2, # pull covariances' curves out a little
         style = "lisrel", # no variances vs. # "ram"'s 2-headed for variances
         color = "green", # color of variables
         edge.color = "black", # color of edges/paths
         layout = "tree2", # tree, spring, circle, circle2
         residuals = TRUE) # residuals variances included in the path diagram
```

```{r}
semPaths(ex1fit_noCov_freeX, what='est', 
         rotation = 2, # default rotation = 1 with four options
         curve = 2, # pull covariances' curves out a little
         nCharNodes = 0,
         nCharEdges = 0, # don't limit variable name lengths
         sizeMan = 8, # font size of manifest variable names
         style = "lisrel", # single-headed arrows vs. # "ram"'s 2-headed for variances
         edge.label.cex=1.2, curvePivot = TRUE, 
         fade=FALSE)
```

<!------------------------------>
## Exercise: How would you fit the model in Saunders et al. (2016)?
<!------------------------------>


<!--chapter:end:03-path.Rmd-->

# Lavaan Lab 2 Mediation and Indirect Effects

In this lab, we will learn how to: 

+ perform a simple mediation analysis using Preacher & Hayes (2004) + Bootstrap
+ test mediation effects in the eating disorder path model 

<!------------------------------>
## Reading-In and Working With Realistic Datasets In R
<!------------------------------>

If your data (eatingDisorderSimData.csv) is stored in you current working directory, then simply load your data by typing the name of the .csv file:

```{r, eval = T}
labData <- read.csv(file = "eatingDisorderSimData.csv", header = T, sep = ",")
```

<!------------------------------>
## Using Lavaan For Mediation Models - Preacher & Hayes’s 
<!------------------------------>

Load the package: 

```{r, eval = T}
library(lavaan)
```

+ Part I: Writing the Model Syntax
+ Part II: Analyzing the Model Using Your Dataset
+ Part III: Examining the results.

## PART I: # Follow the two equations of M (DietSE) & Y (Bulimia)

Diet Self-Efficacy = BMI + Disturbance

Bulimic Symptoms = BMI + Diet Self-Efficacy + Disturbance

Let's write some model syntax:

```{r, eval = T}
ex1MediationSyntax <- " 			 #opening a quote
	#Regressions
	DietSE ~ BMI                    #M ~ X regression (a path)
	Bulimia ~ BMI + DietSE          #Y ~ X + M regression (c prime and b)
	"  
```

No need to fix disturbance covariances in simple mediation as none was estimated

## PART II Let's run our model!

let fixed.x=FALSE to print more lines

```{r, eval = T}
ex1fit_freeX <- lavaan::sem(model = ex1MediationSyntax, data = labData, fixed.x = FALSE)
summary(ex1fit_freeX)
```

note that there are six parameter estimates and df = 0. 

But the output does not include the mediation effect a*b?

### Label the mediation effect

Let's learn how to label parameters

great tutorial example: http://lavaan.ugent.be/tutorial/mediation.html

To label a parameter, include the coefficient label and an asterisk * before the variable to be labelled.

E.g., y ~ b1*x + b2*m

This would give x the label b1 and m the label b2 in the y regression.

```{r, eval = T}
ex2MediationSyntax <- " 			 			#opening a quote
	#Regressions
	DietSE ~ a*BMI                  	#Label the a coefficient in the M regression.
	Bulimia ~ cPrime*BMI + b*DietSE   #Label the direct effect (cPrime) of X and direct effect of M (b) in the Y regression.
	" 
```

What does this do?

```{r}
ex2fit <- lavaan::sem(model = ex2MediationSyntax, data = labData, fixed.x=FALSE)
summary(ex2fit)
```

The regression coefficients have labels now!

### Define a new term for the mediation effect a*b 

...using the labels we just created in ex2MediationSyntax

The := operator in lavaan defines new terms to be tested:

(name of a new term) := operator

```{r}
ex3MediationSyntax <- " 			 			#opening a quote
	#Regressions
	DietSE ~ a*BMI                  	#Label the a coefficient in the M regression.
	Bulimia ~ cPrime*BMI + b*DietSE   #Label the direct effect (cPrime) of X and direct effect of M (b) in the Y regression.
	
	#Define New Parameters
	ab := a*b 									#the product term is computed as a*b
	c := cPrime + ab 						#having defined ab, we can use this here.
" 
```

```{r}
ex3fit <- lavaan::sem(model = ex3MediationSyntax, data = labData, fixed.x=FALSE)
summary(ex3fit)
```

Now there are two significance tests of the indirect effect ab and the total effect c! 

Question: why didn't the #parameters change? 

Note: *defining* a new term is NOT equivalent to *adding* a new parameter!

You can create as many terms as your want without changing the #parameters and the df


## PART III: Summarizing Our Analysis:

We can request standardized coefficients very easily by adding a statement to the summary command.

```{r}
summary(ex3fit, standardized = TRUE) #This includes standardized estimates. std.all contains usual regression standardization.

summary(ex3fit, ci = T)  #Include confidence intervals
```

or both!

```{r}
summary(ex3fit, standardized = TRUE, ci = T)
```

__Important: the default significance tests of defined parameters in lavaan is Sobel's test.__ 

## PART IV: Bootstrap confidence intervals

### The default one is boot.ci.type = "perc"

You can request bootstrap standard errors in sem() using se = "bootstrap" and bootstrap = 1000

```{r}
set.seed(2022)
ex3Boot <- lavaan::sem(model = ex3MediationSyntax, data = labData, se = "bootstrap", bootstrap = 1000, fixed.x=FALSE) 
```

This requires the full dataset - need more than the covariance matrix.

se = "bootstrap" requests bootstrap standard errors.

bootstrap = 1000 requests 1000 bootstrap samples.

Request bootstrap CI: 

```{r}
summary(ex3Boot, ci = TRUE) 
```

Now we have bootstrap standard error and percentile confidence interval for ab!

### BC (bias-corrected) confidence interval

What about other types of bootstrap confidence intervals?

You can request a BC (bias-corrected) by adding an argument boot.ci.type = "bca.simple" to parameterEstimates():

```{r}
parameterEstimates(ex3Boot, level = 0.95, boot.ci.type="bca.simple")
```

which returns a 95% BC confidence interval. 

This approach will yield similar results to the PROCESS Macro in SPSS with bias-corrected standard errors.


<!------------------------------>
## In-Class Exercise: Use Lavaan to estimate and interpret the following model
<!------------------------------>

```{r, eval=TRUE}
ex4MediationSyntax <- "
	#Regressions
	DietSE ~ a*SelfEsteem                  	
	Risk ~ cPrime*SelfEsteem + b*DietSE   
	
	#Define New Parameters
	ab := a*b 									#the product term is computed as a*b
	c := cPrime + ab 						#having defined ab, we can use this here.
"
```


```{r, eval=TRUE}
ex4fit <- lavaan::sem(model = ex4MediationSyntax, data = labData, fixed.x=FALSE)

summary(ex4fit, ci = T)
```

Bootstrap confidence intervals:

```{r, eval=TRUE}
set.seed(2022)

ex4Boot <- lavaan::sem(model = ex4MediationSyntax, data = labData, se = "bootstrap", bootstrap = 1000, fixed.x=FALSE) 

parameterEstimates(ex4Boot, level = 0.95, boot.ci.type="bca.simple")
```


<!------------------------------>
## Exercise: Eating Disorder Mediation Analysis
<!------------------------------>

Give it a try before peaking the answers! 

Hints:

1. Label the regression coefficients: b1 - b12;

2. Fix all disturbance covariances at 0;

3. Define mediation effects and total effects for each of the six mediation models using the labels;

4. Request bootstrap standard errors using se = "bootstrap"; 

5. Print and interpret the mediation effects;

6. (Optional) Identify and interpret the inconsistent mediation effects. 

I'll get you started: 


### Step 1: Labeling and defining the parameters
### Step 2: Fix all disturbance covariances at 0

```{r}
ex5PathSyntax_noCov <- " 			 #opening a quote
	DietSE ~ b1*BMI + b5*SelfEsteem      #DietSE is predicted by BMI and SelfEsteem 
	Bulimia ~ b10*DietSE + b2*BMI + b6*SelfEsteem
	Restrictive ~ b11*DietSE + b3*BMI + b7*SelfEsteem
	Risk ~ b12*DietSE + b4*BMI + b8*SelfEsteem + b9*Accu

	#Disturbance covariances (fixed at 0):
	DietSE ~~ 0*Bulimia  # ~~ indicates a two-headed arrow (variance or covariance)
	DietSE ~~ 0*Restrictive  # 0* in front of the 2nd variable fixes the covariance at 0
	DietSE ~~ 0*Risk     # These lines say that all endogenous variables have no correlated disturbance variances
	Bulimia ~~ 0*Restrictive
	Bulimia ~~ 0*Risk
	Restrictive ~~ 0*Risk
"  
```


### Step 3: Define new terms for mediation effects

Recall:

Define New Parameters

ab := a*b 									#the product term is computed as a*b


```{r, eval=TRUE}
ex5MediationSyntax <- "
	DietSE ~ b1*BMI + b5*SelfEsteem      #DietSE is predicted by BMI and SelfEsteem 
	Bulimia ~ b10*DietSE + b2*BMI + b6*SelfEsteem
	Restrictive ~ b11*DietSE + b3*BMI + b7*SelfEsteem
	Risk ~ b12*DietSE + b4*BMI + b8*SelfEsteem + b9*Accu

	#Disturbance covariances (fixed at 0):
	DietSE ~~ 0*Bulimia  # ~~ indicates a two-headed arrow (variance or covariance)
	DietSE ~~ 0*Restrictive  # 0* in front of the 2nd variable fixes the covariance at 0
	DietSE ~~ 0*Risk     # These lines say that all endogenous variables have no correlated disturbance variances
	Bulimia ~~ 0*Restrictive
	Bulimia ~~ 0*Risk
	Restrictive ~~ 0*Risk
	
	#Define New Parameters
	med1 := b1*b10
	total1 := b2 + med1
	med2 := b1*b11
	total2 := b3 + med2
	med3 := b1*b12
	total3 := b4 + med3
	med4 := b5*b10
	total4 := b6 + med4
	med5 := b5*b11
	total5 := b7 + med5
	med6 := b5*b12
	total6 := b8 + med6
"
```


```{r, eval=FALSE}
ex5fit <- lavaan::sem(model = ex5MediationSyntax, data = labData, fixed.x=FALSE)

summary(ex5fit, ci = T)
```

### Step 4: Bootstrap confidence intervals:
### Step 5: Print and interpret the mediation effects;

```{r, eval=TRUE}
set.seed(2022)

ex5Boot <- lavaan::sem(model = ex5MediationSyntax, data = labData, se = "bootstrap", bootstrap = 1000, fixed.x=FALSE) 

parameterEstimates(ex5Boot, level = 0.95, boot.ci.type="bca.simple")
```


### Plot it!

```{r}
library(semPlot)

semPaths(ex5Boot, what='est', 
         rotation = 2, # default rotation = 1 with four options
         curve = 2, # pull covariances' curves out a little
         nCharNodes = 0,
         nCharEdges = 0, # don't limit variable name lengths
         sizeMan = 8, # font size of manifest variable names
         style = "lisrel", # single-headed arrows vs. # "ram"'s 2-headed for variances
         edge.label.cex=1.2, curvePivot = TRUE, 
         fade=FALSE)
```


<!--chapter:end:04-Mediation.Rmd-->

# Week5_2: Lavaan Lab 3 Moderation and Conditional Effects

In this lab, we will learn how to: 

+ how to perform moderation using regression and sem
+ test the moderation effects of binary and continuous moderators
+ visualize moderation effects. 

<!------------------------------>
## Reading-In Datasets
<!------------------------------>

Let's read this dataset in. Change the file path to whatever directory where you saved the file!

```{r, eval = T}
cbtData <- read.csv(file = "dataInClass.csv", header = T)
```

Let's examine this dataset:

```{r}
head(cbtData)

str(cbtData)

colSums(is.na(cbtData))
```

Notice that the first two columns are not model variables

+ col 1 is a case ID variable.
+ col 2 is a factor variable indicating CBT vs. Info-Only treatment.

Besides,

+ col 5 is a variable that measures negative thoughts.
+ col 7 is a continuous measure of NeedCog.


In the first part of this demo, we will work with three variables: CBTDummy, NeedCog, and Depression

Let's look at the covariance matrix of the three variables

Multiple ways to accomplish this:

```{r}
cov(cbtData[,-c(1,2,5,7)])
cov(cbtData[,c(3,4,6)])
cov(cbtData[,c("CBTDummy", "NeedCog", "Depression")])
```

let's round this to two decimals

```{r}
round(cov(cbtData[,c("CBTDummy", "NeedCog", "Depression")]), digits = 2)
```

What about the means?

```{r}
round(apply(cbtData[,c("CBTDummy", "NeedCog", "Depression")], 2, mean), 2)
```

Although they are not centered, we will proceed because CBTDummy and NeedCog are both binary. 


<!------------------------------>
## Interactions in Regression Using lm()
<!------------------------------>

In regression course we learned the lm() function, which stands for linear model.

To include an interaction in regression, simply use an : to create a product in the formula: 

```{r}
interactionModel <- lm(formula = Depression ~ CBTDummy + NeedCog + CBTDummy:NeedCog, data = cbtData)
```

NOTE: R is very helpful, in that if you just put an asterisk *, it includes all lower-order terms!

```{r}
interactionModel <- lm(formula = Depression ~ CBTDummy*NeedCog, data = cbtData)
```

Let's look at this interaction model: 

```{r}
summary(interactionModel)
```


Let's interpret this ... (In class)


<!------------------------------>
## Interactions in Lavaan
<!------------------------------>

Now let us write the same model using lavaan.

Load the package: 

```{r, eval = T}
library(lavaan)
```

### IMPORTANT NOTE

Because lavaan uses the * for assigning coefficient labels, this cannot be used to create interaction terms.

Instead, we have to create the product term in the dataset first, before running our model.

This is easy to do.

General Format:

existingDataFrame$variableName <- vectorToBeAssignedAsNewVariable

```{r}
cbtData$CBTxNeedCog <- cbtData$CBTDummy * cbtData$NeedCog
```

You can name the product term arbitrarily: 

cbtData\$fourth <- cbtData\$CBTDummy * cbtData$NeedCog

Let's look at cbtData again:

```{r}
head(cbtData)
```

Now you have a new variable called CBTxNeedCog at the end.


### Follow the equation of Y (Depression): 

Depression = CBTDummy +  NeedCog + CBTDummy*NeedCog + Disturbance

Let's write some model syntax (with the labels):

```{r, eval = T}
interactionSyntax <- "
  #Regression with interaction
  #with labels
	Depression ~ b1*CBTDummy + b2*NeedCog + b3*CBTxNeedCog
"
```

let fixed.x=FALSE to print more lines: 

```{r}
inter_fit1 <- lavaan::sem(model = interactionSyntax, 
                  data = cbtData, 
                  fixed.x = FALSE)
```

If you'd like lavaan to print means and intercepts, we need to ask sem() to include the meanstructure:

```{r}
inter_fit1 <- lavaan::sem(model = interactionSyntax, 
                  data = cbtData, 
                  fixed.x =FALSE, 
                  meanstructure = TRUE)
```


```{r}
summary(inter_fit1)
```

How does this compare to our regression model?

```{r}
summary(interactionModel)
```

Same...but sem is more verbose. 


<!------------------------------>
## Visual inspection of interactions
<!------------------------------>

One way to plot the interactions is to use the interact_plot() function on the lm() object. 

Install and load the package interactions first:

```{r}
library(interactions)
```

```{r}
interact_plot(interactionModel, pred = "CBTDummy", modx = "NeedCog")
```

<!------------------------------>
## Centering Continuous Moderator
<!------------------------------>

Now let's work with the continuous measure of NeedCog directly:

```{r}
mean(cbtData$NeedCogCont)
sd(cbtData$NeedCogCont)
```

NeedCogCont has been standardized already, which is helpful.

If not, we use scale() function to center a continuous variable

 + Usage: scale(x, center = TRUE, scale = TRUE)
 + If you just need to center a variable, you disable scale=FALSE

```{r}
centeredNeedCog <- scale(cbtData$NeedCogCont, center = TRUE, scale = FALSE)
hist(centeredNeedCog)
```

For now, we will leave these variables as is in our dataset. But the scale() function is good to know.

<!------------------------------>
## Interactions in Lavaan (Continuous Moderator)
<!------------------------------>

Just like for binary NeedCog moderator, we have to manually create a product term in the dataset first before running our model.

This is easy to do: 

```{r}
cbtData$CBTxNeedCogCont <- cbtData$CBTDummy * cbtData$NeedCogCont
```

Let's look at cbtData again:

```{r}
head(cbtData)
```

Time to write some lavaan model syntax (with labels): 

```{r}
interactionSyntax2 <- "
	#Regression
	Depression ~ b1*CBTDummy + b2*NeedCogCont + b3*CBTxNeedCogCont 
"
```

Let's ask sem() to include the meanstructure:

```{r}
inter_fit2 <- lavaan::sem(model = interactionSyntax2, 
                  data = cbtData, 
                  fixed.x =FALSE, 
                  meanstructure = TRUE)
```

```{r}
summary(inter_fit2)
```


<!------------------------------>
## Simple Slopes Analysis
<!------------------------------>

pick-a-point (Rogosa, 1980) and plot the simple slopes of X at designated levels of Z: 

```{r}
mean(cbtData$NeedCogCont) #0
sd(cbtData$NeedCogCont) # almost 1

mean(cbtData$NeedCogCont) - sd(cbtData$NeedCogCont) # 1sd below the mean
mean(cbtData$NeedCogCont) + sd(cbtData$NeedCogCont) # 1sd above the mean
```

```{r}
interactionSyntax3 <- "
	#Regression
	Depression ~ b1*CBTDummy + b2*NeedCogCont + b3*CBTxNeedCogCont #regression coefficient labels

	#Simple Slopes
	
	SSHigh := b1+b3*1 		#Since sd(NeedCogCont) = approximately 1, this is +1 SD
	SSMod := b1+b3*0 		  #at the mean of (centered) NeedCogCont
	SSLow := b1+b3*(-1)   #Low Simple Slope is at -1 (1 SD below since SD = 1)
"
```


```{r}
inter_fit3 <- lavaan::sem(model = interactionSyntax3, 
                  data = cbtData, 
                  fixed.x =FALSE, 
                  meanstructure = TRUE)

summary(inter_fit3)
```

Now we have tests of the simple slopes at low, moderate, and high values of the moderator!

Along with significance tests.

<!------------------------------>
## Visual inspection of interactions (lm approach)
<!------------------------------>

Interactions in Regression Using lm()

To include ab interaction in regression, simply use an * to create a product in the formula.

```{r}
interactionModel2 <- lm(Depression ~ CBTDummy*NeedCogCont, cbtData)

summary(interactionModel2)
```

pick-a-point (Rogosa, 1980) and plot the simple slopes of X at designated levels of Z: 

```{r}
library(interactions)

interact_plot(interactionModel2, pred = "CBTDummy", modx = "NeedCogCont")
```

<!------------------------------>
## JOHNSON-NEYMAN INTERVAL 
<!------------------------------>

```{r}
interactions::johnson_neyman(interactionModel2, pred = "CBTDummy", modx = "NeedCogCont", alpha = 0.05)
```


<!------------------------------>
## Exercise: How Framing Affects Justifications for Giving or Withholding Aid to Disaster Victims
<!------------------------------>

For this exercise, we will use a real dataset in a study by Chapman and Lickel (2016). 

This study was interested in examining the relation between Climate Change and Disasters: How Framing Affects Justifications for Giving or Withholding Aid to Disaster Victims?

Researchers hypothesizes that Framing a natural disaster as the product of climate change impacts attitudes toward disaster victims and humanitarian relief. 

The predictor is X/Frame: 

 + Participants read a story about a humanitarian crisis caused by a drought in Africa.
 + X = 1: Half of the participants were told that the drought was caused by climate change (the climate change condition) 
 + X  = 0: The other half were not told anything about the specific cause of the drought and thus had no reason to believe it wasn’t the result of natural causes (the natural causes condition). 

The outcome is Y/Donate: 

 + the participants’ willingness to donate to the victims was assessed using a set of questions. 
 + Responses were made on a set of 7-point scales, with higher scores reflecting a greater willingness to donate to the victims

The moderator is W/Skeptic: 

 + The belief whether climate change is a real phenomenon was also measured.


The moderation model looks at whether the attribution frame manipulation (X) might have had a different effect on people's willingness to donate (Y) depending on their climate change skepticism (M)

### Data Prep

The following example data are from Chapman and Lickel (2016)

Also example data in Chapter 12 of Hayes (2017)

Simply load the .rda into R:

```{r}
load("disaster.rda")

head(disaster)
str(disaster)
```

If you are able to install package processR, you can also view its help page:

```{r ins1, eval=FALSE}
install.packages("processR")

library(processR)

data(disaster)

# take a look at the dataset: 

?disaster
```

You probably have to go to https://www.xquartz.org/ to download and install X11, which is a server required by many R packages, including processR. 


Now, disaster is a data.frame with 211 obs. of 5 variables: 

+ id
+ frame: Experimental condition. 0 = naturally caused disaster, 1 = climate change caused disaster
+ donate: Positive attitudes toward donating
+ justify: Negative justifications
+ skeptic: Climate change skepticism


### Moderation with a binary moderator

Let me first manually create a binary moderator based on the continuous version of skeptic: 

```{r}
disaster$skeptic_b <- ifelse(disaster$skeptic<3, 0, 1) # low and high levels of skeptism of climate change
table(disaster$skeptic_b)
```

Next, can you test the moderation effect of skeptic_b on the path from frame to donate? (you can use either lm or lavaan)

```{r}

```

Please interpret the coefficients in the model above and visualize the interaction using interact_plot(). 


<!--chapter:end:05-Moderation.Rmd-->

# Week6_1: Lavaan Lab 4 Mediated Moderation & Moderated Mediation

In this lab, we will learn how to: 

+ Estimate the mediated moderation model
+ Estimate the moderated mediation model
+ Bootstrap the effects
+ Conduct simple slope analyses

<!------------------------------>
## PART 1: Mediated Moderation (Indirect Conditional effect)
<!------------------------------>

### Step 1: Read-in Data

Imagine that we extended our CBT study by adding a mediator: the average number of daily negative thoughts reported at the end of six weeks.

The hypothesis we will test is that NegThoughts mediates the CBT*NeedCog -> Depression path

Let's read this dataset in: 

```{r, eval = T}
cbtData <- read.csv(file = "dataInClass.csv", header = T, sep = ',')
```

This time we work with the continuous version of the moderator: NeedCogCont. 

Let's examine their means and standard deviations:

```{r}
apply(cbtData[,-c(1,2)], 2, mean)
apply(cbtData[,-c(1,2)], 2, sd)
```

Why dropping the first two variables? 

+ The first two variables ID and CBT are not numerical and have no means. 

NeedCogCont has been standardized already, which is helpful. 

+ If not, don't forget to use scale() function to center the continuous variables. 

### Step 2: Create the interaction term for Moderation Analysis

To test the moderation effect, we have to manually create a product term in the dataset before running our model: 

```{r}
cbtData$CBTxNeedCogCont <- cbtData$CBTDummy * cbtData$NeedCogCont
```

Let's look at cbtData again:

```{r}
head(cbtData)
```

### Step 3: Write the syntax and Fit the model 

load the package:

```{r}
library(lavaan)
```

Follow the two equations to write the model syntax: 

```{r}
ex1MedModerationBasic <- " 
  # label the coefficients:
  
  NegThoughts ~ a_m1*CBTxNeedCogCont + a_m2*NeedCogCont + a_m3*CBTDummy
	Depression ~ b1*CBTDummy + b2*NeedCogCont + b3*CBTxNeedCogCont + bM*NegThoughts

  #Define New Parameter Using :=
  
  #Mediated Moderation effect  
  MedMod_ab := a_m1*bM
  TotalMod := MedMod_ab + b3
	"  
```

Since we included the intercept term, we need to ask sem() to include the meanstructure:

```{r}
ex1fit <- lavaan::sem(model = ex1MedModerationBasic, 
              data = cbtData, 
              fixed.x = FALSE,
              meanstructure = TRUE)
summary(ex1fit, ci = T)
```

Are we done?

### Step 4: Bootstrap Version

We need to request Bootstrap because this involves testing a mediation effect MedMod_ab. 

Remember to set a seed: 

```{r}
set.seed(2022)
ex1Boot <- lavaan::sem(model = ex1MedModerationBasic, 
               data = cbtData, 
               fixed.x = FALSE,
               meanstructure = TRUE,
               se = "bootstrap", 
               bootstrap = 1000) 
```

+ This requires the full dataset - need more than the covariance matrix.
+ se = "bootstrap" requests bootstrap standard errors.
+ bootstrap = 1000 requests 1000 bootstrap samples. 

Request BC confidence interval:

```{r}
parameterEstimates(ex1Boot, 
                   level = 0.95, 
                   boot.ci.type="bca.simple",
                   standardized = TRUE)
```

Warning message:

In norm.inter(t, adj.alpha) : extreme order statistics used as endpoints

https://rcompanion.org/handbook/E_04.html

The BCa (bias corrected, accelerated) is often cited as the best for theoretical reasons.  The percentile method is also cited as typically good.  However, if you get the “extreme order statistics used as endpoints” warning message, use a different test.  For small data sets, the interval from BCa may be wider than for some other methods.

### Step 5: Effect size measures

Measure 1: Completely Standardized Indirect Effect (CSIE)

```{r}
beta_a_m1 = -0.668
beta_bM = 0.892
es1 = beta_a_m1*beta_bM
es1
```

+ According to Cohen, .01-.09 is small, .10-.25 is medium, and .25 + is large
+ This is a large mediation effect

Measure 2: 

+  Use unstandardized parameter estimates:

```{r}
TotalMod = -4.967
MedMod_ab = -4.858
prop = MedMod_ab/TotalMod #97.8%
prop
b3 = -0.109 # pvalue=0.218 # nonsig
```

+ Mediated% = indirect effect / total effect = ab / c
+ Consistent mediation 
+ Complete mediation as the remaining direct effect is nonsig and prop > 80%




<!------------------------------>
## PART 2: Moderated Mediation (Conditional Indirect effect)
<!------------------------------>

In this lab, we'll test this first-stage moderated mediation model in which NeedCog moderates the CBT -> NegThoughts path

### Step 1: Product Term

We already have the product term in the dataset:

```{r}
cbtData$CBTxNeedCogCont <- cbtData$CBTDummy * cbtData$NeedCogCont
```

If NeedCog moderates the NegThoughts -> Depression path, then we center NegThoughts and create a product term between centered NegThoughts*NeedCogCont (making sense?)

### Step 2: Write the syntax and Fit the model 

```{r}
ex2ModMediationBasic <- " 
  NegThoughts ~ a1*CBTDummy + a2*NeedCogCont + a3*CBTxNeedCogCont 
	Depression ~ b*NegThoughts + cprime*CBTDummy
	"
```

We'll need to define the Index of Moderated Mediation in the syntax:

```{r}
ex2ModMediation <- " 
	#Regressions
  NegThoughts ~ a1*CBTDummy + a2*NeedCogCont + a3*CBTxNeedCogCont 
	Depression ~ b*NegThoughts + cprime*CBTDummy

  #Index of Moderated Mediation
  IndexOfModMed := a3*b
	"  
```

### Step 3: Bootstrap Version

Since this model involves tests of indirect effects

let's jump to the bootstrap test: 

```{r}
set.seed(2022)
ex2Boot <- lavaan::sem(model = ex2ModMediation, 
               data = cbtData, 
               fixed.x = FALSE,
               meanstructure = TRUE,
               se = "bootstrap", 
               bootstrap = 1000) 
```

You can further request a BC (bias-corrected) by adding an argument boot.ci.type = "bca.simple" to parameterEstimates():

```{r}
parameterEstimates(ex2Boot, 
                   level = 0.95, 
                   boot.ci.type="bca.simple",
                   standardized = TRUE)
```

Defined Parameters:

                   Estimate  Std.Err  ci.lower  ci.upper   std.all

    IndexOfModMed    -4.967    0.114    -5.180    -4.727    -0.609

NeedCogCont significantly moderates CBT -> NegThoughts -> Depression indirect effect through moderating the first stage of the indirect effect

+ Since we expect the effect of CBT on Depression to be negative (CBT reduces Depression)
+ And IndexOfModMed is also negative
+ We'll say NeedCogCont strengthens the indirect effect of CBT on Depression through NegThoughts
+ The higher need for cognition, the stronger the indirect effect, and the more effect mediated by NegThoughts

### Step 4: Simple Slopes 

As a follow-up analysis to a significant moderation effect, we conduct simple slope anlaysis:

Let's use pick-a-point (Rogosa, 1980) and plot the indirect effects at designated levels of NeedCogCont: 

```{r}
mean(cbtData$NeedCogCont) #0
sd(cbtData$NeedCogCont) # 1
```

Three representative levels:

```{r}
mean(cbtData$NeedCogCont) - sd(cbtData$NeedCogCont) # -1
mean(cbtData$NeedCogCont)  #0
mean(cbtData$NeedCogCont) + sd(cbtData$NeedCogCont) # 1
```

let's define the Conditional Indirect Effects in the syntax:

```{r}
ex3ModMediation <- " 
	#Regressions
  NegThoughts ~ a1*CBTDummy + a2*NeedCogCont + a3*CBTxNeedCogCont 
	Depression ~ b*NegThoughts + cprime*CBTDummy

  #Index of Moderated Mediation
  IndexOfModMed := a3*b

  #Simple Slopes
	aSSLow := a1+a3*(-1)	
	aSSMean := a1+a3*0 		
	aSSHigh := a1+a3*1 		

	#Conditional Indirect Effects
	abLow := aSSLow*b
	abMean := aSSMean*b
	abHigh := aSSHigh*b
	"  
```

```{r}
set.seed(2022)
ex3Boot <- lavaan::sem(model = ex3ModMediation, 
               data = cbtData, 
               se = "bootstrap", 
               bootstrap = 1000, 
               fixed.x=FALSE,
               meanstructure = TRUE) 
```

```{r}
parameterEstimates(ex3Boot, 
                   level = 0.95, 
                   boot.ci.type="bca.simple",
                   standardized = TRUE)
```


```{r,eval=FALSE,echo=TRUE}
Defined Parameters: 
                   Estimate  Std.Err  z-value  P(>|z|)    ci.lower  ci.upper    std.all
    IndexOfModMed    -4.967    0.114  -43.431    0.000      -5.180    -4.727     -0.609      
    aSSLow           -1.990    0.092  -21.679    0.000      -2.176    -1.813     -0.126  
    aSSMean          -5.060    0.064  -78.724    0.000      -5.183    -4.930     -0.794                                 
    aSSHigh          -8.131    0.094  -86.243    0.000      -8.313    -7.942     -1.462  
    abLow            -3.218    0.151  -21.338    0.000      -3.532    -2.941     -0.115  
    abMean           -8.185    0.121  -67.625    0.000      -8.433    -7.944     -0.725  
    abHigh          -13.152    0.181  -72.721    0.000     -13.513   -12.779     -1.334  
    b                 1.617    0.013  124.544    0.000       1.592     1.642      0.912  
    cprime           -1.066    0.084  -12.758    0.000      -1.216    -0.899     -0.094  
```

+ What does a1 tell you?
+ What does a2 tell you?
+ What does a3 tell you?
+ What does IndexOfModMed tell you?
+ What does aSSLow tell you?
+ What does aSSMean tell you?
+ What does aSSHigh tell you?
+ What does b tell you?
+ What does abLow tell you?
+ What does abMean tell you?
+ What does abHigh tell you?
+ What does cprime tell you?

+ the simple slopes of CBT -> NegThoughts (a path) are all negative at three levels of the moderator
+ the indirect effects of CBT -> NegThoughts -> Depression (ab) are all negative at three levels of the moderator



<!------------------------------>
### Step 5 JOHNSON-NEYMAN INTERVAL 
<!------------------------------>

Although johnson_neyman() does not work on lavaan fitted object (yet), one can use a try-and-error approach to figure out the region of significance: 

First, obtain the minimum and maximum of the moderator NeedCogCont: 

```{r}
min(cbtData$NeedCogCont)   # -2.83
max(cbtData$NeedCogCont)   #  3.31
```


```{r}
ex4_JN <- " 
	#Regressions
  NegThoughts ~ a1*CBTDummy + a2*NeedCogCont + a3*CBTxNeedCogCont 
	Depression ~ b*NegThoughts + cprime*CBTDummy

  #Index of Moderated Mediation
  IndexOfModMed := a3*b

  #Simple Slopes
 	aSSMin := a1+a3*(-2.83)	
 	aSSMin1 := a1+a3*(-1.75)	
 	aSSMin2 := a1+a3*(-1.74)	
 	aSSMin3 := a1+a3*(-1.58)	
 	aSSMin4 := a1+a3*(-1.57)	
 	aSSLow := a1+a3*(-1)	
 	aSSMean := a1+a3*0 		
 	aSSHigh := a1+a3*1 		
 	aSSMax := a1+a3*(3.31)	

	#Conditional Indirect Effects
	abMin := (a1+a3*(-2.83))*b
	abMin1 := (a1+a3*(-1.75))*b    # cutoff1
	abMin2 := (a1+a3*(-1.74))*b
	abMin3 := (a1+a3*(-1.58))*b
	abMin4 := (a1+a3*(-1.57))*b    # cutoff2
	abLow := aSSLow*b
	abMean := aSSMean*b
	abHigh := aSSHigh*b
	abMax := (a1+a3*(3.31))*b
	"  
```


```{r}
set.seed(2022)
ex4Boot <- lavaan::sem(model = ex4_JN, 
               data = cbtData, 
               se = "bootstrap", 
               bootstrap = 1000, 
               fixed.x=FALSE,
               meanstructure = TRUE) 
```

```{r}
parameterEstimates(ex4Boot, 
                   level = 0.95, 
                   boot.ci.type="bca.simple")
```

So our regions of significance are: 

+ $[-2.83, -1.75]$: In which the ab are positive and significant. Participants with this level of NeegCog experienced elevated levels of depression due to CBT because CBT induces more negative thoughts among them. 
+ $[-1.75, -1.57]$: In which the ab are NOT significant. 
+ $[-1.57, 3.31]$: In which the ab are negative and significant. Participants with this level of NeegCog experienced reduced levels of depression due to CBT because CBT reduced negative thoughts for them. 
 

<!--chapter:end:06-MediationModeration.Rmd-->

# Week6_2: R Lab on Disaster Dataset (Chapman and Lickel, 2016)


## Data Prep

The following example data are from Chapman and Lickel (2016)
Also example data in Chapter 12 of Hayes (2017)

Simply load the .rda into R:

```{r}
load("disaster.rda")

head(disaster)
str(disaster)
```

If you are able to install package processR, you can also view its help page:

```{r, eval=FALSE}
install.packages("processR")

# If error message persists, change the repository to CRAN:

install.packages("processR", repos="https://cran.rstudio.com/")

library(processR)

data(disaster)

# take a look at the dataset: 

?disaster
```

```{r, message=FALSE}
library(processR)
```

You probably have to go to https://www.xquartz.org/ to download and install X11, which is a server required by many R packages, including processR. 

Disaster is a data.frame with 211 obs. of 5 variables: 

+ id
+ frame: Experimental condition. 0 = naturally caused disaster, 1 = climate change caused disaster
+ donate: Positive attitudes toward donating
+ justify: Negative justifications
+ skeptic: Climate change skepticism


### Scatterplot Matrix

Before we build linear models, we should plot the relationship between pairs of variables:

```{r, warning=FALSE, fig.height = 4, fig.width = 5, message=FALSE}
library(PerformanceAnalytics)
chart.Correlation(disaster[,-1])
```

### p-value or bootstrapped confidence interval? 

For models that involve mediation effects, we prefer to use bootstrap confidence intervals over p-values for evaluating the significance of parameter estimates. That is, in the parameter table generated by parameterEstimates() function: 

* A coefficient is considered significant when the interval [ci.lower, ci.upper] does not include zero; 
* A coefficient is considered insignificant when the interval [ci.lower, ci.upper] includes zero. 

In most cases, bootstrap confidence intervals and p-values yield the same conclusions regarding the significance of parameter estimates. If not, bootstrap confidence intervals are used to make the final call.  

In this document, all bootstrap confidence intervals and p-values yield the same conclusions regarding significances, so I'll only refer to p-values for the readability of the analyses. 


## Model 1: Simple Linear Regression Model

With processR, you can draw concept diagram and statistical diagram of `mediation` and `moderation` models quite easily. For example: 

```{r diag demo, fig.height = 4}
labels=list(X="frame",M="justify",Y="donate",W="skeptic")
par(mfrow = c(2,1), mar=c(0,0,0,0), oma=c(0,0,0,0))
pmacroModel(0,labels=labels)
statisticalDiagram(0, labels=labels)
```

return the diagrams of a simple linear regression model. 

For Model 1, let's run a simple linear regression using lm() to estimate the total effect of frame on willingness to donate: 

```{r lm1}
lm1 = lm(donate ~ frame , data = disaster)
summary(lm1)[[4]]
```

* Note that the `[[4]]` was added after `summary(lm1)` to request the coefficient table only.

* The total effect is c = 0.084 (p = 0.645), not significant. 

* However, we learned in this class that absence of association between X and Y does NOT mean that X isn't affecting Y (remember inconsistent mediation?).

So let's move on...


<!------------------------------>
## Model 2: Simple Mediation Model
<!------------------------------>

Q: If a disaster is framed as the result of a climate change (instead of a natural disaster), do you think it's justified to withhold aid to the victims, and thus become less willing to donate? 

```{r diag2, fig.height = 4}
par(mfrow = c(1,2), mar=c(0,0,0,0), oma=c(0,0,0,0))
pmacroModel(4,labels=labels)
statisticalDiagram(4, labels=labels)
```

Load the lavaan package: 

```{r}
library(lavaan)
```

and test the mediation effect (ab) using bootstrap:

```{r lm2}
lm2.syntax <- '
donate ~ b*justify + cprime*frame
justify ~ a*frame

# Define new parameters
#The := operator in lavaan defines new parameters.
ab:= a*b
c:= a*b + cprime
'

set.seed(2022)
lm2.bfit = sem(lm2.syntax, data = disaster, se = "bootstrap", bootstrap = 1000, fixed.x=FALSE, meanstructure = TRUE)
summary(lm2.bfit, ci = T)
parameterEstimates(lm2.bfit, boot.ci.type = "bca.simple", standardized = T)
```

From the coefficient table, we can see:

* a path: a = 0.134 (p = 0.306)
* b path: b = -0.953 (p = 0.000)
* indirect effect: ab = -0.128 (p = 0.307)
* direct effect: cprime = 0.212 (p = 0.127)
* total effect: c = ab + cprime = 0.084 (p = 0.655)
* Except for b path, all effects above are not significant. 

This tells us: 

* The framing of the disaster did not significantly change people’s beliefs about whether providing aid to the victims is justified (a path)
* Justification for withholding aid did make participants less willing to donate (b path) 
* However, the indirect effect ab was not significant, meaning justification for withholding did not explain the relationship between frame and willingness to donate

Let's switch to moderation model:

<!------------------------------>
## Model 3: Simple Moderation Model
<!------------------------------>

Skepticism of climate change cannot be changed by the frame, so skeptic is a moderator, not a mediator, it does not stand in the middle of the pathway

```{r diag3, fig.height = 4}
par(mfrow = c(1,2), mar=c(0,0,0,0), oma=c(0,0,0,0))
pmacroModel(1,labels=labels)
statisticalDiagram(1, labels=labels)
```

Since the moderator skeptic is a continuous measure, we need to mean center it first: 

```{r}
disaster$skep_raw = disaster$skeptic
disaster$skeptic = scale(disaster$skep_raw, center = TRUE, scale = FALSE)
disaster$skep_sd = scale(disaster$skep_raw, center = TRUE, scale = TRUE)
disaster$skepxframe = disaster$skeptic * disaster$frame
```

.. and manually create an interaction term by multiplying skeptic and frame: 

```{r}
disaster$skepxframe = disaster$skeptic * disaster$frame
```

Let's examine their means and standard deviations:

```{r}
round(apply(disaster, 2, mean), 2)
round(apply(disaster, 2, sd), 2)
```

Let's write the syntax for the simple moderation model:

```{r lm3}
lm3.syntax <- '
#Regression with interaction
donate ~ b1*skeptic + b2*frame + b3*skepxframe
'

lm3.fit = sem(lm3.syntax, data = disaster, fixed.x=FALSE, meanstructure = TRUE)
parameterEstimates(lm3.fit, ci = T)
```

* b3 = -0.171, p = 0.040
* So this moderator, skeptic, is a significant moderator of the frame-donate path, that is, skepticism of climate change could change the effect of framing on willingness to donate. 

### JOHNSON-NEYMAN INTERVAL 

```{r}
interactionModel2 <- lm(donate ~ skeptic*frame, disaster)

summary(interactionModel2)
```

```{r}
library(interactions)

interactions::johnson_neyman(interactionModel2, pred = "frame", modx = "skeptic", alpha = 0.05)
```

* As can be seen, it appears that among those low in climate change skepticism (lower than -2.59), framing the drought as caused by climate change produced a greater willingness to donate (simple slopes were significantly positive) compared to when climate change was not described as the cause. 
* Among climate change skeptics (i.e., those high on the skepticism scale), the willingness to donate to the victims were not affected the framing of the problem (simple slopes were not significantly different from 0).

Next, let's test those Moderated Mediation Models one by one. 

<!------------------------------>
## Model 4a: Moderated Mediation Model - Path a only
<!------------------------------>

```{r diag4a, fig.height = 4}
par(mfrow = c(1,2), mar=c(0,0,0,0), oma=c(0,0,0,0))
pmacroModel(7,labels=labels)
statisticalDiagram(7, labels=labels)
```

* Since the frame-justify (a path) is hypothesized to be moderated by skeptic, the simple slope of justify on frame is a function of skeptic, that is, a1+a3*skeptic

* The indirect effect through justify also depends on skeptic, calculated as b\*(a1+a3*skeptic)

* Since skeptic is a continuous variable, we will pick three values from it. The chapter in Hayes (2017) picked the 16th, 50th, and 84th percentiles of the distribution using the quantile() function:

```{r}
quantile(disaster$skeptic, probs = c(0.16, 0.5, 0.84))
```

which are:

* low: -1.78
* median: -0.58
* mean: 0 (why)
* high: 1.82

We'll also define the index of moderated mediation to be: 

* a3*b (refer to slides of week6_1)

Let's write the syntax for the moderated mediation model:

```{r lm4a}
lm4a.syntax <- '
donate ~ b*justify + cprime*frame
justify ~ a1*frame + a2*skeptic + a3*skepxframe

# Define simple slopes and conditional indirect effects using :=

# index of moderated mediation

IndMedMod:= a3*b

# simple slope of justify on frame is a1+a3*skeptic
aLow: = a1+a3*(-1.78)
aMedian: = a1+a3*(-0.58)
aMean: = a1+a3*(0)
aHigh: = a1+a3*1.82

# conditional indirect effects is b*(a1+a3*skeptic)
abLow: = b*aLow
abMedian: = b*aMedian
abMean: = b*aMean
abHigh: = b*aHigh
'

set.seed(2022)
lm4a.fit = sem(lm4a.syntax, data = disaster, se = "bootstrap", bootstrap = 1000, fixed.x=FALSE, meanstructure = TRUE)
parameterEstimates(lm4a.fit, level = 0.95, boot.ci.type = "bca.simple")
```

So we have:

* interaction of skepxframe on justify: a3 = 0.201 (p = 0.001)

The overall effect of frame on justify is significantly moderated by skeptic. That is, how the disaster is framed has a differential effect for people who differ in their climate change skepticism on their beliefs that if it was justified to withhold aid to the victims. 

Let's look at the simple slopes. 

* aLow = -0.241 (p = 0.117)
* aMedian = 0 (p = 0.997)
* aMean = 0.117 (p = 0.307)
* aHigh = 0.483 (p = 0.004)

Moreover, the simple slope aHigh is positive and aLow is negative. That is, when told that the disaster is the result of climate change instead of natural disaster (changing frame from 0 to 1), those who doubt climate change (high on skepticism) think it's justified to withhold the aid whereas those who do not doubt (low on skepticism) it think it's not justified to withhold the aid. 


Okay! The a path is moderated. What about the mediation effect ab?

* IndexOfModMed = -0.192 (p = 0.002)

IndexOfModMed is sig! Woo-hoo! Indirect effect is moderated, too! So what story does it tell you? 

* abLow = 0.230 (p = 0.122)
* abMedian = 0.000 (p = 0.997)
* abMean = -0.112 (p = 0.305)
* abHigh = -0.461 (p = 0.005)

Furthermore, abHigh is negative and abLow is positive, meaning that framing the disaster as caused by climate change leads to less donation for people who doubt climate change (high on skepticism) but it leads to more donation for people who believe it (low on skepticism). The reason for this differential effect is that those who doubt climate change tend to favor the idea of withholding the aid, thus leading to less donation. 


<!------------------------------>
## Model 4b: Moderated Mediation Model - Path b only
<!------------------------------>

```{r diag4b, fig.height = 4}
par(mfrow = c(1,2), mar=c(0,0,0,0), oma=c(0,0,0,0))
pmacroModel(14,labels=labels)
statisticalDiagram(14, labels=labels)
```


Since justify is also a continuous measure, we need to mean center it first: 

```{r}
disaster$just_raw = disaster$justify
disaster$justify = scale(disaster$just_raw, center = TRUE, scale = FALSE)
disaster$just_sd = scale(disaster$just_raw, center = TRUE, scale = TRUE)
```

and create an interaction term by multiplying skeptic by justify (note that this is a new interaction term!):

```{r}
disaster$skepxjusti = disaster$skeptic * disaster$justify
```

Let's examine their means and standard deviations:

```{r}
round(apply(disaster[,-1], 2, mean), 2)
round(apply(disaster[,-1], 2, sd), 2)
```

Since the b path is hypothesized moderated by skeptic, the simple slope of donation on justify (b path) depends on skeptic, the indirect effect through justify (ab) also depends on skeptic. 

We'll define an index of moderated mediation to be: 

* a*b3 (can you derive this?)

Let's write the syntax for the moderated mediation model:

```{r lm4b}
lm4b.syntax <- '
donate ~ b1*justify + cprime*frame + b2*skeptic + b3*skepxjusti
justify ~ a*frame

# Define simple slopes and conditional indirect effects using :=

# index of moderated mediation

IndMedMod:= a*b3

# simple slope of donate on justify is b1+b3*skeptic
bLow: = b1+b3*(-1.78)
bMedian: = b1+b3*(-0.58)
bMean: = b1+b3*(0)
bHigh: = b1+b3*1.82

# conditional indirect effects is a*(b1+b3*skeptic)
abLow: = a*bLow
abMedian: = a*bMedian
abMean: = a*bMean
abHigh: = a*bHigh
'

set.seed(2022)
lm4b.fit = sem(lm4b.syntax, data = disaster, se = "bootstrap", bootstrap = 1000, fixed.x=FALSE, meanstructure = TRUE)
parameterEstimates(lm4b.fit, level = 0.95, boot.ci.type = "bca.simple")
```

So we have:

* b3 = 0.008 (p = 0.743)

The effect of justify on donate is not moderated by skeptic. That is, justification for withholding aid always leads to less donation has a fixed effect on their willingness to donate (b path) regardless of their climate change skepticism. 

Let's look at the simple slopes. 

* bLow = -0.937 (p = 0.000)
* bMedian = -0.927 (p = 0.000)
* bMean = -0.922 (p = 0.000)
* bHigh = -0.907 (p = 0.000)

which do not change much as their climate change skepticism change. Justification for withholding aid always leads to less donation. Skeptic is not an effective moderator. 

Let's look at the indirect effects

* IndexOfModMed = 0.001 (p = 0.808)
* abLow = -0.126 (p = 0.306)
* abMedian = -0.125 (p = 0.306)
* abMean = -0.124 (p = 0.307)
* abHigh = -0.122 (p = 0.310)

Similarly, skeptic is not a good moderator for the indirect effect given that IndexOfModMed is not significant and the indirect effects at high/low levels of skepticism do not differ much. 


<!------------------------------>
## Model 4c: Moderation & Mediation Model - Path cprime only
<!------------------------------>

```{r diag4c, fig.height = 4}
par(mfrow = c(1,2), mar=c(0,0,0,0), oma=c(0,0,0,0))
pmacroModel(5,labels=labels)
statisticalDiagram(5, labels=labels)
```

Since there is NO indirect effect being moderated here, we'll not define any index of moderation mediation. There is only one c3prime coefficient that quantifies the moderation effect of skeptic on frame-donation path.  

```{r lm4c}
lm4c.syntax <- '
donate ~ b*justify + c1prime*frame + skeptic + c3prime*skepxframe
justify ~ a*frame

# Define new parameters
#The := operator in lavaan defines new parameters.

# simple slope of donate on frame is c1prime+c3prime*skeptic
cLow: = c1prime+c3prime*(-1.78)
cMedian: = c1prime+c3prime*(-0.58)
cMean: = c1prime+c3prime*(0)
cHigh: = c1prime+c3prime*1.82

# mediation effect
ab:= a*b
'

set.seed(2022)
lm4c.fit = sem(lm4c.syntax, data = disaster, se = "bootstrap", bootstrap = 1000, fixed.x=FALSE, meanstructure = TRUE)
parameterEstimates(lm4c.fit, level = 0.95, boot.ci.type = "bca.simple")
```

Since we have:

* c3prime = 0.015 (p = 0.839) 

Skeptic is not a moderator for this frame-donation path (cprime). 

The mediation effect:

* ab = -0.124 (p = 0.308) 

is not significant, just like in Model 2. 

<!------------------------------>
## Model 4d: Moderated Mediation Model - Path a and cprime
<!------------------------------>

```{r diag4d, fig.height = 4}
par(mfrow = c(1,2), mar=c(0,0,0,0), oma=c(0,0,0,0))
pmacroModel(8,labels=labels)
statisticalDiagram(8, labels=labels)
```

Model 4d is very similar to Model 4a, except that cprime path is also moderated. We'll still define the index of moderated mediation to be: 

* a3*b

```{r lm4d}
lm4d.syntax <- '
donate ~ b*justify + c1prime*frame + c2prime*skeptic + c3prime*skepxframe
justify ~ a1*frame + a2*skeptic + a3*skepxframe

# Define simple slopes and conditional indirect effects using :=

# index of moderated mediation

IndMedMod:= a3*b

# simple slope of justify on frame is a1+a3*skeptic
aLow: = a1+a3*(-1.78)
aMedian: = a1+a3*(-0.58)
aMean: = a1+a3*(0)
aHigh: = a1+a3*1.82

# conditional indirect effects is b*(a1+a3*skeptic)
abLow: = b*aLow
abMedian: = b*aMedian
abMean: = b*aMean
abHigh: = b*aHigh
'

set.seed(2022)
lm4d.fit = sem(lm4d.syntax, data = disaster, se = "bootstrap", bootstrap = 1000, fixed.x=FALSE, meanstructure = TRUE)
parameterEstimates(lm4d.fit, level = 0.95, boot.ci.type = "bca.simple")
```


Here we have two interaction coefficients:

* a3 = 0.201 (p = 0.001)
* c3prime = 0.015 (p = 0.839)

so that skeptic is a moderator for the frame-to-justify path (a path) but not a moderator for frame-to-donate path (cprime path). For the frame-to-justify path:

* aLow = -0.241 (p = 0.117)
* aMedian = 0 (p = 0.997)
* aMean = 0.117 (p = 0.307)
* aHigh = 0.483 (p = 0.004)

which are exactly the same as those in Model 4a. The simple slope aHigh is positive and aLow is negative. Those who are high on climate change skepticism think it's justified to withhold the aid whereas those who are low on the skepticism do not think it's justified to withhold the aid. 

* IndexOfModMed = -0.186 (p = 0.003)
* abLow = 0.222 (p = 0.127)
* abMedian = 0.000 (p = 0.997)
* abMean = -0.108 (p = 0.305)
* abHigh = -0.446 (p = 0.006)

which are close to those in Model 4a. The indirect effect of donate on frame through justify (ab path) is moderated by skeptic (IndexOfModMed is sig!). Moreover, abHigh is negative and abLow is positive, meaning that framing the disaster as caused by climate change leads to less donation for people who doubt climate change but it leads to more donation for people who believes it because they do not think it's justified to withhold the aid.


<!------------------------------>
## Model 4e: Moderated Mediation Model - Path b and cprime
<!------------------------------>

```{r diag4e, fig.height = 4}
par(mfrow = c(1,2), mar=c(0,0,0,0), oma=c(0,0,0,0))
pmacroModel(15,labels=labels)
statisticalDiagram(15, labels=labels)
```

Model 4e is very similar to Model 4b except that cprime path is also moderated. We'll still define the index of moderated mediation to be: 

* a\*b3 (actually, a\*b2 in this diagram)

Let's write the syntax for the moderated mediation model:

```{r lm4e}
lm4e.syntax <- '
donate ~ b1*justify + b2*skepxjusti + c1prime*frame + c2prime*skeptic + c3prime*skepxframe
justify ~ a*frame

# Define simple slopes and conditional indirect effects using :=

# index of moderated mediation

IndMedMod:= a*b2

# simple slope of donate on justify is b1+b2*skeptic
bLow: = b1+b2*(-1.78)
bMedian: = b1+b2*(-0.58)
bMean: = b1+b2*(0)
bHigh: = b1+b2*1.82

# conditional indirect effects is a*(b1+b2*skeptic)
abLow: = a*bLow
abMedian: = a*bMedian
abMean: = a*bMean
abHigh: = a*bHigh
'

set.seed(2022)
lm4e.fit = sem(lm4e.syntax, data = disaster, se = "bootstrap", bootstrap = 1000, fixed.x=FALSE, meanstructure = TRUE)
parameterEstimates(lm4e.fit, level = 0.95, boot.ci.type = "bca.simple")
```

Here we have two interaction coefficients:

* b2 = 0.007 (p = 0.258)
* c3prime = 0.009 (p = 0.905)

so that skeptic is not a moderator for the b path nor for the cprime path. For the simple slopes of b path:

* bLow = -0.937 (p = 0.000)
* bMedian = -0.929 (p = 0.000)
* bMean = -0.925 (p = 0.000)
* bHigh = -0.912 (p = 0.000)

which do not change much as their climate change skepticism change. Justification for withholding aid always leads to less donation. Skeptic is not an effective moderator. 

Let's look at the indirect effects: 

* IndexOfModMed = 0.001 (p = 0.850)
* abLow = -0.126 (p = 0.306)
* abMedian = -0.125 (p = 0.307)
* abMean = -0.124 (p = 0.307)
* abHigh = -0.122 (p = 0.312)

Similarly, skeptic is not a good moderator for the indirect effect given that IndexOfModMed is not significant and the indirect effects at high/low levels of skepticism do not differ much. 



<!------------------------------>
## Model 4f: Moderated Mediation Model - Path a and b 
<!------------------------------>

```{r diag4f, fig.height = 4}
par(mfrow = c(1,2), mar=c(0,0,0,0), oma=c(0,0,0,0))
pmacroModel(58,labels=labels)
statisticalDiagram(58, labels=labels)
```

When both a and b are moderated by the same moderator, we have:

* a = a1 + a3*skep
* b = b1 + b3*skep
* ab = (a1 + a3\*skep)\*(b1 + b3\*skep) = a1\*b1 + (a1\*b3+a3\*b1)\*skep + a3\*b3\*skep^2

So the indirect effect does not depend on the moderator in a linear way. 

We don't have a formal definition of index of moderated mediation in this scenario. If we are lucky, we might get both (a1\*b3+a3\*b1) and a3\*b3 to be significant...

Let's write the syntax for the moderated mediation model:

```{r lm4f}
lm4f.syntax <- '
donate ~ b1*justify + b2*skeptic + b3*skepxjusti + cprime*frame
justify ~ a1*frame + a2*skeptic + a3*skepxframe

# index of moderated mediation

IndMedMod1:= a1*b3+a3*b1
IndMedMod2:= a3*b3

# simple slope of justify on frame is a1+a3*skeptic
aLow: = a1+a3*(-1.78)
aMedian: = a1+a3*(-0.58)
aMean: = a1+a3*(0)
aHigh: = a1+a3*1.82

# simple slope of donate on justify is b1+b3*skeptic
bLow: = b1+b3*(-1.78)
bMedian: = b1+b3*(-0.58)
bMean: = b1+b3*(0)
bHigh: = b1+b3*1.82

# conditional indirect effects is a*(b1+b3*skeptic)
abLow: = aLow*bLow
abMedian: = aMedian*bMedian
abMean: = aMean*bMean
abHigh: = aHigh*bHigh
'

set.seed(2022)
lm4f.fit = sem(lm4f.syntax, data = disaster, se = "bootstrap", bootstrap = 1000, fixed.x=FALSE, meanstructure = TRUE)
parameterEstimates(lm4f.fit, level = 0.95, boot.ci.type = "bca.simple")
```

Here we have two interaction terms:

* a3 = 0.201 (p = 0.001)
* b3 = 0.008 (p = 0.743)

which means that skeptic is a moderator for the a path but not a moderator for the b path. 

As for the index of moderated mediation:

* IndMedMod1 = -0.185 (p = 0.003)
* IndMedMod2 = 0.002 (p = 0.741)

So IndMedMod1 is sig but IndMedMod2 is not (meh)... Let's examine the indirect effects at different levels: 

* abLow = 0.226 (p = 0.133)
* abMedian = 0.000 (p = 0.997)
* abMean = -0.108 (p = 0.304)
* abHigh = -0.438 (p = 0.006)

which does vary as a function of skepticism. So, we still have a significant moderated mediation in this model. 


<!------------------------------>
## Model 4g: Moderated Mediation Model - Path a, b, and cprime 
<!------------------------------>

```{r diag4g, fig.height = 4}
par(mfrow = c(1,2), mar=c(0,0,0,0), oma=c(0,0,0,0))
pmacroModel(59,labels=labels)
statisticalDiagram(59, labels=labels)
```

Let's write the syntax for the moderated mediation model:

```{r lm4g}
lm4g.syntax <- '
donate ~ b1*justify + b2*skepxjusti + c1prime*frame + c2prime*skeptic + c3prime*skepxframe
justify ~ a1*frame + a2*skeptic + a3*skepxframe

# index of moderated mediation

IndMedMod1:= a1*b2+a3*b1
IndMedMod2:= a3*b2

# simple slope of justify on frame is a1+a3*skeptic
aLow: = a1+a3*(-1.78)
aMedian: = a1+a3*(-0.58)
aMean: = a1+a3*(0)
aHigh: = a1+a3*1.82

# simple slope of donate on justify is b1+b2*skeptic
bLow: = b1+b2*(-1.78)
bMedian: = b1+b2*(-0.58)
bMean: = b1+b2*(0)
bHigh: = b1+b2*1.82

# conditional indirect effects is a*(b1+b2*skeptic)
abLow: = aLow*bLow
abMedian: = aMedian*bMedian
abMean: = aMean*bMean
abHigh: = aHigh*bHigh
'

set.seed(2022)
lm4g.fit = sem(lm4g.syntax, data = disaster, se = "bootstrap", bootstrap = 1000, fixed.x=FALSE, meanstructure = TRUE)
parameterEstimates(lm4g.fit, level = 0.95, boot.ci.type = "bca.simple")
```

Here we have interaction terms:

* a3 = 0.201 (p = 0.001)
* b2 = 0.007 (p = 0.797)
* c3prime = 0.009 (p = 0.905)

which means that skeptic is a moderator for the a path but not a moderator for the b path or the cprime path. 

As for the index of moderated mediation:

* IndMedMod1 = -0.185 (p = 0.003)
* IndMedMod2 = 0.001 (p = 0.797)

So IndMedMod1 is sig but IndMedMod2 is not (again)... Let's examine the indirect effects at different levels: 

* abLow = 0.226 (p = 0.134)
* abMedian = 0.000 (p = 0.997)
* abMean = -0.108 (p = 0.304)
* abHigh = -0.441 (p = 0.007)

which does vary as a function of skepticism. So, we still have a significant moderated mediation in this model. 

<!------------------------------>
## Conclusions
<!------------------------------>


* Although the total effect of frame on donation is not significant to begin with (in Model 1), it should not discourage you from looking for mediators and moderators on any of the paths. 
* In the simple mediation model (model 2), only b path is significantly negative, meaning that justification for withholding aid always leads to less donation regardless of the skepticism towards climate change. Although a path was not significant, again, it should not discourage you from looking for mediators and moderators on that a path. 
* Including a moderator skeptic for a path and testing the moderated mediation models in Model 4a-Model 4g showed that skeptic is only a moderator for the a path, meaning that those who are high on climate change skepticism think it's justified to withhold the aid whereas those who are low on the skepticism think it's not justified to withhold the aid. 
* Comparing Model 4a/4d/4f/4g (which all involve moderate a path), all the simple slopes and indirect effects of a path are more or less the same, and I recommend reported model 4g. 
* Our final conclusion is: a path was moderated by skepticism, b path was not moderated by skepticism but b path itself is significant, cprime was not moderated by skepticism. The indirect path ab was also moderated by skepticism. In particular, framing the disaster as caused by climate change (X) leads to less donation (Y) for people who doubt climate change (W_high) but it leads to more donation (Y) for people who believes it (W_low) because they do not think it's justified to withhold the aid (M). Ignoring this moderator leads to an insignificant mediation effect in Model 2. 

According to Hayes (2017, p. 439): 

"Climate change skeptics seem to feel that victims of a climate change induced disaster (compared to one not attributed to climate change) don’t deserve assistance, and this belief may translate into a reduced willingness to personally donate to the victims. This is a negative indirect effect. But among believers in climate change, the opposite effect is observed, with a climate change induced disaster leading believers to see the victims as more worthy of assistance than if the disaster wasn’t caused by climate change, and this is related to a greater willingness to donate. This is a positive indirect effect. Ignoring the contingency of the indirect effect by failing to include moderation by climate change skepticism in the mediation model obscures the conditional nature of the mechanism at work."




<!--chapter:end:07-MedModRLab.Rmd-->

# Week7_1: Lavaan Lab 5 One-factor CFA Model

In this lab, we will learn how to: 

+ Identify the One-factor CFA Model
+ Scale the One-factor CFA Model
+ Estimate the One-factor CFA Model
+ Interpret the One-factor CFA Model


## Data Prep

We will use cfaInClassData.csv in this lab. 

This is a simulated dataset based on Todd Little's positive affect example.

The hypothesis is that a latent variable ‘positive affect’ is measured by three indicators (glad, cheerful, and happy). 

Let's read this dataset in: 

```{r}
cfaData<- read.csv("cfaInclassData.csv", header = T)
```

and examine the dataset: 

```{r}
head(cfaData)
str(cfaData)
dim(cfaData) #n = 1000, 7 variables
```

Let's examine their means and standard deviations:

```{r}
round(apply(cfaData[,-1], 2, mean), 2) # mean-centered
round(apply(cfaData[,-1], 2, sd), 2) 
```

Let's call up the lavaan library and run some CFA's!

```{r}
library(lavaan)
```

<!------------------------------>
## PART I: One-Factor CFA, Fixed Loading
<!------------------------------>

### Fixed Loading, AKA Marker Variable method. 

FYI, the three equations for the three indicators are:

+ Glad = lambda1*posAffect(eta) + u1
+ Cheerful = lambda2*posAffect(eta) + u2
+ Happy = lambda3*posAffect(eta) + u3

Let's first follow the equations above and write the syntax (disturbances are automatically included): 

```{r, eval=FALSE}
mod1.wrong<- "
  glad ~ posAffect
  cheerful ~ posAffect
  happy ~ posAffect
"
fit1.wrong = lavaan::sem(model = mod1.wrong, data = cfaData, fixed.x=FALSE)
```

Oops - an error message! 

```{r,eval=FALSE}
Error in lav_data_full(data = data, group = group, cluster = cluster,  : 
  lavaan ERROR: missing observed variables in dataset: posAffect
```

This is because posAffect is a latent variable and we have to use =~ to define a latent variable: 

```{r, eval=FALSE}
mod1.wrong<-'
posAffect =~ Glad + Cheerful + Happy
'
fit1.wrong = lavaan::sem(model = mod1.wrong, data = cfaData, fixed.x=FALSE)
```

```{r,eval=FALSE}
Error in lavaan::lavaan(model = mod1.wrong, data = cfaData, fixed.x = FALSE,  : 
  lavaan ERROR: missing observed variables in dataset: Glad Cheerful Happy
```

Error, why? 

The variable names in the model syntax have to match the column names EXACTLY, even the letter cases. 

Let's try again: 

```{r}
mod1<-'
posAffect =~ glad + cheerful + happy
'
```

Let's explain the lavaan model syntax!

+ mod1 is used to name our model. 
+ Since posAffect is a latent variable (it's not in the data), we cannot follow the equations above and write syntax like glad ~ posAffect
+ Instead, we specify a CFA measurement model in mod1.
+ NEW SYNTAX ALERT: Using =~ means "manifested by"
+ In the code above we can see that our latent construct 'posAffect' is manifested by glad, cheerful, and happy
+ By default, the loading of glad is fixed at 1 (Fixed Loading Method)

Next we name the fitted object 'fit1' to see our output. 

```{r}
fit1 = lavaan::sem(mod1, data = cfaData, fixed.x=FALSE)
```

This summary will show us the loadings (I also requested standardized results):

```{r}
summary(fit1, standardized = T)
```

```{r, eval=FALSE}
df = 0 (why?)

Latent Variables:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
  posAffect =~                                                          
    glad              1.000                               0.693    0.705
    cheerful          1.117    0.059   18.782    0.000    0.774    0.787
    happy             1.066    0.057   18.786    0.000    0.739    0.757
```

What does this mean?

+ 1 unit change in posAffect produces:
  * 1-unit change in "glad" (marker indicator)
  * 1.117-unit change in "cheerful" (1.117 times greater than the effect on "glad")
  * 1.066-unit change in "happy" (1.066 times greater than the effect on "glad")

```{r, eval=FALSE}
Variances:
Unique factor variances:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
   .glad              0.485    0.030   16.238    0.000    0.485    0.503
   .cheerful          0.367    0.030   12.062    0.000    0.367    0.380
   .happy             0.407    0.030   13.751    0.000    0.407    0.427
```

+ The leftover unique factor variances remain substantial
+ Meaning that none of the indicators is a perfect measure of posAffect
+ but they all contribute significantly to the measurement of posAffect (the standardized loadings above larger than 0.6)

Followed by the latent factor variance.
```{r, eval=FALSE}
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
    posAffect         0.480    0.043   11.270    0.000    1.000    1.000
```

### Change marker indicator

If you'd like to fix the 2nd loading to 1:

```{r}
mod1b_wrong<-'
posAffect =~ glad + 1*cheerful + happy
'
```

won't work. 

You will get something like this:

```{r,eval=FALSE}
Latent Variables:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
  posAffect =~                                                          
    glad              1.000                               0.734    0.733
    cheerful          1.000                               0.734    0.759
    happy             1.009    0.046   22.052    0.000    0.741    0.759
```

You'll have to change the order of the indicators to move cheerful to the front of the variable list: 

```{r}
mod1b<-'
posAffect =~ cheerful + glad + happy
'
```

Or use \*NA to specify which loading to keep free and use *1 to specify the marker variable whose loading to be fixed at 1

```{r}
mod1b<-'
posAffect =~ NA*glad + 1*cheerful + NA*happy
'
```

Here we named the fitted object 'fit1b' to see our output. 

```{r}
fit1b = lavaan::sem(mod1b, data = cfaData, fixed.x=FALSE)
summary(fit1b, standardized = T)
```

+ The loadings can be obtained by dividing those in fit1 by 1.117 (i.e., they change proportionally).
+ The variances of unique factors and latent factor remain unchanged. 

<!------------------------------>
## PART II: One-Factor CFA, Fixed Factor Variance
<!------------------------------>

### Fixed Factor Method

Keep using the same syntax but assign a new name mod2: 

```{r}
mod2<-'
posAffect =~ glad + cheerful + happy
'
```

To fix the variance of the latent variable to 1, add std.lv=T to sem() function: 

```{r}
fit2<-lavaan::sem(mod2, data = cfaData, fixed.x=FALSE, std.lv=T)
summary(fit2, standardized = TRUE)
```

```{r, eval=FALSE}
Latent Variables:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
  posAffect =~                                                          
    glad              0.693    0.031   22.540    0.000    0.693    0.705
    cheerful          0.774    0.031   25.233    0.000    0.774    0.787
    happy             0.739    0.030   24.226    0.000    0.739    0.757
```

+ 1-SD change in the factor (posAffect) causes:
  * 0.693-unit change in glad (on its raw scale)
  * 0.774-unit change in cheerful (on its raw scale)
  * 0.739-unit change in happy (on its raw scale)

```{r, eval=FALSE}
Variances:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
   .glad              0.485    0.030   16.238    0.000    0.485    0.503
   .cheerful          0.367    0.030   12.062    0.000    0.367    0.380
   .happy             0.407    0.030   13.751    0.000    0.407    0.427
    posAffect         1.000                               1.000    1.000
```

+ We see that posAffect now has variance (=sd) of 1
+ All loadings were freely estimated, no loading is 1.
+ and the unique factor variances are the same as before

<!------------------------------>
## Exercise: One-factor CFA Model
<!------------------------------>

Could you use the indicators satisfied, content, and comfortable to build a one-factor CFA model to measure a latent variable called Satisfaction? 

Use the Fixed Loading and the Fixed Factor Methods and compare their estimates. 

### Fixed Loading

```{r}

```

### Fixed Factor

```{r}

```


<!--chapter:end:08-CFA1.Rmd-->

# Week8_1: Lavaan Lab 6 Two-factor CFA Model


## Data Prep

We will continue to use cfaInClassData.csv in this lab. 

Let's read this dataset in: 

```{r}
cfaData<- read.csv("cfaInclassData.csv", header = T)
```

Load up the lavaan library and run some CFA's!

```{r}
library(lavaan)
```

<!------------------------------>
## PART I: Two-Factor CFA, Fixed Loading
<!------------------------------>

### Fixed Loading, AKA Marker Variable method. 

Let's write up the model syntax for the measurement model with two factors:

```{r}
fixedIndTwoFacSyntax <- "
	#Factor Specification	
	posAffect    =~    glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable
"
```

Here we named the fitted object 'fixedIndTwoFacRun' to see our output: 

```{r}
fixedIndTwoFacRun = lavaan::sem(model = fixedIndTwoFacSyntax, data = cfaData, fixed.x=FALSE)
```

Get a summary using summary() function, add standardized=T to request standardized parameter estimates: 

```{r}
summary(fixedIndTwoFacRun, standardized=T)
```

Here is the fun part. Plot the fitted model using semPaths() function from the semPlot package: 

```{r}
library(semPlot)
semPaths(fixedIndTwoFacRun)
semPaths(fixedIndTwoFacRun, what = 'est') # under "Estimate"
```

```{r, eval=FALSE}
df = 8 (why?)

Latent Variables:
                     Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
  posAffect =~                                        
     glad              1.000                               0.694    0.706
     happy             1.067    0.055   19.294    0.000    0.740    0.758
     cheerful          1.112    0.057   19.458    0.000    0.772    0.785
   satisfaction =~                                                       
     satisfied         1.000                               0.773    0.767
     content           1.068    0.052   20.525    0.000    0.826    0.762
     comfortable       0.918    0.045   20.336    0.000    0.709    0.746
```

What does this mean?

+ 1 unit change in posAffect (factor) produces:
  * 1-unit change in "glad" (marker indicator)
  * 1.067-unit change in "happy" (1.067 times greater than the effect on "glad")
  * 1.112-unit change in "cheerful" (1.112 times greater than the effect on "glad")

+ 1 unit change in satisfaction (factor) produces:
  * 1-unit change in "satisfied" (marker indicator)
  * 1.068-unit change in "content" (1.068 times greater than the effect on "satisfied")
  * 0.918-unit change in "comfortable" (0.918 times greater than the effect on "satisfied")

```{r, eval=FALSE}
Variances:
                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
    .glad              0.484    0.029   16.647    0.000    0.484    0.501
    .happy             0.405    0.028   14.389    0.000    0.405    0.425
    .cheerful          0.371    0.029   13.004    0.000    0.371    0.384
    .satisfied         0.419    0.029   14.326    0.000    0.419    0.412
    .content           0.491    0.034   14.542    0.000    0.491    0.419
    .comfortable       0.400    0.026   15.315    0.000    0.400    0.443
```

+ The leftover unique factor variances remain substantial
+ Meaning that none of the indicators is a perfect measure of posAffect or satisfaction
+ but they all contribute significantly to the measurement of latent variables (the standardized loadings above larger than 0.6)

Followed by two factor variances:
```{r, eval=FALSE}
                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
     posAffect         0.482    0.042   11.439    0.000    1.000    1.000
     satisfaction      0.597    0.047   12.686    0.000    1.000    1.000
```

+ which were freely estimated using Fixed Loading scaling method. 
+ Both posAffect and satisfaction are variable across participants (sig* according to p-values)
+ posAffect seems to be more stable than satisfaction (0.482<0.597). 

```{r, eval=FALSE}
Covariances:
                  Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
 posAffect ~~                                                          
   satisfaction      0.262    0.025   10.284    0.000    0.488    0.488
```

+ covariance between posAffect and satisfaction is 0.262
+ standardized covariance (correlation) between posAffect and satisfaction is 0.488 (sig*)
+ 0.262/sqrt(0.482)/sqrt(0.597) = 0.488
+ posAffect is positively correlated with satisfaction. Participants who have a high level posAffect tend to have a high level of satisfaction. 

### How well does this model fit to the data? 

The model-implied variance of glad is the sum of:

+ Tracing 1: lam1\*psi1\*lam1 = 1.0\*0.482\*1.0 = 0.482
+ Tracing 2: sig2_u1 = sig2_glad = 0.484

which is 0.966. 

What is the sample variance of glad? 

+ var(cfaData$glad) = 0.9664733, which is super close to the model-implied one! 
+ meaning our CFA model is doing a pretty good job at explaining the sample variance of glad. 

The proportion of variance of glad explained by posAffect is: 

+ Tracing 1 / (Tracing 1+Tracing 2) = 49.9%
+ Unexplained: 50.1%

[Exercise] What about the model-implied variance of comfortable? 

+ Tracing 1: 0.918\*.597\*.918 = .503
+ Tracing 2: .400
+ Total .903
+ Proportion of variance explained: .503/.903
+ Sample var: var(cfaData$comfortable) = 0.904

[Exercise] What about the model-implied covariance between glad and comfortable? (e.g., cov(y1, y6))

+ Tracing 1: 1\*.262\*.918 = .241
+ Sample cov: cov(cfaData$glad, cfaData$comfortable) = .230

Overall speaking, how is our model doing at explaining the sample covariance matrix? 
Remember the fitted() function we used during path analysis R labs?

Apply fitted() function to the fitted object fixedIndTwoFacRun (not on the model syntax fixedIndTwoFacSyntax!!):

```{r}
fitted(fixedIndTwoFacRun)
Sigma <- fitted(fixedIndTwoFacRun)$cov
```

How close is Sigma to S? 

+ Rearrange the rows and columns of Sigma (important!) and take the difference between Sigma and S

```{r}
(S = cov(cfaData[,-1]))

diff = Sigma[colnames(S), colnames(S)] - S
round(diff, 3)

print(paste0("The difference between S and Sigma ranged between ", round(min(diff),4), " and ", round(max(diff),4), "."))
```

This is the closest Sigma can get to S. Any other set of parameter estimates would yield bigger differences with S. 

Have you wondered about how we obtain the parameter estimates in the output?

Estimation down the road...

### Fundamental Equation of SEM

Just some bonus stuff...

You can inspect the fitted object using inspect() and save the object as InspFit1. 

```{r}
InspFit1 <- inspect(fixedIndTwoFacRun, what = "est")
```

Extract Lambda matrix from InspFit1. 

```{r}
Lambda <- InspFit1$lambda
Lambda
```

Extract Psi matrix from InspFit1. 

```{r}
Psi <- InspFit1$psi
Psi
```

Extract Theta matrix from InspFit1. 

```{r}
Theta <- InspFit1$theta
Theta
```

Use the three matrices above to calculate the model-implied covariance matrix and save is as SIGMA: 

```{r}
SIGMA <- Lambda%*%Psi%*%t(Lambda)+Theta
```

A shortcut function to obtain the SIGMA matrix is to use fitted() function, as shown above...

```{r}
all.equal(Sigma, SIGMA)
```

### Interpretion

How do I interpret the results? 

+ (1) Introduce the scaling method I used;
+ (2) Based on the loadings, acknowledge that the indicators are not perfect measures of the latent factors, but they all contribute significantly to the measurement of latent factors (the standardized loadings above larger than 0.6);
+ (3) Report the the proportions of variance explained on each indicator;
+ (4) Describe the discrepancy between S and Sigma (where the main differences lie, and whether the differences are concerning);
+ (5) Interpret the correlation among the latent factors (size, sign, positive/negative, sig/non-sig). 


### Standardized solutions: Std.lv vs. Std.all

Std.lv: 

+ This is the solution you'll get using Fixed Factor Variance Scaling Method;
+ All factor variances are fixed as 1.0;
+ Factor covariance is the same as factor correlation;
+ All factor loadings are freely estimated so that the model-implied covariance matrix remains the same;
+ All unique factor variances remain unchanged. 

For example, under Std.lv, the model-implied variance of glad is the sum of:

+ Tracing 1: lam1\*psi1\*lam1 = 0.694\*1.0\*0.694 = 0.482
+ Tracing 2: sig2_u1 = sig2_glad = 0.484
+ Proportion of variance explained: 0.482/0.966 = 50.1%

which is still 0.966. 

[Exercise] Why is 0.709 the loading of comfortable under Std.lv? 

Under Std.lv, the model-implied variance of comfortable is the sum of:

+ Tracing 1: 
+ Tracing 2: 
+ Proportion of variance explained: 


Std.all:

+ All factor variances are fixed as 1.0;
+ Factor covariance is the same as factor correlation;
+ All factor loadings and unique factor variances are re-estimated so that the model-implied variances of indicators are all 1.0;

For example, under Std.all, the model-implied variance of glad is the sum of:

+ Tracing 1: lam1\*psi1\*lam1 = 0.706\*1.0\*0.706 = 0.499
+ Tracing 2: sig2_u1 = sig2_glad = 0.501

which add to 1.0. 

[Exercise] Why is 0.746 the loading of comfortable under Std.all? 

Under Std.all, the model-implied variance of comfortable is the sum of:

+ Tracing 1: 
+ Tracing 2: 


Why the hassle? 

+ The solution is fully standardized so that squaring Std.all loadings is equivalent to the proportion of variance explained: 
+ 0.706\*0.706 (std.all)
+ 1.0\*0.482\*1.0/0.966 (fixed loading)
+ 0.694\*1.0\*0.694/0.966 (fixed variance; std.lv)
+ = 49.9%


<!------------------------------>
## PART II: Two-Factor CFA, Fixed Factor Variance
<!------------------------------>

### Fixed Factor Method

Keep using the same syntax but assign a new name: 

```{r}
fixedFacTwoFacSyntax <- "
	#Factor Specification	
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable
"
```

To fix the variance of the latent variable to 1, add std.lv=T to sem() function: 

```{r}
fixedFacTwoFacRun = lavaan::sem(model = fixedFacTwoFacSyntax, 
                        data = cfaData, 
                        fixed.x=FALSE, 
                        std.lv=T)
```

Get a summary using summary() function, add standardized=T to request standardized parameter estimates 

```{r}
summary(fixedFacTwoFacRun, standardized=T)
```


```{r, eval=FALSE}
 df = 8  # same!

Latent Variables:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
  posAffect =~                                                          
    glad              0.694    0.030   22.878    0.000    0.694    0.706
    happy             0.740    0.030   24.806    0.000    0.740    0.758
    cheerful          0.772    0.030   25.798    0.000    0.772    0.785
  satisfaction =~                                                       
    satisfied         0.773    0.030   25.373    0.000    0.773    0.767
    content           0.826    0.033   25.207    0.000    0.826    0.762
    comfortable       0.709    0.029   24.584    0.000    0.709    0.746
```

+ 1-SD change in the factor (posAffect) causes:
  * 0.694-unit change in glad (on its raw scale)
  * 0.740-unit change in happy (on its raw scale)
  * 0.772-unit change in cheerful (on its raw scale)

+ 1-SD change in the factor (satisfaction) causes:
  * 0.773-unit change in satisfied (on its raw scale)
  * 0.826-unit change in content (on its raw scale)
  * 0.709-unit change in comfortable (on its raw scale)

```{r, eval=FALSE}
 Covariances:
                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
   posAffect ~~                                                          
     satisfaction      0.262    0.025   10.284    0.000    0.488    0.488

Variances:
                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
    .glad              0.484    0.029   16.647    0.000    0.484    0.501
    .happy             0.405    0.028   14.389    0.000    0.405    0.425
    .cheerful          0.371    0.029   13.004    0.000    0.371    0.384
    .satisfied         0.419    0.029   14.326    0.000    0.419    0.412
    .content           0.491    0.034   14.542    0.000    0.491    0.419
    .comfortable       0.400    0.026   15.315    0.000    0.400    0.443
```

remain unchanged. 

Followed by two factor variances.

```{r, eval=FALSE}
                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
    posAffect         1.000                               1.000    1.000
    satisfaction      1.000                               1.000    1.000
```


<!--chapter:end:09-CFA2.Rmd-->

# Week8_2: Lavaan Lab 7 Two-factor SR Model


## Data Prep

Again, we use cfaInClassData.csv in this lab 

Let's read this dataset in: 

```{r}
cfaData<- read.csv("cfaInclassData.csv", header = T)
```

Load up the lavaan library: 

```{r}
library(lavaan)
```

<!------------------------------>
## PART I: Two-Factor SR, Fixed Loading
<!------------------------------>

### Fixed Loading, AKA Marker Variable method. 

Let's write up the model syntax for the structural regression (SR) model with two factors:

```{r}
srSyntax <- "
	#Factor Specification	
	posAffect =~ glad + cheerful + happy  
	satisfaction =~ satisfied + content + comfortable 
	
	#Structural Regression!
	satisfaction ~ posAffect
"
```

Here we named the fitted object 'srRun' to see our output: 

```{r}
srRun = lavaan::sem(model = srSyntax, 
                    data = cfaData, 
                    fixed.x=FALSE)
```

Get a summary using summary() function, add standardized=T to request standardized parameter estimates:

```{r}
summary(srRun, standardized = T)
```

The above syntax reproduces the SR analysis from the class slides.

+ CFA part under "Latent Variables" remains unchanged
+ "Covariances" section no longer exists
+ satisfaction is also removed under "Variances"

Instead, in the Regressions section: 

```{r,eval=FALSE}
Regressions:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
  satisfaction ~                                                        
    posAffect         0.544    0.047   11.490    0.000    0.488    0.488
```

returns the regression slope of posAffect (b = 0.544). One-unit change in posAffect is leading to one-unit change in satisfaction. 

```{r,eval=FALSE}
Variances:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
   .satisfaction      0.455    0.038   11.869    0.000    0.762    0.762
```

returns the disturbance variance of satisfaction (sigma_(d_2)^2, not psi_2!)


<!------------------------------>
## PART II: Two-Factor SR, Fixed Factor Variance
<!------------------------------>

### Fixed Factor Method

Here we named the fitted object 'srRun2'. 

We add std.lv=T to fix all latent factor variances to 1: 

```{r}
srRun2 = lavaan::sem(model = srSyntax, 
            data = cfaData, 
            fixed.x=FALSE,
            std.lv=T)
summary(srRun2, standardized = T)
```

This doesn't work as expected, why?

Therefore, for SR models, we should always go with fixed loading scaling approach. 



<!------------------------------>
## PART III: Exercise (what fun!): 3-Factor SR Model
<!------------------------------>

Suppose that in a 3-factor SR model: 

+ Positive Affect is measured by Happy and Cheerful
+ Satisfaction is measured by Satisfied and Content
+ Pleasure is measured by Glad and Comfortable
+ Satisfaction is predicted by both Positive Affect and Pleasure

Can you use cfaData to fit such a model? 

```{r}

```


<!--chapter:end:10-SR.Rmd-->

# Week8_2: Lavaan Lab 8 Estimation Methods


In this lab, we will learn how to estimate parameters in CFA/SR models. 

Load up the lavaan library: 

```{r}
library(lavaan)
```

<!------------------------------>
## PART I: Hypothetical Example
<!------------------------------>

### One-factor CFA model

A made-up sample covariance matrix with n = 200:

```{r}
n = 200
S_3fac = matrix(c(5, 2, 3.5, 2, 3, 2, 3.5, 2, 6), 3, 3, 
                dimnames = list(c('Y1', 'Y2', 'Y3'), c('Y1', 'Y2', 'Y3')))
S_3fac
```
Fit a one-factor CFA to the sample covariance matrix:

```{r}
one_fac_syntax <- "
	eta =~ Y1 + Y2 + Y3
"
```

Request Unweighted Least Squares (ULS):

```{r}
one_fac_fit2 <- lavaan::sem(one_fac_syntax, 
                    sample.cov = S_3fac, 
                    sample.nobs = n, 
                    estimator = "ULS", 
                    fixed.x = FALSE)

summary(one_fac_fit2, standardized = T)
```

Sigma:

```{r}
fitted(one_fac_fit2)$cov
```

```{r}
Sigma = fitted(one_fac_fit2)$cov
diff = Sigma[colnames(S_3fac), colnames(S_3fac)] - S_3fac
round(diff,3)
```
all zeros. Meaning that Sigma = S.


<!------------------------------>
## PART II: ULS on the Positive Affect Example
<!------------------------------>

Let's read this dataset in: 

```{r}
cfaData<- read.csv("cfaInclassData.csv", header = T)
```

Fit a two-factor CFA model: 

```{r}
fixedIndTwoFacSyntax <- "
	#Factor Specification	
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable
"
```

```{r}
two_fac_fit_uls <- lavaan::sem(fixedIndTwoFacSyntax, 
                       data = cfaData, 
                       fixed.x = FALSE,
                       estimator = "ULS")

summary(two_fac_fit_uls, standardized = T)
```

Sigma:

```{r}
S = cov(cfaData[,-1])
Sigma = fitted(two_fac_fit_uls)$cov[colnames(S), colnames(S)]
diff = Sigma - S
round(diff,3)

print(paste0("The difference between S and Sigma ranged between ", round(min(diff),4), " and ", round(max(diff),4), "."))
```
Sigma is not the same as S, but close. 

The sum of squared differences is:

```{r}
sum(diff[lower.tri(diff,diag = T)]^2)
```



<!------------------------------>
## PART III: Calculate ULS test statistic manually
<!------------------------------>

ULS test statistic is calculated as:

```{r}
T_uls = (1000-1)*sum(diff[lower.tri(diff,diag = T)]^2)
T_uls
```

One can also obtain vectors of S and Sigma first: 

```{r}
s = lav_matrix_vech(S)
sigma = lav_matrix_vech(Sigma)
```

and calculate the ULS test statistic: 

```{r}
T_uls = (1000-1)*sum((s - sigma)^2)
T_uls
```
+ No p-value for ULS test statistic
+ as there is no known distribution for this test statistic
+ i.e., no suitable method for model fit evaluation



<!------------------------------>
## PART IV: ML vs ULS vs WLS
<!------------------------------>

### ML Estimation

```{r}
two_fac_fit_ml <- lavaan::sem(fixedIndTwoFacSyntax, 
                       data = cfaData, 
                       fixed.x = FALSE,
                       estimator = "ML")
```

### WLS Estimation

```{r}
two_fac_fit_wls <- lavaan::sem(fixedIndTwoFacSyntax, 
                      data = cfaData, 
                      fixed.x = FALSE,
                      estimator = "WLS")
```

### Compare the parameter estimates

```{r}
coefTable = parameterEstimates(two_fac_fit_ml)[,1:3]
coefTable = cbind(coefTable, 
                  ML = parameterEstimates(two_fac_fit_ml)$est, 
                  ULS = parameterEstimates(two_fac_fit_uls)$est, 
                  WLS = parameterEstimates(two_fac_fit_wls)$est)
coefTable
```



<!------------------------------>
## PART V: Improper Solutions
<!------------------------------>

Going back to the 1-factor toy example...

Suppose we have a new covariance matrix now: 

```{r}
S_3fac_new = matrix(c(5, 1, 3.5, 1, 3, 2, 3.5, 2, 6), 3, 3, 
                    dimnames = list(c('Y1', 'Y2', 'Y3'), c('Y1', 'Y2', 'Y3')))
S_3fac_new
```

The one-factor syntax is still:

```{r}
one_fac_syntax <- "
	eta =~ Y1 + Y2 + Y3
"
```

ML Estimation:

```{r}
one_fac_fit_new <- lavaan::sem(one_fac_syntax, 
                    sample.cov = S_3fac_new, 
                    sample.nobs = n, 
                    estimator = "ML", 
                    fixed.x = FALSE)
```

+ lavaan WARNING: some estimated ov variances are negative
+ negative residual variances
+ ULS doesn't help either

```{r}
summary(one_fac_fit_new, standardized = T)
```

Label and constraint sig3 to be larger than 0:

```{r}
one_fac_syntax_const <- "
	eta =~ Y1 + Y2 + Y3
	
	Y3~~sig3*Y3
	# constraints
	sig3 > 0
"
```

ML Estimation:

```{r}
one_fac_fit_new2 <- lavaan::sem(one_fac_syntax_const, 
                       sample.cov = S_3fac_new, 
                       sample.nobs = n, 
                       fixed.x = FALSE)
summary(one_fac_fit_new2, standardized = T)
```

<!--chapter:end:11-Estimation.Rmd-->

# Week10_2: Lavaan Lab 9 Model Fit Part I (Test Statistics)


In this lab, we will learn: 

+ how to calculate and interpret chi-square statistics for SEM models.
+ how to compare nested models using chi-square difference test. 

Load up the lavaan and semPlot libraries: 

```{r}
library(lavaan)
library(semPlot)
```

<!------------------------------>
## PART I: Robust ML on the Positive Affect Example
<!------------------------------>

Let's read this dataset in: 

```{r}
cfaData<- read.csv("cfaInclassData.csv", header = T)
```

Write out syntax for a two-factor CFA model: 

```{r}
fixedIndTwoFacSyntax <- "
	#Factor Specification	
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable
"
```

Fit the model regularly:

```{r}
fixedIndTwoFacRun = lavaan::sem(model = fixedIndTwoFacSyntax, 
                        data = cfaData, 
                        fixed.x=FALSE)

fixedIndTwoFacRun
```
+ Model chi_sq: misfit defined through the likelihood ratio.
+ T_ML = 2.957
+ df_ML = 8
+ pvalue_ML = 0.937
+ Since pvalue_ML > 0.05, this model does not have significant model misfit. 

### Mean corrected statistic (T_M)

Satorra and Bentler (1994, 2001) proposed two robust corrections for non-normally distributed data: 

```{r}
two_fac_fit_M <- lavaan::sem(fixedIndTwoFacSyntax, 
                     data = cfaData, 
                     fixed.x=FALSE,
                     estimator = "MLM")

two_fac_fit_M
```

+ T_M = 2.891
+ df_M = 8
+ pvalue_M = 0.941

### Mean and variance adjusted statistic (T_MV)

+ estimator = "MLMVS" returns the Mean- and variance adjusted statistic with an updated degrees of freedom (recommended)
+ estimator = "MLMV" returns another version of Mean- and variance adjusted statistic but does not change the degrees of freedom 

```{r}
two_fac_fit_MV <- lavaan::sem(fixedIndTwoFacSyntax, 
                      data = cfaData, 
                      fixed.x=FALSE,
                      estimator = "MLMVS")

#summary(two_fac_fit_MV, standardized = T)
two_fac_fit_MV
```

+ T_MV = 2.842
+ df_MV = 7.864
+ pvalue_MV = 0.939

Please see a complete list of estimators here: http://lavaan.ugent.be/tutorial/est.html

### Yuan-Bentler test statistic (T_MLR)

Just like T_M and T_MV, T_MLR also corrects for nonnormality. Since MLR works for both complete and incomplete data, T_MLR is more popular in practice:

```{r}
two_fac_fit_MLR <- lavaan::sem(fixedIndTwoFacSyntax, 
                      data = cfaData, 
                      fixed.x=FALSE,
                      estimator = "MLR")

two_fac_fit_MLR
```
+ T_MLR = 2.897
+ df_MLR = 8
+ pvalue_MLR = 0.941

### Small sample correction - F test

```{r}
F_ratio = 2.957/8
```

referred to an F(df, N-1) distribution:

```{r}
?pf
p_val_F = 1-pf(F_ratio, 8, 1000-1)
p_val_F
```

which is very similar to the three p-values given above given a large sample size in this study N = 1000. 

<!------------------------------>
## PART II: Nested Model Comparison
<!------------------------------>

We can compare the fit of the two-factor model to that of a one-factor model because the one-factor model is nested in the two-factor model. 

### One-factor model

```{r}
OneFacSyntax <- "
	#Factor Specification	
	eta1 =~ glad + happy + cheerful + satisfied + content + comfortable  
"

one_fac_fit = lavaan::sem(model = OneFacSyntax, 
                  data = cfaData, 
                  fixed.x=FALSE) 
```

request standardized = T to check standardized loadings - item reliability

```{r}
summary(one_fac_fit, standardized = T)
```

+ Only the last three standardized loadings are larger than 0.6
+ The first three indicators are not reliable indicators of the new latent variable eta1

```{r,eval=FALSE}
Model Test User Model:

  Test statistic                               592.661
  Degrees of freedom                                 9
  P-value (Chi-square)                           0.000
```

+ The chi-square statistic is very large and significant for this one-factor model...poor fit

### Plotting

```{r}
semPaths(fixedIndTwoFacRun, what = "std", fade= F)
semPaths(one_fac_fit, what = "std", fade= F)
```

### Comparing Nested Models

+ The one-factor model is nested in the two-factor model. 
+ The fit of the one-factor model is worse than the two-factor model, but is it significantly worse? 
+ Here we use anova() function to perform chi-square difference test
+ Note that the order of the models in anova() doesn't matter 

```{r}
anova(one_fac_fit, fixedIndTwoFacRun)
```

```{r,eval=FALSE}
Chi-Squared Difference Test

                  Df   AIC   BIC    Chisq Chisq diff Df diff Pr(>Chisq)    
fixedIndTwoFacRun  8 14992 15056   2.9575                                  
one_fac_fit        9 15580 15639 592.6611      589.7       1  < 2.2e-16 ***
 ---
 Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

+ The model on top is the base model and the model at the bottom is the restricted model.
+ The restricted model always fits worse than the base model. 
+ Chisq diff = 589.7; Df diff = 1; p-value < 0.001
+ Chisq diff is sig: one-factor fits **significantly** worse than the two-factor model and we should endorse two-factor model 

<!------------------------------>
## PART III: Exercises: More Nested Models
<!------------------------------>

Your turn now, Have fun! 

### Exercises: Compare the base model (fixedIndTwoFacRun) to

+ (Model 2) 2-factor CFA model with orthogonal latent variables
+ (Model 3) 2-factor CFA model with a cross-loading from posAffect to satisfied
+ (Model 4) 2-factor CFA model with a correlation between unique factors u1 and u4

### Model 2: Orthogonal Factors

```{r}
OrthFacSyntax <- "
	#Factor Specification	
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable
	
	#Orthogonal Factors: no covariance 
	posAffect ~~ 0*satisfaction
"
```

Fit Model 2: 

```{r}
OrthFac_fit <- lavaan::sem(model = OrthFacSyntax, 
                   data = cfaData, 
                   fixed.x = F)
```

Plot Model 2: 

```{r}
semPaths(OrthFac_fit, what = "std", fade= F)
```

chi-square difference test:

```{r}
anova(fixedIndTwoFacRun, OrthFac_fit)
```

+ Chisq diff = 165.52; Df diff = 1; p-value < 0.001
+ Chisq diff is sig: the two-factor model with orthogonal latent variables fits **significantly** worse than the model with correlated latent variables. 
+ We should endorse the base two-factor model with correlated latent variables. 


### Model 3: Cross loading

```{r}
CrossLoadingSyntax <- "
	#Factor Specification	
	# cross loading: satisfied load on both latent variables
	# try to avoid using satisfied as the marker variable
	posAffect =~ glad + satisfied + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable
"
```

Fit Model 3: 

```{r}
CrossLoading_fit <- lavaan::sem(model = CrossLoadingSyntax, 
                                data = cfaData, fixed.x = F)
```

Plot Model 3: 

```{r}
semPaths(CrossLoading_fit, what = "std", fade= F)
```

chi-square difference test:

```{r}
anova(fixedIndTwoFacRun, CrossLoading_fit)
```

+ Chisq diff = 0.052477; Df diff = 1; p-value = 0.8188
+ Chisq diff is not sig: the two-factor model without the cross-loading is **NOT** significantly worse than the model with the cross-loading. 
+ The cross-loading is not necessary. 
+ We should endorse the base two-factor model without the cross-loading. 


### Model 4: Correlated Unique Factors

```{r}
CorrUniSyntax <-"
	#Factor Specification	
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable

  # correlated error 
	glad ~~ satisfied
"
```

Fit Model 4: 

```{r}
CorrUni_fit <- lavaan::sem(model= CorrUniSyntax, 
                           data = cfaData, fixed.x = F)
```

Plot Model 4: 

```{r}
semPaths(CorrUni_fit, what = "std", fade= F)
```

chi-square difference test:

```{r}
anova(fixedIndTwoFacRun, CorrUni_fit)
```

+ Chisq diff = 1.3232; Df diff = 1; p-value = 0.25
+ Chisq diff is not sig: the two-factor model without the correlated unique factors is **NOT** significantly worse than the model with the correlated unique factors. 
+ The correlation between u1 and u4 is not necessary. 
+ We should endorse the base two-factor model without the correlated unique factors.



<!--chapter:end:12-Model_Fit_1.Rmd-->

# Week11_1: Lavaan Lab 10 Model Fit Part II (Fit Indices)


In this lab, we will learn: 

+ how to calculate and interpret global fit indices for SEM models.
+ how to compare non-nested models using AIC and BIC. 

Load up the lavaan library:

```{r}
library(lavaan)
```

<!------------------------------>
## PART I: Fit Indices
<!------------------------------>

Let's read this dataset in: 

```{r}
cfaData<- read.csv("cfaInclassData.csv", header = T)
```

Write out syntax for a two-factor CFA model: 

```{r}
fixedIndTwoFacSyntax <- "
	#Factor Specification	
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable
"
```

Fit the model regularly:

```{r}
fixedIndTwoFacRun = lavaan::sem(model = fixedIndTwoFacSyntax, 
                        data = cfaData, 
                        fixed.x=FALSE)
```

Request fit indices by adding fit.measures = T in the summary() function:

```{r}
summary(fixedIndTwoFacRun, standardized = T, fit.measures = T)
```

### RMSEA

```{r, eval=FALSE}
Root Mean Square Error of Approximation:

  RMSEA                                          0.000
  90 Percent confidence interval - lower         0.000
  90 Percent confidence interval - upper         0.009
  P-value RMSEA <= 0.05                          1.000
```

reproducing RMSEA: 

+ T = 2.957
+ df = 8
+ N = 1000
+ RMSEA = sqrt(max(T-df,0)/(N-1)/df) = sqrt(max(2.957-8,0)/(1000-1)/8) = 0


### SRMR

```{r, eval=FALSE}
Standardized Root Mean Square Residual:

  SRMR                                           0.007
```

reproducing SRMR: 

```{r}
S = cov(cfaData[,-1])
colnames = colnames(S)
SIGMA = fitted(fixedIndTwoFacRun)$cov[colnames, colnames]
p = ncol(S)

# use cov2cor() function to convert diff to a correlation matrix and standardize the residuals: 

resd = cov2cor(S) - cov2cor(SIGMA)

# keep only the nonduplicated elements:

resd2 = lav_matrix_vech(resd)

sqrt(sum(resd2^2)/(p*(p+1)/2))
```
+ A small average standardized residual...looks good


### Null Model MO

```{r, eval=FALSE}
Model Test Baseline Model:

  Test statistic                              2020.010
  Degrees of freedom                                15
  P-value                                        0.000
```

+ This is the chi_sq for the baseline model used in the CFI/TLI/comparative fit measures.
+ We know what this means now!
+ chisquare of the null model: 2020.010
+ df of the null model: 15

reproducing M0:

```{r}
baselineM0 <- "
	glad ~~ glad
	happy ~~ happy
	cheerful ~~ cheerful
	satisfied ~~ satisfied
	content ~~ content
	comfortable ~~ comfortable
"
base_fit <- lavaan::sem(baselineM0, data = cfaData, fixed.x = FALSE)
base_fit
```


### CFI/TLI

```{r, eval=FALSE}
User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    1.000
  Tucker-Lewis Index (TLI)                       1.005
```


+ 100% improvement over the null(baseline) model ... great fit
+ Here TLI is larger than 1 because this is a rare situation with chisquare=2.957<df=8
+ numerator of TLI = (2020.010/15-2.957/8) = 134.2977
+ denominator of TLI = (2020.010/15-1) = 133.6673
+ TLI = 134.2977 / 133.6673 = 1.005
+ A TLI that is larger than 1 is no different from TLI = 1

great overall fit. 

### Loglikelihood

```{r, eval=FALSE}
Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -7483.272
  Loglikelihood unrestricted model (H1)      -7481.793
```

+ H0 is the loglikelihood of your model (user model ... lavaan is kind to clarify this)
+ H1 is the saturated model loglikelihood.

### AIC/BIC

```{r, eval=FALSE}
  Akaike (AIC)                               14992.544
  Bayesian (BIC)                             15056.345
  Sample-size adjusted Bayesian (BIC)        15015.056
```

+ Penalized -2 LogL
+ If these are lower than some other model -> prefer this model.
+ If these are higher than some other model -> prefer the other model.

reproducing AIC/BIC:

```{r}
logLik = -7483.272
q = 13 # (4 loadings + 6 unique factor variances + 3 factor var/covs)
N = 1000

(AIC = -2*logLik + 2*q)
(BIC = -2*logLik + log(N)*q)
```

<!------------------------------>
## PART II: Exercise
<!------------------------------>

For this portion, we will run the CFA analyses on a new simulated dataset based on Todd Little's positive affect example. 

Read in the new dataset:

```{r}
affectData_new <- read.csv("ChiStatSimDat.csv", header = T)
```

Examine the dataset:

```{r}
head(affectData_new)
```

Examine the covariance matrix:

```{r}
cov(affectData_new)
```
all positive! (Remember that indicators need to be all positively correlated for CFA models?)

### PART I: Plot the distributions of all indicators

```{r}
library(PerformanceAnalytics)
chart.Correlation(affectData_new)
```

all indicators look roughly normal

### PART II: Write out the model syntax for two-factor model

```{r}
twofa.model <- "
	#Factor Specification	
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable  
"
```

### PART III: Fit the two-factor model

```{r}
new_fit = lavaan::sem(twofa.model, data = affectData_new, fixed.x=FALSE)
summary(new_fit, standardized = T, fit.measures = T)
```

### PART IV: Interpret the chisquare statistic and fit indices

```{r,eval=FALSE}
Model Test User Model:
                                                      
  Test statistic                               113.638
  Degrees of freedom                                 8
  P-value (Chi-square)                           0.000
```

+ 113.638 is much larger than df=8 and the p-value is 0.000<0.05,
+ This chisquare is too large and the model is a poor fit. 

```{r,eval=FALSE}
Root Mean Square Error of Approximation:

  RMSEA                                          0.257
  90 Percent confidence interval - lower         0.216
  90 Percent confidence interval - upper         0.300
  P-value RMSEA <= 0.05                          0.000

Standardized Root Mean Square Residual:

  SRMR                                           0.070

User Model versus Baseline Model:

  Comparative Fit Index (CFI)                    0.908
  Tucker-Lewis Index (TLI)                       0.828
```

+ RMSEA = 0.257 >> 0.1. The lower bound of the confidence interval is also larger than 0.1. This indicates a poor fit. 
+ P-value RMSEA <= 0.05: sig - close fit null hypothesis rejected.
+ SRMR = 0.07 < 0.08, meaning that the average standardized residual between S and Sigma is no larger than 0.08, but SRMR is known to be lenient (i.e., low SRMR =/= good models, but high SRMR = bad models). 
+ 90.8% improvement over the null model ... marginal fit



<!--chapter:end:13-Model_Fit_2.Rmd-->

# Week11_2: Lavaan Lab 11 Model Local Fitting and Model Modifications


In this lab, we will learn: 

+ how to examine SEM local fit using residuals 
+ how to modify SEM models for improved fit using modification indices

Load up the lavaan library:

```{r}
library(lavaan)
```

<!------------------------------>
## PART I: Local Fit with Residuals
<!------------------------------>

Let's read in the new dataset ChiStatSimDat.csv: 

```{r}
cfaData<- read.csv("ChiStatSimDat.csv", header = T)
```

Write out syntax for a two-factor CFA model: 

```{r}
fixedIndTwoFacSyntax <- "
	#Factor Specification	
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable
"
```

Fit the two-factor model:

```{r}
fixedIndTwoFacRun = lavaan::sem(model = fixedIndTwoFacSyntax, 
                        data = cfaData, 
                        fixed.x=FALSE)
```

### Unstandardized residuals

```{r}
resid(fixedIndTwoFacRun)$cov
```

What does this mean? What is the metric?

### Standardized residuals

```{r}
resid(fixedIndTwoFacRun, type = "standardized")$cov
```

### Normalized residuals

```{r}
resid(fixedIndTwoFacRun, type = "normalized")$cov
```

+ Different residuals, same story
+ The covariance residual between cheerful and comfortable is the largest and positive
+ The model under-predicts this covariance
+ Fix!


<!------------------------------>
## PART II: Modification Indices
<!------------------------------>

```{r, eval=FALSE}
modindices(fixedIndTwoFacRun)
```

Filter output and only show rows with a modification index value equal or higher than 1:

```{r}
modindices(fixedIndTwoFacRun, minimum.value = 10)
```

Sort the output using the values of the modification index values. Higher values appear first: 
```{r}
modindices(fixedIndTwoFacRun, minimum.value = 10, sort = TRUE)
```

+ op ~~ : a correlation between two unique factors 
+ op =~ : cross-loading
+ This indicates that the parameters lavaan detects for you to free up are all residual covariances.

### Modified Model 1:

```{r}
mod1 <- "
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable  
	
	#residal covariance
	cheerful ~~ comfortable
"
```

```{r}
mod1_fit <- lavaan::sem(mod1, data = cfaData, 
                        std.lv = TRUE, fixed.x=FALSE)

summary(mod1_fit, fit.measures = T, standardized = T)
```

Model comparison: 

```{r}
anova(mod1_fit, fixedIndTwoFacRun)
```

Keep modifying mod1:

```{r}
modindices(mod1_fit, minimum.value = 10, sort = TRUE)
```


### Modified Model 2_1:

```{r}
mod2_1 <- "
  # cross loading
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ cheerful + satisfied + content + comfortable  # cheerful also loads on satisfaction
	
	#residal covariance
	cheerful ~~ comfortable
"
```

```{r}
mod2_1_fit <- lavaan::sem(mod2_1, data = cfaData, 
                          std.lv = TRUE, fixed.x=FALSE)

summary(mod2_1_fit, fit.measures = T, standardized = T)
```

Model comparison: 

```{r}
anova(mod2_1_fit, mod1_fit)
```


### Modified Model 2_2:

```{r}
mod2_2 <- "
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable 
	
	#residal covariance
	cheerful ~~ comfortable
	glad ~~ happy
"
```

```{r}
mod2_2_fit <- lavaan::sem(mod2_2, data = cfaData, 
                          std.lv = TRUE, fixed.x=FALSE)

summary(mod2_2_fit, fit.measures = T, standardized = T)
```

Model comparison: 

```{r}
anova(mod2_2_fit, mod1_fit)
```

Keep modifying 2_2:

```{r}
modindices(mod2_2_fit, minimum.value = 10, sort = TRUE)
```



### Modified Model 3:

```{r}
mod3 <- "
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable 
	
	#residal covariance
	cheerful ~~ comfortable
	glad ~~ happy
	content ~~ happy
"
```

```{r}
mod3_fit <- lavaan::sem(mod3, data = cfaData, std.lv = TRUE, fixed.x = FALSE)

summary(mod3_fit, fit.measures = T, standardized = T)
```

Model comparison: 

```{r}
anova(mod3_fit, mod2_2_fit)
```

Keep modifying mod3:

```{r}
modindices(mod3_fit, minimum.value = 10, sort = TRUE)
```

No suggestions could decrease the model chisquare by more than 10. 

<!--chapter:end:14-ModelModification.Rmd-->

# Week12_1: Lavaan Lab 12 SEM for Missing Data

In this lab, we'll use an example dataset HolzingerSwineford1939 in the package lavaan. Hence, lavaan must be installed.

Load up the lavaan library:

```{r}
library(lavaan)
```

Use data() to load HolzingerSwineford1939: 

```{r}
data(HolzingerSwineford1939)
head(HolzingerSwineford1939,3)
tail(HolzingerSwineford1939,3)
?HolzingerSwineford1939
```

+ The classic Holzinger and Swineford (1939) dataset consists of mental ability test scores of seventh- and eighth-grade children from two different schools (Pasteur and Grant-White). 
+ In the original dataset (available in the MBESS package), there are scores for 26 tests. 
+ However, a smaller subset with 9 variables is more widely used in the literature (for example in Joreskog's 1969 paper, which also uses the 145 subjects from the Grant-White school only).



<!------------------------------>
## PART I: Generate some missing data
<!------------------------------>

HolzingerSwineford1939 has complete dataset on all nine indicators x1-x9. In this example, we will create some missingness in x5 and x9. 

For a commented analysis, check vignettes of the R package lslx. 

+ First, missingness on x5 depends on x1: lowest 20% of x1 miss x5 values 

```{r}
data_miss <- lavaan::HolzingerSwineford1939
data_miss$x5 <- ifelse(data_miss$x1 <= quantile(data_miss$x1, .2), 
                       NA, data_miss$x5)
```

+ Second, missingness on x9 depends on age: lowest 10% of age group miss x9 values 
+ Note that age is created by ageyr and agemo. Since ageyr and agemo are not the variables that we are interested, the two variables are treated as auxiliary in the later analysis.

```{r}
data_miss$age <- data_miss$ageyr + data_miss$agemo/12
data_miss$x9 <- ifelse(data_miss$age <= quantile(data_miss$age, .1), 
                       NA, data_miss$x9)
head(data_miss)
```

+ use the function is.na() to return a matrix of missing data indicators (missing: true, complete: false)

```{r}
na.eval = is.na(data_miss)
head(na.eval[,7:15], 3)
```

+ missing counts for each column (variable)

```{r}
colSums(na.eval)
```

+ 65 values are missing on x5
+ 33 values are missing on x9

MCAR, MAR, OR MNAR? 

+ Ans: MAR for both x5 and x9
+ A small tip: if you want a complete version of the dataset, use function na.omit()


```{r}
data.complete = na.omit(data_miss)
dim(data.complete) # [1] 208  16
```

<!------------------------------>
## PART II: Visualization of missing data patterns (nice-to-have)
<!------------------------------>

To visualize and handle missingness, we need mice package:

```{r,message=FALSE}
#install.packages('mice', dependencies=TRUE)
library("mice")
```

Display missing-data patterns:
```{r}
md.pattern(data_miss)
```

Three variables with missing values on the right side: grade x9 x5: 

+ five rows: five patterns:
+ 208 cases with complete responses (0 variable missing)
+ 59 cases with only x5 missing (1 variable missing)
+ 27 cases with only x9 missing (1 variable missing)
+ 6 cases with both x5 and x9 missing (2 variables missing)
+ 1 case with grade missing (1 variable missing)


<!------------------------------>
## PART III: Build a CFA model with missing data
<!------------------------------>

Write out syntax for a three-factor CFA model: 

```{r}
HS.model <- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '
```

Left untreated, the default in sem() is listwise deletion: 

```{r}
fit.listwise <- lavaan::sem(HS.model, 
                    data = data_miss, 
                    fixed.x = FALSE)

summary(fit.listwise, fit.measures = TRUE)
```


<!------------------------------>
## PART IV: Addressing missing data
<!------------------------------>

### FIML

```{r}
fit.fiml <- lavaan::sem(HS.model, 
                data = data_miss, 
                missing = 'fiml',
                fixed.x = FALSE)

summary(fit.fiml, fit.measures = TRUE)
```


### Multiple Imputation

To perform MI with lavaan, we turn to the R-package semTools which offers many functions that extends the basic sem() function. 

```{r,message=FALSE}
#install.packages('semTools', dependencies=TRUE)
library("semTools")
```


Mice also utilizes information from auxiliary variables. Since we don't know which ones are auxiliary variables, let's include sex, age and grade and generate imputed datasets.

Again, MI consists of three steps:

+ (1) Imputation Step
+ (2) Analysis Step
+ (3) Pooling Step

```{r}
out1 <- cfa.mi(HS.model, 
               data=data_miss[,c("x1", "x2", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "sex", "age", "grade")],
               fixed.x = FALSE, 
               m = 20, 
               miPackage="mice",
               seed = 12345)

summary(out1)
```






<!--chapter:end:15-SEM_for_Missing_Data.Rmd-->

# Week12_2: Lavaan Lab 13 SEM for Nonnormal and Categorical Data

Load up the lavaan library:

```{r}
library(lavaan)
```

<!------------------------------>
## PART I: Nonnormality Diagnosis
<!------------------------------>

Let's first load the simulated non-normal data and look at the normality/nonnormality of the items:

```{r}
nnorm_dat <- read.csv("nonnormal.csv", header = T)
head(nnorm_dat)
```

```{r}
par(mfrow = c(2, 2)) #opens graph window with 2 rows 2 columns
hist(nnorm_dat$odd5)
hist(nnorm_dat$odd6)
hist(nnorm_dat$odd7)
hist(nnorm_dat$odd8)
```

Use describe() function from the psych package to get univariate descriptives:

```{r,message=FALSE}
#install.packages("psych")
library(psych)
describe(nnorm_dat)
```

Use mardia() from the psych package to test multivariate normality:

```{r}
par(mfrow = c(1, 1)) #opens graph window
mardia(nnorm_dat)
```

In any case, these data are clearly far from normal, so ...

<!------------------------------>
## PART II: Robust corrections
<!------------------------------>

Write out syntax for a one-factor CFA model: 

```{r}
cfaSyn <- "
	odd =~ odd1 + odd2 + odd3 + odd4 + odd5 + odd6 + odd7 + odd8
"
```

Fit the one-factor model:

```{r}
mlrFit <- lavaan::sem(cfaSyn, 
              data = nnorm_dat, 
              fixed.x = FALSE,
              estimator = "mlr")

summary(mlrFit, fit.measure = T)
```


<!------------------------------>
## PART III: Categorical Data Analysis in Lavaan
<!------------------------------>

Let's load the simulated data in which ODD items are ordinal:

```{r}
odd <- read.csv("oddData.csv", header = T)
head(odd)
```

Write out syntax for a one-factor CFA model: 

```{r}
oddOneFac = '
	#Specify Overall Odd Factor
	odd  =~ odd1 + odd2 + odd3 + odd4 + odd5 + odd6 + odd7 + odd8
	'
```

+ Fit the one-factor model:
+ label ordinal variables using ordered argument: 
+ ordered = c( #NAMES OF ORDINAL INDICATORS#)

```{r}
oneFacFit <- lavaan::sem(oddOneFac, 
                 data = odd,
                 ordered=c('odd1','odd2','odd3','odd4','odd5','odd6','odd7','odd8'), 
                 fixed.x = FALSE) 
#declare these as ordered variable

summary(oneFacFit, fit.measures = T)
```


<!------------------------------>
## PART IV: What if you have it all? 
<!------------------------------>

+ Unfortunately you cannot use missing = 'fiml' for categorical data:

```{r}
FitMessy <- lavaan::sem(oddOneFac, 
                data = odd,
                ordered=c('odd1','odd2','odd3','odd4','odd5','odd6','odd7','odd8'), 
                fixed.x = FALSE,
                estimator = "DWLS",
                #missing = 'fiml'
                ) 

FitMessy
#summary(FitMessy, fit.measures = T)
```

+ But you cannot use missing = 'fiml' together with MLR for nonnormal data:

```{r}
FitMessy <- lavaan::sem(oddOneFac, 
                data = nnorm_dat,
                #ordered=c('odd1','odd2','odd3','odd4','odd5','odd6','odd7','odd8'), 
                fixed.x = FALSE,
                estimator = "mlr",
                missing = 'fiml') 

FitMessy
#summary(FitMessy, fit.measures = T)
```

<!--chapter:end:16-SEM_for_Nonnormal_Categorical_Data.Rmd-->

# Week13_1: Lavaan Lab 14 Measurement Invariance

For this lab, we will run the MG-CFA analyses in class using simulated data based on Todd Little's positive affect example.

Load up the lavaan library:

```{r, message=FALSE}
library(lavaan)
```

and the dataset:

```{r}
affectData <- read.csv("cfaInclassData.csv", header = T)
```

For demonstration purposes, let's first simulate a grouping variable called school:

```{r}
set.seed(555)
affectData$school = sample(c('public', 'private'), nrow(affectData), replace = T)
table(affectData$school)
head(affectData)
```

The goal of testing measurement invariance (MI) is to make sure that the scale that measures positive affect and satisfaction functions in the same way between public and private schools.

<!------------------------------>
## PART I: Multi-Group Analyses, Done Incorrectly
<!------------------------------>

Syntax for an SR model (it doesn't matter whether the model is for CFA or SR, the test of MI only applies to the CFA part): 

```{r}
srSyntax <- "
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable 
	
	# Structural Regression: beta
	satisfaction ~ posAffect
	"
```

```{r}
MGsrRunWRONG <- lavaan::sem(srSyntax, 
                    data = affectData, 
                    fixed.x=FALSE,
                    group = "school", # group indicator
                    estimator = "MLR") # use MLR as a go-to estimation method

summary(MGsrRunWRONG, standardized = T, fit.measures = T)
```

```{r,warning=FALSE}
library(semPlot)
semPaths(MGsrRunWRONG, what='est', 
         nCharNodes = 0,
         nCharEdges = 0, # don't limit variable name lengths
         edge.label.cex=0.6, 
         curvePivot = TRUE, 
         curve = 1.5, # pull covariances' curves out a little
         fade=FALSE)
```


<!------------------------------>
## PART II: Testing Measurement Invariance
<!------------------------------>

### step 1: Configural invariance

If you simply use the MGsrRunWRONG synatx above, you are just testing configural invariance: 

```{r}
configuralFit <- lavaan::sem(srSyntax, 
                    data = affectData, 
                    fixed.x=FALSE,
                    group = "school", # group indicator
                    estimator = "MLR") # use MLR as a go-to estimation method
#summary(configuralFit, standardized = T, fit.measures = T)
```

+ Configural invariance was established due to satisfying model fit; 

### step 2: Metric (weak) invariance

To test metric invariance, you could manually constraint all factor loadings to be the same using tricks like "posAffect =~ c(lam1, lam1)*glad" but there is a shortcut using "group.equal" argument:

```{r}
metricFit <- lavaan::sem(srSyntax, 
                 data = affectData, 
                 fixed.x=FALSE,
                 estimator = 'MLR',
                 group = "school", 
                 group.equal = c("loadings")) 
```

+ so that all factor loadings are fixed to be the same across groups
+ More group equality constraints can be added, like "intercepts", "means", "residuals", "residual.covariances", "lv.variances", "lv.covariances", "regressions"

```{r}
summary(metricFit, standardized = T, fit.measures = T)
```

+ Again, metric invariance was established due to satisfying model fit; 
+ To test whether the equal factor loading assumption caused damage to model fit, we compare metricFit to configuralFit: 

Model comparison: 

```{r}
anova(configuralFit, metricFit)
```

+ The test was not significant, meaning the increase in chi-square (due to the assumption of equal factor loadings) was not substantial enough to worsen the model fit; 
+ Note that this test suffers from the same problem as the chi-square test (too sensitive to model misfit)

### step 3: Scalar (strong) Invariance

In this step, both factor loadings and measurement intercepts (of course, including factor structure) are constrained to be equal between the groups: 

```{r}
scalarFit <- lavaan::sem(srSyntax, 
                 data = affectData, 
                 fixed.x=FALSE,
                 estimator = 'MLR',
                 group = "school", 
                 group.equal = c("loadings", "intercepts")) 
summary(scalarFit, standardized = T, fit.measures = T)
```

Model comparison: 

```{r}
anova(metricFit, scalarFit)
```

+ The test was not significant, meaning the increase in chi-square (due to the assumption of equal measurement intercepts) was not substantial enough to worsen the model fit; 
+ Scalar invariance was established; 

### step 4: (Optional) Residual variance (strict) invariance 

```{r}
resVarFit <- lavaan::sem(srSyntax, 
                 data = affectData, 
                 fixed.x=FALSE,
                 estimator = 'MLR',
                 group = "school", 
                 group.equal = c("loadings", "intercepts", "residuals")) 
summary(resVarFit, standardized = T, fit.measures = T)
```

Model comparison: 

```{r}
anova(resVarFit, scalarFit)
```

+ The test was not significant, meaning the increase in chi-square (due to the assumption of equal residual variances) was not substantial enough to worsen the model fit; 
+ Strict invariance was established. 

<!------------------------------>
## PART III: Shortcut to performing MI
<!------------------------------>

### measurementInvariance()

There is a shortcut function in package 'semTools' that performsinvariance testing in one place, but unfornately it will soon retire...

```{r, message=FALSE}
library(semTools)

measurementInvariance(model = srSyntax, 
                      data = affectData, 
                      fixed.x=FALSE,
                      estimator = 'MLR', 
                      group = "school")
```

### measEq.syntax()

To use measEq.syntax() from semTools, we need to use a model syntax for CFA model instead of SR model: 

```{r}
cfaSyntax <- "
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable 
	"
```

```{r}
test.seq <- list(weak = c("loadings"),
                 strong = c("intercepts"),
                 strict = c("residuals"))
meq.list <- list()
for (i in 0:length(test.seq)) {
  if (i == 0L) {
    meq.label <- "configural"
    group.equal <- ""
  } else {
    meq.label <- names(test.seq)[i]
    group.equal <- unlist(test.seq[1:i])
  }
  meq.list[[meq.label]] <- measEq.syntax(configural.model = cfaSyntax,
                                         data = affectData,
                                         fixed.x = TRUE,
                                         estimator = 'MLR', 
                                         group = "school",
                                         group.equal = group.equal,
                                         return.fit = TRUE)
}
```

```{r}
a = compareFit(meq.list)
summary(compareFit(meq.list))
```


<!------------------------------>
## PART IV: Multi-Group CFA Modeling, done right
<!------------------------------>

+ To compare the structural model parameters, at least scalar (strong) invariance is required; 
+ Since strict invariance was also satisfied, we will use resVarFit for MG-SR Modeling in this example:

### Statistical Test of Equal Factor Means:

```{r}
equalMeanfit <- lavaan::sem(cfaSyntax, 
                    affectData, 
                    fixed.x = FALSE, 
                    estimator = 'MLR', 
                    group = "school", 
                    group.equal = c("loadings", "intercepts", "residuals", 
                                    "means"))

summary(equalMeanfit, standardized = T, fit.measures = T)

anova(resVarFit, equalMeanfit)
```

+ The anova test was not significant, meaning the increase in chi-square (due to the constraint of equal latent means) was not substantial enough to worsen the model fit; 
+ It says the levels of positive affect and satisfaction in public schools were essentially the same as those in private schools. 

### Statistical Test of Equal Regression Coefficients:

+ Note that we used srSyntax here because we need to define the regression coefficient between PA and satisfaction: 

```{r}
equalBetafit <- lavaan::sem(srSyntax, 
                    affectData, 
                    fixed.x = FALSE, 
                    estimator = 'MLR', 
                    group = "school", 
                    group.equal = c("loadings", "intercepts", "residuals",
                                 "regressions"))

summary(equalBetafit, standardized = T, fit.measures = T)

anova(resVarFit, equalBetafit)
```

+ The test was not significant, meaning the increase in chi-square (due to the constraint of equal regression coefficients) was not substantial enough to worsen the model fit; 
+ It says the effect of positive affect on satisfaction in public schools was essentially the same as that in private schools.






<!--chapter:end:17-Measurement_Invariance.Rmd-->

# Week13_2: Lavaan Lab 15 MIMIC & Longitudinal Invariance

+ For this lab, we will run Partial Invariance Test and MIMIC Models using simulated data based on Todd Little's positive affect example.
+ We will also test longitudinal measurement invariance using a longitudinal dataset from semTools

Load up the lavaan library:

```{r, message=FALSE}
library(lavaan)
```

and the dataset:

```{r}
affectData <- read.csv("cfaInclassData.csv", header = T)
```

For demonstration purposes, let's first simulate a grouping variable called school:

```{r}
set.seed(555)
affectData$school = sample(c('public', 'private'), nrow(affectData), replace = T)
```


<!------------------------------>
## PART I: Partial Invariance
<!------------------------------>

Suppose that you do not need: 

+ the loading of content on satisfaction
+ the intercept of content 

to be equal across groups, you can use group.partial= to relax them: 

+ "satisfaction=~content": factor loading of content on satisfaction
+ "content~1": intercept of indicator content

```{r}
srSyntax <- "
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable 
	
	# Structural Regression: beta
	satisfaction ~ posAffect
	"
```

```{r}
PartialInvFit <- lavaan::sem(srSyntax, 
                 data = affectData, 
                 fixed.x=FALSE,
                 estimator = 'MLR',
                 group = "school", 
                 group.equal = c("loadings", "intercepts", "residuals"),
                 group.partial = c("satisfaction=~content", "content~1")) 
summary(PartialInvFit, standardized = T, fit.measures = T)
```

+ The overall model seems to be fine, so we can safely assume these two parameters can be freed across group; 
+ Technically you want to compare PartialInvFit to resVarFit from last lab

<!------------------------------>
## PART II: MIMIC
<!------------------------------>

To test whether the grouping variable school affects the loadings (i.e., metric invariance), school has to first interact with PA and predict the indicators:

This is easily said than done. **To create such an interaction, we first need to create indicators of the latent interaction by multiplying school with each of the indicators of PA**:

```{r}
# first convert public/private to 0/1
affectData$school_N = ifelse(affectData$school=='public', 0, 1)

affectData$intPA1 =  affectData$school_N * affectData$glad
affectData$intPA2 =  affectData$school_N * affectData$happy
affectData$intPA3 =  affectData$school_N * affectData$cheerful
```

### Test Metric Invariance

Now that we have our latent interaction indicators ready, we can run our MIMIC analyses by testing: 

```{r}
srSyntaxMIMIC0 <- "
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable 
	schoolxPA =~ intPA1 + intPA2 + intPA3 
	
	# Structural Regression: beta
	satisfaction ~ posAffect
	
	# Correlated Residuals:
	intPA1 ~~ glad
	intPA2 ~~ happy
	intPA3 ~~ cheerful
	"
```

```{r}
MIMICmodel <- lavaan::sem(srSyntaxMIMIC0, 
                 data = affectData, 
                 fixed.x=FALSE,
                 estimator = 'MLR') 
```

```{r,warning=FALSE}
library(semPlot)
semPaths(MIMICmodel, what='est', 
         nCharNodes = 0,
         nCharEdges = 0, # don't limit variable name lengths
         edge.label.cex=0.6, 
         curvePivot = TRUE, 
         curve = 1.5, # pull covariances' curves out a little
         fade=FALSE)
```


```{r}
srSyntaxMIMICLoading <- "
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable 
	
	
	schoolxPA =~ intPA1 + intPA2 + intPA3 
	
	# Structural Regression: beta
	satisfaction ~ posAffect
	
	# Correlated Residuals:
	intPA1 ~~ glad
	intPA2 ~~ happy
	intPA3 ~~ cheerful
	
	# Test Metric Invariance
	glad ~ school + schoolxPA
	happy ~ school + schoolxPA
	cheerful ~ school + schoolxPA
	"
```

Note that you don't need group=, group.equal=, or group.partial= in the following function (why?): 

```{r}
MIMICloading <- lavaan::sem(srSyntaxMIMICLoading, 
                 data = affectData, 
                 fixed.x=FALSE,
                 estimator = 'MLR') 
summary(MIMICloading, standardized = T, fit.measures = T)
```

```{r,warning=FALSE}
semPaths(MIMICloading, what='est', 
         nCharNodes = 0,
         nCharEdges = 0, # don't limit variable name lengths
         edge.label.cex=0.6, 
         curvePivot = TRUE, 
         curve = 1.5, # pull covariances' curves out a little
         fade=FALSE)
```

```{r, eval = FALSE, echo=TRUE}
Regressions:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
  satisfaction ~                                                        
    posAffect         0.583    0.073    7.942    0.000    0.485    0.485
  glad ~                                                                
    school           -0.038    0.043   -0.869    0.385   -0.038   -0.019
    schoolxPA         0.129    0.147    0.874    0.382    0.068    0.070
  happy ~                                                               
    school           -0.014    0.043   -0.325    0.745   -0.014   -0.007
    schoolxPA        -0.081    0.177   -0.457    0.648   -0.043   -0.044
  cheerful ~                                                            
    school           -0.048    0.042   -1.150    0.250   -0.048   -0.024
    schoolxPA         0.118    0.173    0.681    0.496    0.063    0.064
```

+ The coefficient of schoolxPA on all indicators were insignificant. 
+ The loadings do not depend on school type.
+ No sign of violation of metric invariance.

### Test Scalar Invariance

Since metric invariance has been established, we do not need the indicators of the latent interactions, we simply predict each of the indicators using group: 

```{r}
srSyntaxMIMICInt <- "
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable 

	# Structural Regression: beta
	satisfaction ~ posAffect

	# Test Scalar Invariance
	glad ~ school
	happy ~ school
	cheerful ~ school
	"
```

```{r}
MIMICintercept <- lavaan::sem(srSyntaxMIMICInt, 
                       data = affectData,
                       fixed.x=FALSE,
                       estimator = 'MLR') 
```

```{r,warning=FALSE}
semPaths(MIMICintercept, what='est', 
         nCharNodes = 0,
         nCharEdges = 0, # don't limit variable name lengths
         edge.label.cex=0.6, 
         curvePivot = TRUE, 
         curve = 1.5, # pull covariances' curves out a little
         fade=FALSE)
```

```{r}
summary(MIMICintercept, standardized = T, fit.measures = T)
```

+ The coefficient of school on all indicators were insignificant. 
+ The intercepts of indicators do not depend on school type.
+ No sign of violation of scalar invariance.

### Test The Hypothesis of Equal Factor Means:

```{r}
cfaSyntaxMIMIC <- "
	posAffect =~ glad + happy + cheerful 
	satisfaction =~ satisfied + content + comfortable 

	# Test Equal Factor Means
	posAffect ~ school
	satisfaction ~ school
	"
```

```{r}
MIMICmean <- lavaan::sem(cfaSyntaxMIMIC, 
                 data = affectData,
                 fixed.x=FALSE,
                 estimator = 'MLR') 
summary(MIMICmean, standardized = T, fit.measures = T)
```

```{r,warning=FALSE}
semPaths(MIMICmean, what='est', 
         nCharNodes = 0,
         nCharEdges = 0, # don't limit variable name lengths
         edge.label.cex=0.6, 
         curvePivot = TRUE, 
         curve = 1.5, # pull covariances' curves out a little
         fade=FALSE)
```

+ The coefficient of school on two latent variables were insignificant. 
+ It says the levels of positive affect and satisfaction in public schools were essentially the same as those in private schools. 

<!------------------------------>
## PART III: Longitudinal Invariance
<!------------------------------>

The following codes were adapted from the examples of measEq.syntax() in semTools: 

```{r, message=FALSE}
library(semTools)
?measEq.syntax
```

They used a built-in dataset called datCat: 

```{r}
head(datCat)
```

+ A data.frame with 200 observations of 9 variables.
+ A simulated data set with 2 factors with 4 indicators each separated into two groups
+ Let's ignore the gender groups for now
+ u1-u4 are likert variables measured at time 1
+ u5-u8 are the same set of likert variables measured at time 2
+ Both u1-u4 and u5-u8 measure the same latent variable, FU

The goal of testing longitudinal invariance is to make sure that the scale that measures positive affect and satisfaction functions in the same way across all time points. 

### step 1: Configural invariance

First define the CFA model that measures the same latent variable (FU) at two time points:

```{r}
mod.cat <- ' FU1 =~ u1 + u2 + u3 + u4
             FU2 =~ u5 + u6 + u7 + u8 '
```

It's important to know: 

+ You do not want to use sem() to test longitudinal invariance (technically you can, but it'll be very messy)
+ I recommend using the function measEq.syntax() from semTools package
+ To tell measEq.syntax() that FU1 are FU2 are just the same variables, you need to define a list longFacNames that includes this information
+ The indicators are categorical you'll need the ordered= argument and parameterization = "theta"
+ The example codes used ID.fac = "std.lv" (fixed variance scaling) so we'll use this as well
+ return.fit = TRUE fits the model instead of just creating a model syntax

```{r}
## the 2 factors are actually the same factor (FU) measured twice
longFacNames <- list(FU = c("FU1","FU2"))
```

```{r}
syntax.config <- measEq.syntax(configural.model = mod.cat,
                               data = datCat,
                               ordered = paste0("u", 1:8),
                               parameterization = "theta",
                               ID.fac = "std.lv", 
                               longFacNames = longFacNames,
                               fixed.x = TRUE,
                               return.fit = TRUE)
#cat(as.character(syntax.config))
summary(syntax.config, standardized = T, fit.measures = T)
```


### step 1.5: Threshold invariance (for categorical indicators only)

+ The test of Threshold invariance has to happen before the test of all other parameters;
+ Note that we do not have to use group = argument, longFacNames does the job 
+ Use long.equal = c("thresholds") to test Threshold invariance

```{r}
syntax.thresh <- measEq.syntax(configural.model = mod.cat,
                               data = datCat,
                               ordered = paste0("u", 1:8),
                               parameterization = "theta",
                               ID.fac = "std.lv", 
                               longFacNames = longFacNames,
                               long.equal = c("thresholds"),
                               fixed.x = TRUE,
                               return.fit = TRUE)

summary(syntax.thresh, standardized = T, fit.measures = T)
```

compare their fit to test threshold invariance:

```{r}
anova(syntax.config, syntax.thresh)
```

+ The test was not significant, meaning the increase in chi-square (due to the assumption of equal thresholds) was not substantial enough to worsen the model fit; 
+ Threshold invariance was established; 


<!------------------------------>
### RECOMMENDED PRACTICE: fit one invariance model at a time
<!------------------------------>

+ A downside of setting return.fit=TRUE is that if the model has trouble converging, you don't have the opportunity to investigate the syntax, or even to know whether an error resulted from the syntax-generator or from lavaan itself.
+ A downside of automatically fitting an entire set of invariance models (like the old measurementInvariance() function did) is that you might end up testing models that shouldn't even be fitted because less restrictive models already fail (e.g., don't test full scalar invariance if metric invariance fails! Establish partial metric invariance first, then test equivalent of intercepts ONLY among the indicators that have invariate loadings.)

+ The recommended sequence is to 
  (1) generate and save each syntax object (i.e., return = FALSE), 
  (2) print it to the screen to verify you are fitting the model you expect to (and potentially learn which identification constraints should be released when equality constraints are imposed), and 
  (3) fit that model to the data, as you would if you had written the syntax yourself.

+ Continuing from the examples above, after establishing invariance of thresholds, we proceed to test equivalence of loadings and intercepts (metric and scalar invariance, respectively) simultaneously across groups and repeated measures.


### step 2: Metric (weak) invariance

```{r, results='hide'}
syntax.metric <- measEq.syntax(configural.model = mod.cat,
                               data = datCat,
                               ordered = paste0("u", 1:8),
                               parameterization = "theta",
                               ID.fac = "std.lv", 
                               longFacNames = longFacNames,
                               long.equal = c("thresholds","loadings"),
                               fixed.x = TRUE,
                               return.fit = TRUE)
summary(syntax.metric, standardized = T, fit.measures = T)  # summarize model features
```

test equivalence of loadings, given equivalence of thresholds: 

```{r}
anova(syntax.thresh, syntax.metric)
```

+ The test was not significant, meaning the increase in chi-square (due to the assumption of equal loadings) was not substantial enough to worsen the model fit; 
+ Metric invariance was established; 


### step 3: Scalar (strong) Invariance

```{r, results='hide'}
syntax.scalar <- measEq.syntax(configural.model = mod.cat, 
                               data = datCat,
                               ordered = paste0("u", 1:8),
                               parameterization = "theta",
                               ID.fac = "std.lv", 
                               longFacNames = longFacNames,
                               long.equal  = c("thresholds","loadings","intercepts"),
                               fixed.x = TRUE,
                               return.fit = TRUE)
summary(syntax.scalar, standardized = T, fit.measures = T)  # summarize model features
```

test equivalence of intercepts, given equal thresholds & loadings:

```{r}
anova(syntax.metric, syntax.scalar)
```

+ The test was not significant, meaning the increase in chi-square (due to the assumption of equal intercepts) was not substantial enough to worsen the model fit; 
+ Scalar invariance was established; 


### step 4: Residual variance (strict) invariance 

```{r, results='hide'}
syntax.strict <- measEq.syntax(configural.model = mod.cat, 
                               data = datCat,
                               ordered = paste0("u", 1:8),
                               parameterization = "theta",
                               ID.fac = "std.lv", 
                               longFacNames = longFacNames,
                               long.equal  = c("thresholds","loadings","intercepts", 
                                               "residuals"),
                               fixed.x = TRUE,
                               return.fit = TRUE)
summary(syntax.strict, standardized = T, fit.measures = T)  # summarize model features
```

test equivalence of intercepts, given equal thresholds & loadings: 

```{r}
anova(syntax.scalar, syntax.strict)
```

+ The test was not significant, meaning the increase in chi-square (due to the assumption of equal residual variances) was not substantial enough to worsen the model fit; 
+ Strict invariance was established; 


### Shortcut Function

For a single table with all results, you can pass the models to summarize to the compareFit() function:

```{r}
summary(compareFit(syntax.config, syntax.thresh, syntax.metric, syntax.scalar, syntax.strict))
```

<!------------------------------>
### NOT RECOMMENDED: fit several invariance models at once
<!------------------------------>

Must SIMULTANEOUSLY constrain thresholds, loadings, and intercepts": 

```{r}
test.seq <- list(strong = c("thresholds", "loadings","intercepts"),
                 strict = c("residuals"))
```

```{r}
meq.list <- list()
for (i in 0:length(test.seq)) {
  if (i == 0L) {
    meq.label <- "configural"
    long.equal <- ""
  } else {
    meq.label <- names(test.seq)[i]
    long.equal <- unlist(test.seq[1:i])
  }
  meq.list[[meq.label]] <- measEq.syntax(configural.model = mod.cat,
                                         data = datCat,
                                         ordered = paste0("u", 1:8),
                                         parameterization = "theta",
                                         ID.fac = "std.lv",
                                         longFacNames = longFacNames,
                                         long.equal = long.equal,
                                         fixed.x = TRUE,
                                         return.fit = TRUE)
}
```

```{r}
compareFit(meq.list)
summary(compareFit(meq.list))
```

<!------------------------------>
## PART IV: Exercises: MIMIC
<!------------------------------>

In this exercise, you are given a dataset, activefull.txt, to fit the MIMIC model on page 70 of <Week13 MGSEM + Measurement Invariance.pdf>: 

I'll get you started: 

```{r}
active<-read.table('activefull.txt', header=T)
V<-c('ws1','ls1','lt1','gender')
active_sub<-active[,V]
head(active_sub)
```

+ This subscale measures the latent variable R using three continuous indicators: 'ws1','ls1','lt1'
+ You can ignore the mediator edu for now. 

**Using active_sub, can you test the (1) Metric Invariance and (2) Scalar Invariance of this subscale between gender groups? **

```{r}

```




<!------------------------------>
## PART V: Exercises: Longitudinal Invariance
<!------------------------------>

In this exercise, you are given a dataset, myData, that can be downloaded from Mplus website: 

```{r}
myData <- read.table("http://www.statmodel.com/usersguide/chap5/ex5.16.dat")
names(myData) <- c("u1","u2","u3","u4","u5","u6","x1","x2","x3","g")
myData_sub<-myData[,c("u1","u2","u3","u4","u5","u6")]
head(myData_sub)
```

+ myData_sub is a data.frame with 2200 observations of 6 variables.
+ u1-u3 are binary variables measured at time 1
+ u4-u6 are the same set of binary variables measured at time 2
+ Both u1-u3 and u4-u6 measure the same latent variable, FU

Let's first define the CFA model that measures the same latent variable (FU) at two time points (you are welcome):

```{r}
bin.mod <- '
  FU1 =~ u1 + u2 + u3
  FU2 =~ u4 + u5 + u6
'
```

Using myData_sub, can you test the (1) Metric Invariance and (2) Scalar Invariance of this subscale between gender groups? 

```{r}

```


```{r}
test.seq <- list(strong = c("thresholds", "loadings","intercepts"),
                 strict = c("residuals"))
```

```{r}
meq.list <- list()
for (i in 0:length(test.seq)) {
  if (i == 0L) {
    meq.label <- "configural"
    long.equal <- ""
  } else {
    meq.label <- names(test.seq)[i]
    long.equal <- unlist(test.seq[1:i])
  }
  meq.list[[meq.label]] <- measEq.syntax(configural.model = bin.mod,
                                         data = myData_sub,
                                         ordered = paste0("u", 1:6),
                                         parameterization = "theta",
                                         ID.fac = "std.lv",
                                         longFacNames = longFacNames,
                                         long.equal = long.equal,
                                         fixed.x = TRUE,
                                         return.fit = TRUE)
}
```

```{r}
compareFit(meq.list)
summary(compareFit(meq.list))
```



<!--chapter:end:18-Extensions_MI.Rmd-->

# Week14: Lavaan Lab 16 Latent Growth Models

In this lab, we will:

+ run and interpret a series of growth models (no growth, linear, quadratic, latent basis, spline growth);
+ compare nested models and identify the best possible shape for characterizing the growth patterns; 
+ add predictors for the growth factors;
+ run growth models on latent variables. 

Load up the lavaan library:

```{r, message=FALSE}
library(lavaan)
```

We will also need ggplot2, semPlot, and semTools. Install them if you haven't: 

```{r,message=FALSE}
#install.packages("ggplot2")
#install.packages("semPlot")
#install.packages("semTools")
library(ggplot2)
library(semPlot)
library(semTools)
```

+ For this lab, we will work with a simulated dataset # based on an example from McCoach & Kaniskan (2010). 
+ The main DV is Oral Reading Fluency (ORF) and is measured over 4 time points (Fall and Spring, 2 consecutive years) 
+ N = 277 Elementary students.
+ Let's read in the dataset:

```{r}
orf <- read.csv("readingSimData.csv", header = T)
```

Take a look at the dataset:

```{r}
head(orf)
```

sample size:
```{r}
n <- nrow(orf)
n #277, just like the McCoach paper.
```

sample means and cov matrix
```{r}
orfNames <- paste0("orf", 1:4)
(samMeans <- round(apply(orf[,orfNames], 2, mean), 3))
(samCov <- round(cov(orf[,orfNames])*((n-1)/n), 3))
```

<!------------------------------>
## PART I: Spaghetti Plot
<!------------------------------>

For more details, check out https://www.r-bloggers.com/my-commonly-done-ggplot2-graphs/

First, let's use reshape() to convert wide format to long format for plotting: 

```{r}
growthDataLong <- reshape(orf, varying = paste0("orf", 1:4), sep = "", direction = "long")
head(growthDataLong)
```

Plot trajectory of individual with id=1

```{r}
tspag_id1 = ggplot(growthDataLong[growthDataLong$id==1, ], aes(x=time, y=orf)) + 
  geom_line() + 
  xlab("Observation Time Point") +
  ylab("Y") + 
  ylim(-40, 300) + 
  ggtitle("Spaghetti plot") + 
  aes(colour = factor(id))
tspag_id1
```

plot trajectory of everyone 

```{r}
tspag = ggplot(growthDataLong, aes(x=time, y=orf)) + 
  geom_line(show.legend = FALSE) + 
  xlab("Observation Time Point") +
  ylab("Y") + 
  ylim(-40, 300) + 
  ggtitle("Spaghetti plot") + 
  aes(colour = factor(id))
tspag
```


<!------------------------------>
## PART II: Growth Models
<!------------------------------>

### 1. No growth model

+ Let's start by examining the hypothesis of no growth (intercept only)
+ Intercept loads on all variables with fixed loadings of 1.0
+ Use a*VAR1 to fix the coefficient of VAR1 at a:

```{r}
noGrowthSyn <- "
	#Specify Latent Intercept
	I =~ 1*orf1 + 1*orf2 + 1*orf3 + 1*orf4
"
```

```{r}
noGrowthFit <- growth(noGrowthSyn, data = orf, fixed.x = FALSE)
summary(noGrowthFit, fit.measures = T)
```

```{r}
semPaths(noGrowthFit, what='est', fade= F)
```

### 2. Linear growth model

+ Intercept loads on all variables with fixed loadings of 1.0
+ Slope loads on all variables with fixed loadings of t = 0, 1, 2, ..., t-1
+ t must start from 0

```{r}
linearGrowthSyn <- "
	#Specify Latent Intercept and Slope
	I =~ 1*orf1 + 1*orf2 + 1*orf3 + 1*orf4
	S =~ 0*orf1 + 1*orf2 + 2*orf3 + 3*orf4
"
```

```{r}
linearGrowthFit <- growth(linearGrowthSyn, data = orf, fixed.x = FALSE)
summary(linearGrowthFit, fit.measures = T)
```

```{r}
semPaths(linearGrowthFit, what='est', fade= F)
```

### 3. Quadratic growth model

+ Intercept loads on all variables with fixed loadings of 1.0
+ Slope loads on all variables with fixed loadings of t = 0, 1, 2, ..., t-1
+ Quadratic loads on all variables with fixed loadings of t^2 = 0, 1, 4, ..., (t-1)^2
+ Quadratic has no variance and covariances

```{r}
quadGrowthSyn <- "
	#int and slope factors
	I =~ 1*orf1 + 1*orf2 + 1*orf3 + 1*orf4
	S =~ 0*orf1 + 1*orf2 + 2*orf3 + 3*orf4
	#quadratic factor = slope^2
	quadS =~ 0*orf1 + 1*orf2 + 4*orf3 + 9*orf4
"
```

```{r}
quadGrowthFit <- growth(quadGrowthSyn, data = orf, fixed.x = FALSE)
```

If you get the following warning messages:

1: In lav_object_post_check(object) :
  lavaan WARNING: some estimated ov variances are negative

+ Use var1~~0*var2 to fix the (co)variances at 0

```{r}
quadGrowthSyn_noQuad <- "
	#int and slope factors
	I =~ 1*orf1 + 1*orf2 + 1*orf3 + 1*orf4
	S =~ 0*orf1 + 1*orf2 + 2*orf3 + 3*orf4
	#quadratic factor = slope^2
	quadS =~ 0*orf1 + 1*orf2 + 4*orf3 + 9*orf4
	
	quadS ~~ 0*quadS #restrict quadratic variance to 0
	quadS ~~ 0*I #restrict quadratic covariance with I to 0
	quadS ~~ 0*S #restrict quadratic covariance with S to 0
"
```

```{r}
quadGrowthNoquadFit <- growth(quadGrowthSyn_noQuad, 
                              data = orf, fixed.x = FALSE)
summary(quadGrowthNoquadFit, fit.measures = T)
```

```{r}
semPaths(quadGrowthNoquadFit, what='est', fade= F)
```

### 4. Latent basis growth model (extension of linear growth model)

+ Intercept loads on all variables with fixed loadings of 1.0
+ Slope loads on all variables with free loadings between 0 and t-1

```{r}
latentBasisSyn <- "
	#Int and slope specification
	I =~ 1*orf1 + 1*orf2 + 1*orf3 + 1*orf4
	
	#orf2 and orf3 are free in the latent basis specification
	S =~ 0*orf1 + alpha1*orf2 + alpha2*orf3 + 3*orf4
"
```

```{r}
latentBasisFit <- growth(latentBasisSyn, 
                         data = orf, 
                         fixed.x = FALSE)
summary(latentBasisFit, fit.measures = T)
```

```{r}
semPaths(latentBasisFit, what='est', fade= F)
```

RMSEA failed us...
one approach is to use model modification indices: 

```{r,warning=FALSE}
modindices(latentBasisFit,sort. = T)
```

Another approach is to use Spline Growth Model.

### 5. Spline Growth Model

```{r}
splineGrowthSyn <- "
	#Specify Latent Intercept and Slope
	I =~ 1*orf1 + 1*orf2 + 1*orf3 + 1*orf4
	S =~ 0*orf1 + 1*orf2 + 2*orf3 + 3*orf4

	#summer is the spline variable
	summer =~ 0*orf1 + 0*orf2 + 1*orf3 + 1*orf4

	#Summer gets a mean but no variance
	summer ~ 1
	summer ~~ 0*summer

	#Summer is uncorrelated with I and S
	summer ~~ 0*I 
	summer ~~ 0*S 
"
```

```{r}
splineGrowthFit <- growth(splineGrowthSyn, data = orf, fixed.x = FALSE)
summary(splineGrowthFit, fit.measures = T)
```

```{r}
semPaths(splineGrowthFit, what='est', fade= F)
```

### Model Comparison

```{r}
lavTestLRT(noGrowthFit, linearGrowthFit)
```

+ Linear Growth Model fits significantly better than No Growth Model

```{r}
lavTestLRT(linearGrowthFit, quadGrowthNoquadFit)
```

+ Linear Growth Model fits almost the same as the Quadratic Growth Model (keep linear model due to parsimony principle)

```{r}
lavTestLRT(linearGrowthFit, latentBasisFit)
```

+ Latent Basis Model fits significantly better than Linear Growth Model

```{r}
lavTestLRT(linearGrowthFit, splineGrowthFit)
```

+ Spline Growth Model also fits significantly better than Linear Growth Model

### 6. Final Model: Spline Growth Model with a binary treatment predictor

```{r}
splineGrowthTreatmentPredictorSyn <- "
	#Specify Latent Intercept and Slope
	I =~ 1*orf1 + 1*orf2 + 1*orf3 + 1*orf4
	S =~ 0*orf1 + 1*orf2 + 2*orf3 + 3*orf4

	#summer is the spline variable
	summer =~ 0*orf1 + 0*orf2 + 1*orf3 + 1*orf4

	#Summer gets a mean but no variance
	summer ~~ 0*summer

	#Summer is uncorrelated with I and S
	summer ~~ 0*I 
	summer ~~ 0*S 

	#Intercept, Slope, and Summer regressed on (predicted by) treatment
	I ~ treatmentDummy
	S ~ treatmentDummy
	summer ~ treatmentDummy
"
```

+ When including external predictors, we need to turn on fixed.x = T...
+ otherwise you'll get a warning message and misleading model fit:

```{r}
# do not do this:
splineGrowthTreatPredictorFit <- growth(splineGrowthTreatmentPredictorSyn, 
                                       data = orf, 
                                       fixed.x = F) # <- Here
```

Instead, turn on fixed.x = T:

```{r}
splineGrowthTreatPredictorFit <- growth(splineGrowthTreatmentPredictorSyn, 
                                       data = orf, 
                                       fixed.x = T) # <- Here
summary(splineGrowthTreatPredictorFit, fit.measures = T)
```

```{r}
semPaths(splineGrowthTreatPredictorFit, what='est', fade= F)
```


<!------------------------------>
## PART III: LGM on Latent Variables
<!------------------------------>

### Example

Please go over the checklist:

1. Make sure the latent variables satisfy longitudinal measurement invariance at the level of scalar invariance or above 
2. Use the loadings over time (i.e., metric invariance)
3. No need to correlate the latent factors
4. Add intercepts for all indicators EXCEPT for marker indicators
5. Add correlated residuals for repeated measures of the same indicators
6. Use std.lv = TRUE as the scaling method in growth()

For this example, we will use the dataset exLong from package semTools: 

```{r}
data(exLong)
head(exLong)
?exLong
```

The syntax for linear growth model with latent variables:

```{r}
exLinearGrowthsyn <- "
  
  # Use the loadings over time (i.e., metric invariance)
  f_t1 =~ lamb1*y1t1 + lamb2*y2t1 + lamb3*y3t1
  f_t2 =~ lamb1*y1t2 + lamb2*y2t2 + lamb3*y3t2
  f_t3 =~ lamb1*y1t3 + lamb2*y2t3 + lamb3*y3t3

  #Int and slope specification
	I =~ 1*f_t1 + 1*f_t2 + 1*f_t3
	S =~ 0*f_t1 + 1*f_t2 + 2*f_t3
	
	# Add intercepts for all indicators EXCEPT for marker indicators
  y2t1 ~ 1
  y3t1 ~ 1
  y2t2 ~ 1
  y3t2 ~ 1
	y2t3 ~ 1
  y3t3 ~ 1

	# Add correlated residuals for repeated measures of the same indicators
	y1t1 ~~ y1t2
	y1t1 ~~ y1t3
	y1t2 ~~ y1t3
	y2t1 ~~ y2t2
	y2t1 ~~ y2t3
	y2t2 ~~ y2t3
	y3t1 ~~ y3t2
	y3t1 ~~ y3t3
	y3t2 ~~ y3t3
"
```

Use std.lv = TRUE as the scaling method in growth():

```{r}
exLinearGrowthFit <- growth(exLinearGrowthsyn, 
                         data = exLong, 
                         fixed.x = FALSE,
                         std.lv = TRUE)
summary(exLinearGrowthFit, fit.measures = T)
```

```{r}
semPaths(exLinearGrowthFit, what='est', fade= F)
```

### Exercise

Q: Could you fit the latent basis model to the same dataset and compare the fit of the two models?

```{r}

```


<!--chapter:end:19-Growth_Models.Rmd-->

# Week15_1: Lavaan Lab 17 Second-order and Bifactor Models

In this lab, we will evaluate the dimensionality of ISMI-29 by fitting and comparing the following four models:

1. Unidimensional model (one-factor CFA)
2. Correlated factors model (multi-factor CFA)
3. Second-order factor model
4. Bifactor model 

Load up the lavaan and semPlot libraries:

```{r, message=FALSE}
library(lavaan)
library(semPlot)
```

+ In this lab, we will work with the ISMI-29 data that are collected using Internalized Stigma of Mental Illness Scale 
+ 758 participants and 29 items
+ Let's read in the dataset:

```{r}
ISMI29 = read.csv('ISMI-29 n758 (Hammer 16).csv', header = F)
```

Take a look at the dataset:

```{r}
head(ISMI29)
```

sample size:
```{r}
n <- nrow(ISMI29)
n #758
```

Factor structure: 

+ Item1-6: Alienation  “Having a mental illness has spoiled my life.”
+ Item7-13: Stereotype Endorsement  “Mentally ill people tend to be violent”
+ Item14-18: Discrimination Experience   “People discriminate against me because I have a mental illness”
+ Item19-24: Social Withdrawal   “I don’t talk about myself as much because I don’t want to burden others with my mental illness”
+ Item25-29: \*Stigma Resistance  (*reverse-coded) “I can have a good, fulfilling life, despite my mental illness”    

<!------------------------------>
## PART I: Unidimensional model
<!------------------------------>

Write out syntax for a one-factor CFA model: 

```{r}
uni.model = '
ISMI =~ V1+V2+V3+V4+V5+V6+V7+V8+V9+V10+V11+V12+V13+V14+V15+V16+V17+V18+V19+
        V20+V21+V22+V23+V24+V25+V26+V27+V28+V29
'
```

Fit the model:

+ It is recommended to fix the variances of all first- and second-order factors to be 1 (lavaan: std.lv = TRUE) and request standardized solutions;

```{r}
uni.model.fit = lavaan::sem(uni.model, 
                    data=ISMI29, 
                    ordered = colnames(ISMI29), 
                    std.lv = TRUE, 
                    fixed.x = F)
summary(uni.model.fit, standardized = TRUE, fit.measures = TRUE)
```

Plot the path diagram:

```{r}
semPaths(uni.model.fit, what = 'std', fade = F)
```

<!------------------------------>
## PART II: Correlated factors model
<!------------------------------>

Write out syntax for a five-factor CFA model: 

```{r}
cor.fac.model = '
Alienation =~ V1+V2+V3+V4+V5+V6
Stereotype =~ V7+V8+V9+V10+V11+V12+V13
Discrimination =~ V14+V15+V16+V17+V18
Withdrawal =~ V19+V20+V21+V22+V23+V24
Stigma =~ V25+V26+V27+V28+V29
'
```

```{r}
cor.fac.model.fit = lavaan::sem(cor.fac.model, 
                        data=ISMI29, 
                        ordered = colnames(ISMI29), 
                        std.lv = TRUE, 
                        fixed.x = F)

summary(cor.fac.model.fit, standardized = TRUE, fit.measures = TRUE)
```

```{r}
semPaths(cor.fac.model.fit, what = 'std', fade = F)
```


<!------------------------------>
## PART III: Second-order factor Model
<!------------------------------>

Write out syntax for a five-factor second-order CFA model: 

```{r}
secondfac.model = '
Alienation =~ V1+V2+V3+V4+V5+V6
Stereotype =~ V7+V8+V9+V10+V11+V12+V13
Discrimination =~ V14+V15+V16+V17+V18
Withdrawal =~ V19+V20+V21+V22+V23+V24
Stigma =~ V25+V26+V27+V28+V29

# Second-order factor ISMI
ISMI =~ Alienation + Stereotype + Discrimination + Withdrawal + Stigma
'
```

```{r}
secondfac.model.fit = lavaan::sem(secondfac.model, 
                          data=ISMI29, 
                          ordered = colnames(ISMI29), 
                          std.lv = TRUE, 
                          fixed.x = F)
summary(secondfac.model.fit, standardized = TRUE, fit.measures = TRUE)
```

```{r}
semPaths(secondfac.model.fit, what = 'std', fade = F)
```

<!------------------------------>
## PART IV: Bifactor Model
<!------------------------------>

```{r}
bifac.model = '
# specific factors
Alienation =~ V1+V2+V3+V4+V5+V6
Stereotype =~ V7+V8+V9+V10+V11+V12+V13
Discrimination =~ V14+V15+V16+V17+V18
Withdrawal =~ V19+V20+V21+V22+V23+V24
Stigma =~ V25+V26+V27+V28+V29

# general factor GEN
GEN =~ V1+V2+V3+V4+V5+V6+V7+V8+V9+V10+V11+V12+V13+V14+V15+V16+V17+V18+V19+
      V20+V21+V22+V23+V24+V25+V26+V27+V28+V29
'
```

When using sem() to fit a bifactor model, make sure to turn on 

+ orthogonal = TRUE to ensure that all specific factors and general factors are uncorrelated
+ otherwise, you'll get an error/warning saying that the model is not identified.

```{r}
bifac.model.fit = lavaan::sem(bifac.model, 
                      data=ISMI29, 
                      ordered = colnames(ISMI29), 
                      std.lv = TRUE, 
                      fixed.x = F,
                      orthogonal = TRUE)
```

```{r}
summary(bifac.model.fit, standardized = TRUE, fit.measures = TRUE)
```

```{r}
semPaths(bifac.model.fit, what = 'std', fade = F)
```


<!------------------------------>
## PART V: Model Comparison 
<!------------------------------>

```{r}
UniFactor = fitMeasures(uni.model.fit, fit.measures = c("chisq.scaled", "df.scaled", "pvalue.scaled", "rmsea.scaled", "rmsea.ci.lower.scaled", "rmsea.ci.upper.scaled", "cfi.scaled", "tli.scaled", "srmr_bentler"))
FiveFactor = fitMeasures(cor.fac.model.fit, fit.measures = c("chisq.scaled", "df.scaled", "pvalue.scaled", "rmsea.scaled", "rmsea.ci.lower.scaled", "rmsea.ci.upper.scaled", "cfi.scaled", "tli.scaled", "srmr_bentler"))
SecondOrder = fitMeasures(secondfac.model.fit, fit.measures = c("chisq.scaled", "df.scaled", "pvalue.scaled", "rmsea.scaled", "rmsea.ci.lower.scaled", "rmsea.ci.upper.scaled", "cfi.scaled", "tli.scaled", "srmr_bentler"))
Bifactor = fitMeasures(bifac.model.fit, fit.measures = c("chisq.scaled", "df.scaled", "pvalue.scaled", "rmsea.scaled", "rmsea.ci.lower.scaled", "rmsea.ci.upper.scaled", "cfi.scaled", "tli.scaled", "srmr_bentler"))
round(cbind(UniFactor, FiveFactor, SecondOrder, Bifactor), 3)
```

Bifactor model wins!


<!------------------------------>
## Exercise: Mental Ability Scale
<!------------------------------>

Let's bring our Holzinger and Swineford Dataset back: 

```{r}
head(HolzingerSwineford1939)
?HolzingerSwineford1939
```

This dataset has 301 cases with 9 mental ability items.

**Assignment: Could you use the four models above to examine the dimensionality of this ODD Subscale?**

Here is a factor structure that you may need: 

```{r}
cor.fac.HS.model = '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed   =~ x7 + x8 + x9
'
```

Good luck!

```{r}
bifac.model = '
# specific factors
visual  =~ x2 + x3 # remove x1 because of heywood case
textual =~ x4 + x5 + x6
speed   =~ x7 + x8 + x9

# general factor GEN
G =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9
'
bifac.model.fit = lavaan::sem(bifac.model, 
                      data=HolzingerSwineford1939, 
                      #ordered = colnames(odd), 
                      std.lv = TRUE, 
                      fixed.x = F,
                      orthogonal = TRUE,
                      estimator = 'MLR')
lavaan:::summary(bifac.model.fit, standardized = TRUE, fit.measures = TRUE)
```


<!--chapter:end:20-HigherOrder_Bifactor.Rmd-->

# Week15_2: Lavaan Lab 18 CFA of MTMM Matrix

In this lab, we will:
    
+ run CFA on MTMM Matrix to investigate convergent and discrimative validity 

Load up the lavaan and semPlot libraries:

```{r, message=FALSE}
library(lavaan)
library(semPlot)
```

+ Let's read in a simulated MTMM matrix:

```{r}
load("MTMM.RData")
```

Take a look at the matrix:

```{r}
dim(MTMM)
head(MTMM)
```
This is a covariance matrix. You could also convert it to a correlation matrix: 

```{r}
cov2cor(MTMM)
```


<!------------------------------>
## PART I: Correlated methods specification 
<!------------------------------>

This model specifies both traits and methods factors:

```{r}
MTMM.model.spec1.wrong <- '
# trait factors

paranoid =~ PARI +  PARC + PARO   
schizotypal =~ SZTI + SZTC + SZTO
schizoid =~ SZDI + SZDC + SZDO

# method factors

inventory =~ SZTI + PARI + SZDI
clininter =~ PARC + SZTC + SZDC
obsrating =~ PARO + SZTO + SZDO
'
```

Fit the model:

+ Since MTMM is a covariance matrix, we supply the sample size 500;

```{r}
fit1 <- lavaan::sem(MTMM.model.spec1.wrong, 
            sample.cov=MTMM, sample.nobs=500,
            fixed.x = F)
```

You might get the following warning message:

```{r, eval=FALSE}
Warning message:
  In lavaan::lavaan(model = MTMM.model.spec1.wrong, sample.cov = MTMM,  :
        lavaan WARNING:
        the optimizer (NLMINB) claimed the model converged, but not all
        elements of the gradient are (near) zero; the optimizer may not
        have found a local solution use check.gradient = FALSE to skip
        this check.                        
```

+ The problem is by default lavaan correlates all traits and methods factors; 
+ To get the model to fit, we need to manually uncorrelate traits and methods factors;

```{r}
MTMM.model.spec1 <- '
# trait factors

paranoid =~ PARI +  PARC + PARO   
schizotypal =~ SZTI + SZTC + SZTO
schizoid =~ SZDI + SZDC + SZDO

# method factors

inventory =~ SZTI + PARI + SZDI
clininter =~ PARC + SZTC + SZDC
obsrating =~ PARO + SZTO + SZDO

# uncorrelated trait and method

paranoid ~~ 0*inventory
paranoid ~~ 0*clininter
paranoid ~~ 0*obsrating
schizotypal ~~ 0*inventory
schizotypal ~~ 0*clininter
schizotypal ~~ 0*obsrating
schizoid ~~ 0*inventory
schizoid ~~ 0*clininter
schizoid ~~ 0*obsrating
'
```

Model fit:

```{r}
fit2 <- lavaan::sem(MTMM.model.spec1, 
            sample.cov=MTMM, sample.nobs=500,
            fixed.x = F)

summary(fit2, standardized = T, fit.measures = T)
```

```{r, eval=FALSE}
Heywood case
Warning messages:
1: In lav_object_post_check(object) :
  lavaan WARNING: some estimated ov variances are negative
```

Plot the path diagram:

```{r}
semPaths(fit2, what='std', 
         nCharNodes = 0,
         nCharEdges = 0, # don't limit variable name lengths
         curvePivot = TRUE, 
         curve = 1.1, # pull covariances' curves out a little
         fade=FALSE)
```


<!------------------------------>
## PART II: Correlated uniqueness specification
<!------------------------------>

In this specification: 

+ There is no method factor;
+ Instead, the unique factors are correlated within method blocks; 

```{r}
MTMM.model.spec2 <- '
# trait factors

paranoid =~ PARI + PARC + PARO   
schizotypal =~ SZTI + SZTC + SZTO
schizoid =~ SZDI + SZDC + SZDO

# no method factors

# correlated residual covariances

# Method 1 Block
PARI ~~ SZTI + SZDI
SZTI ~~ SZDI

# Method 2 Block
PARC ~~ SZTC + SZDC
SZTC ~~ SZDC

# Method 3 Block
PARO ~~ SZTO + SZDO
SZTO ~~ SZDO
'
```

Model fit:

```{r}
fit3 <- lavaan::sem(MTMM.model.spec2, 
            sample.cov=MTMM, sample.nobs=500,
            fixed.x = F, std.lv = T)

#results with standardized parameter estimates
summary(fit3, standardized=TRUE, fit.measures=TRUE)
```

```{r}
semPaths(fit3, what='std', 
         nCharNodes = 0,
         nCharEdges = 0, # don't limit variable name lengths
         curvePivot = TRUE, 
         curve = 1.1, # pull covariances' curves out a little
         fade=FALSE)
```



<!--chapter:end:21-MTMM.Rmd-->

# Week16: Lavaan Lab 19 Multilevel SEM

In this lab, we will:
    
+ build a multilevel CFA model 
+ add covariates at both the between and the within level

Load up the lavaan library:

```{r, message=FALSE}
library(lavaan)
```

Let's read in a Mplus example dataset from an online location

```{r}
Data <- read.table("http://statmodel.com/usersguide/chap9/ex9.6.dat")
names(Data) <- c("y1", "y2", "y3", "y4", "x1", "x2", "w", "clus")
```

Take a look at the matrix:

```{r}
head(Data)
dim(Data)
length(unique(Data$clus))
```

+ there are 1000 individual observations in 110 clusters
+ cluster sizes: 5, 10, 15
+ 4 measures at the within level y1, y2, y3, y4
+ 2 covariates at the within level: x1, x2
+ 1 covariate at the between level: w

<!------------------------------>
## PART I: Multilevel CFA 1: within-only construct
<!------------------------------>

This model specifies the latent variable only at the within level:

```{r}
model1 <- '
  level: 1
    fw =~ y1 + y2 + y3 + y4

  level: 2
    y1 ~~ y1 + y2 + y3 + y4
    y2 ~~ y2 + y2 + y3
    y3 ~~ y3 + y4
    y4 ~~ y4

    # all variances and covariances are freely estimated
'
```

Fit the model:

```{r}
model1fit <- lavaan::sem(model1, data = Data, 
                         cluster = "clus",
                         estimator = 'MLR',
                         fixed.x = FALSE)

lavaan::summary(model1fit, fit.measures = T, standardized = T)
```

<!------------------------------>
## PART II: Multilevel CFA 2: Between-only construct
<!------------------------------>

+ Example: construct reflects self-reported ‘school climate’ measured by a questionnaire filled in by the school principles
+ We will only have one response for each school 
+ We may collect other variables from students/teachers in the schools though

Note that the following model syntax:

```{r, eval=FALSE}
model2.wrong <- '
  level: 1
  # perhaps other level-1 variables

  level: 2
    fb =~ y1 + y2 + y3 + y4
'

model2fit <- lavaan::sem(model2.wrong, data = Data, 
                         cluster = "clus",
                         estimator = 'MLR',
                         fixed.x = FALSE)
```

```{r, eval=FALSE}
Error in lav_partable_vnames(tmp.lav, type = "ov", level = tmp.level.values[l]) : lavaan ERROR: level column does not contain value `1'
```

won't work because there is nothing at level 1. Instead, specify this model just like a regular CFA model:

```{r}
model2 <- '
    fb =~ y1 + y2 + y3 + y4
'
```


Fit the model:

```{r}
model2fit <- lavaan::sem(model2, data = Data, 
                         cluster = "clus",
                         estimator = 'MLR',
                         fixed.x = FALSE)

lavaan::summary(model2fit, fit.measures = T, standardized = T)
```


<!------------------------------>
## PART III: Multilevel CFA 3: Shared cross-level construct
<!------------------------------>

+ This model specifies the latent variable both at the within and the between level;
+ However, the latent variable only makes sense at the between level so SEM model is only built at the between level;
+ The indicators are correlated at the within level; 

```{r m3}
model3 <- '
  level: 1
    y1 ~~ y1 + y2 + y3 + y4
    y2 ~~ y2 + y3 + y4
    y3 ~~ y3 + y4
    y4 ~~ y4

  level: 2
    fs =~ y1 + y2 + y3 + y4

 # Fix Significant Heywood Cases
  y2 ~~ v2*y2
  y4 ~~ v4*y4
  v2 > 0
  v4 > 0 
'
```

Fit the model:

```{r m3fit}
model3fit <- lavaan::sem(model3, data = Data, 
                         cluster = "clus",
                         estimator = 'MLR',
                         fixed.x = FALSE)

lavaan::summary(model3fit, standardized = T, fit.measures = T)
```


<!------------------------------>
## PART IV: Multilevel CFA 4: Configural construct
<!------------------------------>

+ Model 4a specifies the latent variable both at the within and the between level;
+ The CFA at each level should have the same factor structure, but not necessarily the same parameter estimates;

```{r}
model4a <- '
  level: 1
    fw =~ y1 + y2 + y3 + y4

  level: 2
    fb =~ y1 + y2 + y3 + y4
'

model4afit <- lavaan::sem(model4a, data = Data, 
                         cluster = "clus",
                         estimator = 'MLR',
                         fixed.x = FALSE)

lavaan::summary(model4afit, fit.measures = T, standardized = T)
```

+ Model 4b specifies the same CFA at each level and requires the same factor loadings;

```{r}
model4b <- '
  level: 1
    fw =~ a*y1 + b*y2 + c*y3 + d*y4

  level: 2
    fb =~ a*y1 + b*y2 + c*y3 + d*y4
'

model4bfit <- lavaan::sem(model4b, data = Data, 
                         cluster = "clus",
                         estimator = 'MLR',
                         fixed.x = FALSE)

lavaan::summary(model4bfit, fit.measures = T, standardized = T)
```


<!------------------------------>
## PART V: Multilevel CFA 5: Shared + Configural construct
<!------------------------------>

+ This model specifies the latent variable both at the within and the between level;
+ The CFA at each level should have the same factor structure, but not necessarily the same parameter estimates;

```{r}
model5 <- '
  level: 1
    fw =~ a*y1 + b*y2 + c*y3 + d*y4

  level: 2
    fb =~ a*y1 + b*y2 + c*y3 + d*y4   # configural
    fs =~ y1 + y2 + y3 + y4           # shared
    
    # fb and fs must be orthogonal
    fs ~~ 0*fb
'

model5fit <- lavaan::sem(model5, data = Data, 
                         cluster = "clus",
                         estimator = 'MLR',
                         fixed.x = FALSE)

lavaan::summary(model5fit, fit.measures = T, standardized = T)
```


<!------------------------------>
## PART VI: Model Comparison 
<!------------------------------>

```{r}
m1 = fitMeasures(model1fit, fit.measures = c("chisq.scaled", "df.scaled", "pvalue.scaled", "rmsea.robust", "rmsea.ci.lower.robust", "rmsea.ci.upper.robust", "cfi.robust", "tli.robust", "srmr_within", "srmr_between"))
m2 = fitMeasures(model2fit, fit.measures = c("chisq.scaled", "df.scaled", "pvalue.scaled", "rmsea.robust", "rmsea.ci.lower.robust", "rmsea.ci.upper.robust", "cfi.robust", "tli.robust", "srmr_within", "srmr_between"))
m3 = fitMeasures(model3fit, fit.measures = c("chisq.scaled", "df.scaled", "pvalue.scaled", "rmsea.robust", "rmsea.ci.lower.robust", "rmsea.ci.upper.robust", "cfi.robust", "tli.robust", "srmr_within", "srmr_between"))
m4a = fitMeasures(model4afit, fit.measures = c("chisq.scaled", "df.scaled", "pvalue.scaled", "rmsea.robust", "rmsea.ci.lower.robust", "rmsea.ci.upper.robust", "cfi.robust", "tli.robust", "srmr_within", "srmr_between"))
m4b = fitMeasures(model4bfit, fit.measures = c("chisq.scaled", "df.scaled", "pvalue.scaled", "rmsea.robust", "rmsea.ci.lower.robust", "rmsea.ci.upper.robust", "cfi.robust", "tli.robust", "srmr_within", "srmr_between"))
m5 = fitMeasures(model5fit, fit.measures = c("chisq.scaled", "df.scaled", "pvalue.scaled", "rmsea.robust", "rmsea.ci.lower.robust", "rmsea.ci.upper.robust", "cfi.robust", "tli.robust", "srmr_within", "srmr_between"))
```
```{r,message=FALSE}
#install.packages('qpcR')
library(qpcR)
round(qpcR:::cbind.na(m1, m2, m3, m4a, m4b, m5), 3)
```

The final model goes to (drumroll)...model4b!

<!------------------------------>
## PART VII: Adding Covariates to Multilevel SEM
<!------------------------------>

### Model A: Adding a within-only covariate

```{r}
model4wCovA <- '
  level: 1
    fw =~ a*y1 + b*y2 + c*y3 + d*y4
    fw ~ x1

  level: 2
    fb =~ a*y1 + b*y2 + c*y3 + d*y4
'

model4wCovAfit <- lavaan::sem(model4wCovA, data = Data, 
                              cluster = "clus", 
                              estimator = 'MLR',
                              fixed.x = FALSE)

lavaan::summary(model4wCovAfit, fit.measures = T, standardized = T)
```

### Model B: Adding a between-only covariate

```{r}
model4wCovB <- '
  level: 1
    fw =~ a*y1 + b*y2 + c*y3 + d*y4

  level: 2
    fb =~ a*y1 + b*y2 + c*y3 + d*y4
    fb ~ w
'

model4wCovBfit <- lavaan::sem(model4wCovB, data = Data, 
                              cluster = "clus", 
                              estimator = 'MLR',
                              fixed.x = FALSE)

lavaan::summary(model4wCovBfit, fit.measures = T, standardized = T)
```

### Model C: Adding a covariate at both levels

```{r}
model4wCovC <- '
  level: 1
    fw =~ a*y1 + b*y2 + c*y3 + d*y4
    fw ~ x1

  level: 2
    fb =~ a*y1 + b*y2 + c*y3 + d*y4
    fb ~ x1
'

model4wCovCfit <- lavaan::sem(model4wCovC, data = Data, 
                              cluster = "clus", 
                              estimator = 'MLR',
                              fixed.x = FALSE)

lavaan::summary(model4wCovCfit, fit.measures = T, standardized = T)
```


<!------------------------------>
## PART VII: Final Model
<!------------------------------>

```{r}
modelFinal <- '
  level: 1
    fw =~ a*y1 + b*y2 + c*y3 + d*y4
    fw ~ x1 + x2

  level: 2
    fb =~ a*y1 + b*y2 + c*y3 + d*y4
    fb ~ w
'

modelFinalfit <- lavaan::sem(modelFinal, data = Data, 
                              cluster = "clus", 
                              estimator = 'MLR',
                              fixed.x = FALSE)

lavaan::summary(modelFinalfit, fit.measures = T, standardized = T)
```


<!--chapter:end:22-MultilevelSEM.Rmd-->

