[["index.html", "EPSY:579 R Cookbook for SEM Chapter 1 Course", " EPSY:579 R Cookbook for SEM Gabriella Jiang QUERIES, University of Illinois at Urbana-Champaign Chapter 1 Course Structural Equation Modeling (SEM) is a general class of multivariate techniques that models relationships between latent variables and observed variables (“measurement models”) and relationships among latent variables (“structural models”) simultaneously. Students will learn the theoretical background of SEM as well as the techniques using programming language R. Topics covered in this class include mediation/moderation model; confirmatory factor analysis; model fit evaluation; multi-group SEM; latent growth modeling; MTMM model; and SEM with categorical variables. 4 graduate hours. No professional credit. Prerequisite: EPSY 580 and EPSY 581; or Equivalents. This site is supposed to serve as a repository for R codes used in lab sessions of this course in Spring 2022. *Disclaimer: Opinions are my own and not the views of my employer "],["r-exercises.html", "Chapter 2 R Exercises", " Chapter 2 R Exercises "],["week4_1-lavaan-lab-1-path-analysis-model.html", "Chapter 3 Week4_1: Lavaan Lab 1 Path Analysis Model 3.1 Reading-In and Working With Realistic Datasets In R 3.2 Sample Covariance Matrices using the cov() function 3.3 Installing Packages 3.4 Loading Packages (Libraries) That You Have Installed 3.5 Using Lavaan For Path Models 3.6 Plotting SEM model 3.7 Exercise: How would you fit the model in Saunders et al. (2016)?", " Chapter 3 Week4_1: Lavaan Lab 1 Path Analysis Model In this lab, we will learn how to: install a package called lavaan in R perform path analysis using the lavaan package 3.1 Reading-In and Working With Realistic Datasets In R 3.1.0.1 To begin, we will read the file that we will use for our SEM lab (eatingDisorderSimData.csv). Try running this function, as written: file.choose() Using the GUI (graphical user interface) window that pops up, select the file eatingDisorderSimData.csv This should produce a file path like this (note: below is a Mac version): /Your/File/Path/eatingDisorderSimData.csv You can copy this path into the read.csv and put it in the file = argument of the function: read.csv() is a function for reading in .csv files. Assign the name labData to the dataset in R using &lt;- labData &lt;- read.csv(file = &quot;/Users/gejiang/Box Sync/MacSync/Teaching/590SEM/Spring 2022/Week 4/R/eatingDisorderSimData.csv&quot;, header = TRUE) Important Argument: header = if header = TRUE, indicates that your dataset has column names that are to be read in separate from the data. if header = FALSE, indicates that your dataset does NOT have column names, and therefore the first row of the dataset should be read as data. 3.1.0.2 Or you could NEST the file.choose() function inside the read.csv function labData &lt;- read.csv(file = file.choose(), header = T) Because file.choose() returns the file path, putting this inside the read.csv function is the same as writing the path inside the function! 3.1.0.3 Pros and Cons of writing the full file path vs. using read.csv(file = file.choose(), header = T) If you write down the full file path and put it in the function, then the next time you run this R script you can easily read in your data without searching through your directories and folders. However, if you move your file to a different folder in the future, you’ll need to change the directory path in your R script. file.choose() is very easy and user-friendly. Using this method allows you to find your datafile even if you’ve moved it to a different folder. However, it is slightly more effortful to go in and select your folder each time. 3.1.0.4 Gabriella recommends: Set your working directory to the directory that contains the dataset, and simply load your data by typing the name of the .csv file: setwd(&quot;~/Box Sync/MacSync/Teaching/590SEM/Spring 2022/Week 4/R&quot;) labData &lt;- read.csv(file = &quot;eatingDisorderSimData.csv&quot;, header = T, sep = &quot;,&quot;) This serves to save all your future analyses in your working directory. read.csv() is related to a broader function called read.table. The read.table function has a sep = argument sep = If sep = “,” this indicates a comma-separated (.csv) file If sep = ” ” this indicates a tab-delimited (“white space” delimited) file, such as a .txt 3.1.0.5 Finally, point and click always works… library(readr) eatingDisorderSimData &lt;- read_csv(&quot;eatingDisorderSimData.csv&quot;) View(eatingDisorderSimData) 3.2 Sample Covariance Matrices using the cov() function 3.2.0.1 Quick review: str(labData) #structure ## &#39;data.frame&#39;: 1339 obs. of 7 variables: ## $ BMI : num 0.377 0.302 -1.098 -1.13 -2.797 ... ## $ SelfEsteem : num 0.0685 -0.3059 1.4755 -0.1329 1.3538 ... ## $ Accu : num 1.782 0.491 -0.682 2.224 0.892 ... ## $ DietSE : num -0.0544 -2.3957 0.168 1.1851 0.5131 ... ## $ Restrictive: num -0.525 2.067 0.364 -1.656 0.743 ... ## $ Bulimia : num 0.432 0.196 -1.434 -0.675 -0.858 ... ## $ Risk : num 0.508 0.91 -0.777 -0.554 -0.314 ... head(labData) #first few lines ## BMI SelfEsteem Accu DietSE Restrictive Bulimia Risk ## 1 0.3769721 0.0685226 1.7822103 -0.05436952 -0.5251424 0.4322272 0.50794715 ## 2 0.3015484 -0.3058876 0.4909857 -2.39569010 2.0671867 0.1959765 0.90996098 ## 3 -1.0980232 1.4754543 -0.6819827 0.16801384 0.3638750 -1.4337656 -0.77678045 ## 4 -1.1304059 -0.1329290 2.2235223 1.18505959 -1.6557519 -0.6748446 -0.55411733 ## 5 -2.7965343 1.3537804 0.8922687 0.51311551 0.7431860 -0.8575733 -0.31385631 ## 6 0.7205735 -1.9361462 -1.0307704 0.79749119 -1.8609143 0.3290163 0.08012833 colnames(labData) #column names ## [1] &quot;BMI&quot; &quot;SelfEsteem&quot; &quot;Accu&quot; &quot;DietSE&quot; &quot;Restrictive&quot; &quot;Bulimia&quot; &quot;Risk&quot; How many observations are in this dataset? Number of observations = number of rows, with 1 person per row nrow(labData) #1339 ## [1] 1339 let’s save this number as n n &lt;- nrow(labData) Let’s look at the sample covariance matrix of these variables using the cov() function: cov(labData) ## BMI SelfEsteem Accu DietSE Restrictive Bulimia Risk ## BMI 1.07399214 -0.1380786 -0.02076620 -0.10688665 -0.13056197 0.16177119 0.07938074 ## SelfEsteem -0.13807862 1.0021547 0.03501750 0.10557111 -0.11991676 -0.31717764 -0.22864713 ## Accu -0.02076620 0.0350175 0.97176431 -0.02069863 -0.09050653 -0.09549788 -0.10327073 ## DietSE -0.10688665 0.1055711 -0.02069863 0.96607293 -0.15678475 -0.21922044 0.07119772 ## Restrictive -0.13056197 -0.1199168 -0.09050653 -0.15678475 1.01695732 0.58684522 0.78960193 ## Bulimia 0.16177119 -0.3171776 -0.09549788 -0.21922044 0.58684522 1.03637890 0.87337921 ## Risk 0.07938074 -0.2286471 -0.10327073 0.07119772 0.78960193 0.87337921 1.05356717 let’s save this sample cov as capital S: S = cov(labData) If we wanted, we could look at a subset of the dataset, e.g.,: cov(labData[,c(&quot;BMI&quot;, &quot;SelfEsteem&quot;, &quot;Accu&quot;)]) ## BMI SelfEsteem Accu ## BMI 1.0739921 -0.1380786 -0.0207662 ## SelfEsteem -0.1380786 1.0021547 0.0350175 ## Accu -0.0207662 0.0350175 0.9717643 This is often useful if our analysis will only contain certain variables. If only two variables: cov(labData$BMI, labData$SelfEsteem) ## [1] -0.1380786 If only one variable (variance): cov(labData$BMI, labData$BMI) ## [1] 1.073992 3.3 Installing Packages We will mostly be using the lavaan package to perform SEM analyses, so let’s use the install.packages() function to install it first install.packages(&quot;lavaan&quot;) lavaan stands for LAtent VAriable ANalysis using R. lavaan website: http://lavaan.ugent.be Check out the tutorials and examples! 3.4 Loading Packages (Libraries) That You Have Installed AFTER YOU’VE INSTALLED A PACKAGE ONE TIME, YOU DON’T HAVE TO EVER INSTALL IT AGAIN, UNLESS YOU DELETE AND REINSTALL R FOR SOME REASON. HOWEVER, NOW THAT THESE FUNCTIONS ARE INSTALLED IN R ON YOUR MACHINE, YOU MUST LOAD THE LIBRARY EVERY TIME YOU OPEN R AND WISH TO USE IT. To do this, use the library() function: library(lavaan) This is lavaan 0.6-9 lavaan is FREE software! Please report any bugs. Don’t worry about the “BETA” warning, this package is awesome! This may seem like a pain, but roll with it. The good news is that once you do it, you have access to a whole library of SEM functions. If you boot up R and receive error msgs like “could not find function”sem”” IT IS PROBABLY BECAUSE YOU HAVEN’T LOADED THE lavaan PACKAGE. Check out the help page of a particular function, say sem(): help(sem) ?sem 3.5 Using Lavaan For Path Models Every analysis in lavaan has three main parts. Part I: Writing the Model Syntax Part II: Analyzing the Model Using Your Dataset Part III: Examining the results. 3.5.1 PART I: Follow the set of equations we wrote in class: Self-Efficacy = BMI + Self-Esteem + Disturbance Bulimic Symptoms = BMI + Self-Esteem + Self-Efficacy + Disturbance Restrictive Symptoms = BMI + Self-Esteem + Self-Efficacy + Disturbance Overall Risk = BMI + Self-Esteem + Self-Efficacy + Acculturation + Disturbance Let’s write some model syntax: ex1PathSyntax &lt;- &quot; #opening a quote # Tilda ~ : Regression # M ~ X regression (X predicts M) # Each line corresponds to an equation # Disturbance is automatically included for each regression # (i.e. no extra term needed) DietSE ~ BMI + SelfEsteem #DietSE is predicted by BMI and SelfEsteem Bulimia ~ DietSE + BMI + SelfEsteem Restrictive ~ DietSE + BMI + SelfEsteem Risk ~ DietSE + BMI + SelfEsteem + Accu &quot; Things to note here: We are calling our saved model syntax object ex1PathSyntax We assign it using &lt;- as usual Then we open a quotation ” Then we write each part of the model on separate lines. Then we close the quotation ” The variables names need to match those in the dataset (case matters!) Add comments inside the model syntax using hashtag 3.5.2 PART II Let’s run our model! To run this model, we will start by using the sem() function. Sensible defaults for estimating CFA models like assumptions of linear regression, so we don’t actually have to write some constraints into the model above Alternatively, one can use lavaan() function [with the fewest default settings] or cfa() function [with similar defaults as sem() function] To use lavaan(), you have to specify all 22 parameters in the model. 3.5.2.1 ex1fit You can run the sem() function using two different sources of data: The raw dataset, using: sem(model = modelSyntax, data = yourDataset) example: ex1fit &lt;- sem(model = ex1PathSyntax, data = labData) If you encounter errors like: Error in if ((!is.matrix(model)) | ncol(model) != 3) stop(“model argument must be a 3-column matrix”) : argument is of length zero IT IS PROBABLY BECAUSE YOU HAVEN’T LOADED THE lavaan PACKAGE. To make sure you are using the sem() function from the lavaan package, add PackageName:: before a function: ex1fit &lt;- lavaan::sem(model = ex1PathSyntax, data = labData) Then we can obtain complete results using the summary() function: summary(ex1fit) ## lavaan 0.6-10 ended normally after 36 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 19 ## ## Number of observations 1339 ## ## Model Test User Model: ## ## Test statistic 16.429 ## Degrees of freedom 3 ## P-value (Chi-square) 0.001 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## DietSE ~ ## BMI -0.088 0.026 -3.381 0.001 ## SelfEsteem 0.093 0.027 3.480 0.001 ## Bulimia ~ ## DietSE -0.185 0.026 -6.994 0.000 ## BMI 0.096 0.025 3.796 0.000 ## SelfEsteem -0.284 0.026 -10.871 0.000 ## Restrictive ~ ## DietSE -0.166 0.027 -6.039 0.000 ## BMI -0.154 0.026 -5.892 0.000 ## SelfEsteem -0.123 0.027 -4.561 0.000 ## Risk ~ ## DietSE 0.105 0.028 3.766 0.000 ## BMI 0.055 0.027 2.057 0.040 ## SelfEsteem -0.232 0.028 -8.425 0.000 ## Accu 0.007 0.009 0.783 0.434 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .Bulimia ~~ ## .Restrictive 0.536 0.029 18.389 0.000 ## .Risk 0.814 0.034 23.983 0.000 ## .Restrictive ~~ ## .Risk 0.785 0.034 22.996 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .DietSE 0.946 0.037 25.875 0.000 ## .Bulimia 0.890 0.034 25.875 0.000 ## .Restrictive 0.955 0.037 25.875 0.000 ## .Risk 0.989 0.038 25.875 0.000 The covariance matrix, using: sem(model = modelSyntax, sample.cov = yourCovarianceMatrix, sample.nobs = numberOfObservationsInYourDataset) This is to illustrate that WITH COMPLETE DATA, you can run SEM analyses using only covariances as input and obtain the same results as with raw data! This positions SEM for meta-analysis and replication studies. example: ex1fit_S &lt;- lavaan::sem(model = ex1PathSyntax, sample.cov = S, sample.nobs = n) summary(ex1fit_S) ## lavaan 0.6-10 ended normally after 36 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 19 ## ## Number of observations 1339 ## ## Model Test User Model: ## ## Test statistic 16.429 ## Degrees of freedom 3 ## P-value (Chi-square) 0.001 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## DietSE ~ ## BMI -0.088 0.026 -3.381 0.001 ## SelfEsteem 0.093 0.027 3.480 0.001 ## Bulimia ~ ## DietSE -0.185 0.026 -6.994 0.000 ## BMI 0.096 0.025 3.796 0.000 ## SelfEsteem -0.284 0.026 -10.871 0.000 ## Restrictive ~ ## DietSE -0.166 0.027 -6.039 0.000 ## BMI -0.154 0.026 -5.892 0.000 ## SelfEsteem -0.123 0.027 -4.561 0.000 ## Risk ~ ## DietSE 0.105 0.028 3.766 0.000 ## BMI 0.055 0.027 2.057 0.040 ## SelfEsteem -0.232 0.028 -8.425 0.000 ## Accu 0.007 0.009 0.783 0.434 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .Bulimia ~~ ## .Restrictive 0.536 0.029 18.389 0.000 ## .Risk 0.814 0.034 23.983 0.000 ## .Restrictive ~~ ## .Risk 0.785 0.034 22.996 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .DietSE 0.946 0.037 25.875 0.000 ## .Bulimia 0.890 0.034 25.875 0.000 ## .Restrictive 0.955 0.037 25.875 0.000 ## .Risk 0.989 0.038 25.875 0.000 The . before a variable name refers to its disturbance. e.g., .Bulimia refers to the disturbance of Bulimia, not Bulimia itself You should get exactly the same output in ex1fit and ex1fit_S. Wait, Gabriella, the df is not 6…. This is because sem() by default assumes that disturbances of endogenous variables covary among themselves (which, in our model, are not correlated at all!) The estimates of disturbance covariances are presented under “Covariances” in the output: Covariances: Estimate Std.Err z-value P(&gt;|z|) .Bulimia ~~ .Restrictive 0.536 0.029 18.389 0.000 .Risk 0.814 0.034 23.983 0.000 .Restrictive ~~ .Risk 0.785 0.034 22.996 0.000 3.5.2.2 ex1PathSyntax_noCov To change those defaults, one needs to explicitly fix those disturbance covariances at 0 (this is a strong assumption, I know…): http://lavaan.ugent.be/tutorial/syntax2.html ex1PathSyntax_noCov &lt;- &quot; #opening a quote # ~~ indicates a two-headed arrow (variance or covariance) # 0* in front of the 2nd variable fixes the covariance at 0 DietSE ~ BMI + SelfEsteem #DietSE is predicted by BMI and SelfEsteem Bulimia ~ DietSE + BMI + SelfEsteem Restrictive ~ DietSE + BMI + SelfEsteem Risk ~ DietSE + BMI + SelfEsteem + Accu #Disturbance covariances (fixed at 0): DietSE ~~ 0*Bulimia DietSE ~~ 0*Restrictive DietSE ~~ 0*Risk Bulimia ~~ 0*Restrictive Bulimia ~~ 0*Risk Restrictive ~~ 0*Risk # These lines above say that there is no covariance among the disturbances of all endogenous variables &quot; ex1fit_noCov &lt;- lavaan::sem(model = ex1PathSyntax_noCov, data = labData) summary(ex1fit_noCov) ## lavaan 0.6-10 ended normally after 1 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 16 ## ## Number of observations 1339 ## ## Model Test User Model: ## ## Test statistic 3536.813 ## Degrees of freedom 6 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## DietSE ~ ## BMI -0.088 0.026 -3.381 0.001 ## SelfEsteem 0.093 0.027 3.480 0.001 ## Bulimia ~ ## DietSE -0.185 0.026 -6.994 0.000 ## BMI 0.096 0.025 3.796 0.000 ## SelfEsteem -0.284 0.026 -10.871 0.000 ## Restrictive ~ ## DietSE -0.166 0.027 -6.039 0.000 ## BMI -0.154 0.026 -5.892 0.000 ## SelfEsteem -0.123 0.027 -4.561 0.000 ## Risk ~ ## DietSE 0.102 0.028 3.686 0.000 ## BMI 0.053 0.026 2.000 0.045 ## SelfEsteem -0.228 0.027 -8.332 0.000 ## Accu -0.095 0.027 -3.449 0.001 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .DietSE ~~ ## .Bulimia 0.000 ## .Restrictive 0.000 ## .Risk 0.000 ## .Bulimia ~~ ## .Restrictive 0.000 ## .Risk 0.000 ## .Restrictive ~~ ## .Risk 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .DietSE 0.946 0.037 25.875 0.000 ## .Bulimia 0.890 0.034 25.875 0.000 ## .Restrictive 0.955 0.037 25.875 0.000 ## .Risk 0.979 0.038 25.875 0.000 df = 6 and Covariances: Estimate Std.Err z-value P(&gt;|z|) .DietSE ~~ .Bulimia 0.000 .Restrictive 0.000 .Risk 0.000 .Bulimia ~~ .Restrictive 0.000 .Risk 0.000 .Restrictive ~~ .Risk 0.000 Wait, where are the variances and covariances of exogenous variables? They are not included in the output because they are estimated PERFECTLY 3.5.2.3 ex1fit_noCov_freeX fixed.x=FALSE asks for the variances/covariances/means of the exogenous variables to be freely estimated instead of being fixed at the values found from the sample This usually makes no difference from ex1fit_noCov, except that it prints more lines ex1fit_noCov_freeX &lt;- lavaan::sem(model = ex1PathSyntax_noCov, data = labData, fixed.x = FALSE) summary(ex1fit_noCov_freeX) ## lavaan 0.6-10 ended normally after 1 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 22 ## ## Number of observations 1339 ## ## Model Test User Model: ## ## Test statistic 3536.813 ## Degrees of freedom 6 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## DietSE ~ ## BMI -0.088 0.026 -3.381 0.001 ## SelfEsteem 0.093 0.027 3.480 0.001 ## Bulimia ~ ## DietSE -0.185 0.026 -6.994 0.000 ## BMI 0.096 0.025 3.796 0.000 ## SelfEsteem -0.284 0.026 -10.871 0.000 ## Restrictive ~ ## DietSE -0.166 0.027 -6.039 0.000 ## BMI -0.154 0.026 -5.892 0.000 ## SelfEsteem -0.123 0.027 -4.561 0.000 ## Risk ~ ## DietSE 0.102 0.028 3.686 0.000 ## BMI 0.053 0.026 2.000 0.045 ## SelfEsteem -0.228 0.027 -8.332 0.000 ## Accu -0.095 0.027 -3.449 0.001 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .DietSE ~~ ## .Bulimia 0.000 ## .Restrictive 0.000 ## .Risk 0.000 ## .Bulimia ~~ ## .Restrictive 0.000 ## .Risk 0.000 ## .Restrictive ~~ ## .Risk 0.000 ## BMI ~~ ## SelfEsteem -0.138 0.029 -4.828 0.000 ## Accu -0.021 0.028 -0.744 0.457 ## SelfEsteem ~~ ## Accu 0.035 0.027 1.298 0.194 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .DietSE 0.946 0.037 25.875 0.000 ## .Bulimia 0.890 0.034 25.875 0.000 ## .Restrictive 0.955 0.037 25.875 0.000 ## .Risk 0.979 0.038 25.875 0.000 ## BMI 1.073 0.041 25.875 0.000 ## SelfEsteem 1.001 0.039 25.875 0.000 ## Accu 0.971 0.038 25.875 0.000 3.5.2.4 ex1fit_noCov_lavaan As a bonus, here is how you would write the model syntax if you use lavaan() instead of sem()… ex1PathSyntax_lavaan &lt;- &quot; #opening a quote # ~~ indicates a two-headed arrow (variance or covariance) #regression coefficients (12) DietSE ~ BMI + SelfEsteem Bulimia ~ DietSE + BMI + SelfEsteem Restrictive ~ DietSE + BMI + SelfEsteem Risk ~ DietSE + BMI + SelfEsteem + Accu #variances of exogenous variables (3) BMI ~~ BMI SelfEsteem ~~ SelfEsteem Accu ~~ Accu #disturbance variances (4) DietSE ~~ DietSE Bulimia ~~ Bulimia Restrictive ~~ Restrictive Risk ~~ Risk #covariances among exogenous variables (3) BMI ~~ SelfEsteem BMI ~~ Accu SelfEsteem ~~ Accu #total: 22 parameters &quot; ex1fit_noCov_lavaan &lt;- lavaan(model = ex1PathSyntax_lavaan, data = labData) summary(ex1fit_noCov_lavaan) ## lavaan 0.6-10 ended normally after 11 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 22 ## ## Number of observations 1339 ## ## Model Test User Model: ## ## Test statistic 3536.813 ## Degrees of freedom 6 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## DietSE ~ ## BMI -0.088 0.026 -3.381 0.001 ## SelfEsteem 0.093 0.027 3.480 0.001 ## Bulimia ~ ## DietSE -0.185 0.026 -6.994 0.000 ## BMI 0.096 0.025 3.796 0.000 ## SelfEsteem -0.284 0.026 -10.871 0.000 ## Restrictive ~ ## DietSE -0.166 0.027 -6.039 0.000 ## BMI -0.154 0.026 -5.892 0.000 ## SelfEsteem -0.123 0.027 -4.561 0.000 ## Risk ~ ## DietSE 0.102 0.028 3.686 0.000 ## BMI 0.053 0.026 2.000 0.045 ## SelfEsteem -0.228 0.027 -8.332 0.000 ## Accu -0.095 0.027 -3.449 0.001 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## BMI ~~ ## SelfEsteem -0.138 0.029 -4.828 0.000 ## Accu -0.021 0.028 -0.744 0.457 ## SelfEsteem ~~ ## Accu 0.035 0.027 1.298 0.194 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## BMI 1.073 0.041 25.875 0.000 ## SelfEsteem 1.001 0.039 25.875 0.000 ## Accu 0.971 0.038 25.875 0.000 ## .DietSE 0.946 0.037 25.875 0.000 ## .Bulimia 0.890 0.034 25.875 0.000 ## .Restrictive 0.955 0.037 25.875 0.000 ## .Risk 0.979 0.038 25.875 0.000 which yields the same output as ex1fit_noCov_freeX. 3.5.3 Sigma Matrices Let’s have a look at the model-implied covarinace matrix from our final model ex1fit_noCov_freeX and save it as Sigma: fitted(ex1fit_noCov_freeX) ## $cov ## DietSE Bulimi Rstrct Risk BMI SlfEst Accu ## DietSE 0.965 ## Bulimia -0.219 1.036 ## Restrictive -0.157 0.051 1.016 ## Risk 0.069 0.060 0.005 1.052 ## BMI -0.107 0.162 -0.130 0.079 1.073 ## SelfEsteem 0.105 -0.317 -0.120 -0.228 -0.138 1.001 ## Accu 0.005 -0.013 -0.002 -0.101 -0.021 0.035 0.971 Sigma &lt;- fitted(ex1fit_noCov_freeX)$cov How close is Sigma to S? Rearrange the rows and columns of Sigma (important!) and take the difference diff = Sigma[colnames(S), colnames(S)] - S round(diff, 3) ## BMI SelfEsteem Accu DietSE Restrictive Bulimia Risk ## BMI -0.001 0.000 0.000 0.000 0.000 0.000 0.000 ## SelfEsteem 0.000 -0.001 0.000 0.000 0.000 0.000 0.000 ## Accu 0.000 0.000 -0.001 0.026 0.089 0.083 0.003 ## DietSE 0.000 0.000 0.026 -0.001 0.000 0.000 -0.002 ## Restrictive 0.000 0.000 0.089 0.000 -0.001 -0.536 -0.785 ## Bulimia 0.000 0.000 0.083 0.000 -0.536 -0.001 -0.814 ## Risk 0.000 0.000 0.003 -0.002 -0.785 -0.814 -0.001 How about the default model that include disturbance covariances? Sigma0 &lt;- fitted(ex1fit)$cov diff0 = Sigma0[colnames(S), colnames(S)] - S round(diff0, 3) ## BMI SelfEsteem Accu DietSE Restrictive Bulimia Risk ## BMI -0.001 0.000 0.000 0.000 0.000 0.000 0.000 ## SelfEsteem 0.000 -0.001 0.000 0.000 0.000 0.000 0.000 ## Accu 0.000 0.000 -0.001 0.026 0.089 0.083 0.101 ## DietSE 0.000 0.000 0.026 -0.001 0.000 0.000 0.000 ## Restrictive 0.000 0.000 0.089 0.000 -0.001 0.000 0.000 ## Bulimia 0.000 0.000 0.083 0.000 0.000 -0.001 0.000 ## Risk 0.000 0.000 0.101 0.000 0.000 0.000 0.001 3.5.3.1 Gabriella’s Practical Tips: To begin with, constraint the disturbance covariances to be 0 ; Keep the model if the model fits the data well; Relax the constraints the disturbance covariances if the initial model did not fit well. 3.5.4 PART III: Summarizing Our Analysis: There are some useful options we can ask for with summary(): summary(ex1fit_noCov_freeX, fit.measures = T) #include model fit measures summary(ex1fit_noCov_freeX, standardized = T) #This includes standardized estimates. std.all contains usual regression standardization. summary(ex1fit_noCov_freeX, ci = T) #Include confidence intervals # Add them all! If we JUST want the parameter estimates: parameterEstimates(ex1fit_noCov_freeX) ## lhs op rhs est se z pvalue ci.lower ci.upper ## 1 DietSE ~ BMI -0.088 0.026 -3.381 0.001 -0.138 -0.037 ## 2 DietSE ~ SelfEsteem 0.093 0.027 3.480 0.001 0.041 0.146 ## 3 Bulimia ~ DietSE -0.185 0.026 -6.994 0.000 -0.237 -0.133 ## 4 Bulimia ~ BMI 0.096 0.025 3.796 0.000 0.046 0.145 ## 5 Bulimia ~ SelfEsteem -0.284 0.026 -10.871 0.000 -0.335 -0.233 ## 6 Restrictive ~ DietSE -0.166 0.027 -6.039 0.000 -0.220 -0.112 ## 7 Restrictive ~ BMI -0.154 0.026 -5.892 0.000 -0.205 -0.103 ## 8 Restrictive ~ SelfEsteem -0.123 0.027 -4.561 0.000 -0.176 -0.070 ## 9 Risk ~ DietSE 0.102 0.028 3.686 0.000 0.048 0.157 ## 10 Risk ~ BMI 0.053 0.026 2.000 0.045 0.001 0.105 ## 11 Risk ~ SelfEsteem -0.228 0.027 -8.332 0.000 -0.282 -0.175 ## 12 Risk ~ Accu -0.095 0.027 -3.449 0.001 -0.149 -0.041 ## 13 DietSE ~~ Bulimia 0.000 0.000 NA NA 0.000 0.000 ## 14 DietSE ~~ Restrictive 0.000 0.000 NA NA 0.000 0.000 ## 15 DietSE ~~ Risk 0.000 0.000 NA NA 0.000 0.000 ## 16 Bulimia ~~ Restrictive 0.000 0.000 NA NA 0.000 0.000 ## 17 Bulimia ~~ Risk 0.000 0.000 NA NA 0.000 0.000 ## 18 Restrictive ~~ Risk 0.000 0.000 NA NA 0.000 0.000 ## 19 DietSE ~~ DietSE 0.946 0.037 25.875 0.000 0.874 1.018 ## 20 Bulimia ~~ Bulimia 0.890 0.034 25.875 0.000 0.822 0.957 ## 21 Restrictive ~~ Restrictive 0.955 0.037 25.875 0.000 0.883 1.028 ## 22 Risk ~~ Risk 0.979 0.038 25.875 0.000 0.905 1.054 ## 23 BMI ~~ BMI 1.073 0.041 25.875 0.000 0.992 1.154 ## 24 BMI ~~ SelfEsteem -0.138 0.029 -4.828 0.000 -0.194 -0.082 ## 25 BMI ~~ Accu -0.021 0.028 -0.744 0.457 -0.075 0.034 ## 26 SelfEsteem ~~ SelfEsteem 1.001 0.039 25.875 0.000 0.926 1.077 ## 27 SelfEsteem ~~ Accu 0.035 0.027 1.298 0.194 -0.018 0.088 ## 28 Accu ~~ Accu 0.971 0.038 25.875 0.000 0.897 1.045 parameterEstimates(ex1fit_noCov_freeX, standardized = T) #include standardized solution.... ## lhs op rhs est se z pvalue ci.lower ci.upper std.lv std.all std.nox ## 1 DietSE ~ BMI -0.088 0.026 -3.381 0.001 -0.138 -0.037 -0.088 -0.092 -0.089 ## 2 DietSE ~ SelfEsteem 0.093 0.027 3.480 0.001 0.041 0.146 0.093 0.095 0.095 ## 3 Bulimia ~ DietSE -0.185 0.026 -6.994 0.000 -0.237 -0.133 -0.185 -0.179 -0.179 ## 4 Bulimia ~ BMI 0.096 0.025 3.796 0.000 0.046 0.145 0.096 0.097 0.094 ## 5 Bulimia ~ SelfEsteem -0.284 0.026 -10.871 0.000 -0.335 -0.233 -0.284 -0.279 -0.279 ## 6 Restrictive ~ DietSE -0.166 0.027 -6.039 0.000 -0.220 -0.112 -0.166 -0.162 -0.162 ## 7 Restrictive ~ BMI -0.154 0.026 -5.892 0.000 -0.205 -0.103 -0.154 -0.158 -0.153 ## 8 Restrictive ~ SelfEsteem -0.123 0.027 -4.561 0.000 -0.176 -0.070 -0.123 -0.122 -0.122 ## 9 Risk ~ DietSE 0.102 0.028 3.686 0.000 0.048 0.157 0.102 0.098 0.098 ## 10 Risk ~ BMI 0.053 0.026 2.000 0.045 0.001 0.105 0.053 0.053 0.052 ## 11 Risk ~ SelfEsteem -0.228 0.027 -8.332 0.000 -0.282 -0.175 -0.228 -0.223 -0.223 ## 12 Risk ~ Accu -0.095 0.027 -3.449 0.001 -0.149 -0.041 -0.095 -0.091 -0.092 ## 13 DietSE ~~ Bulimia 0.000 0.000 NA NA 0.000 0.000 0.000 0.000 0.000 ## 14 DietSE ~~ Restrictive 0.000 0.000 NA NA 0.000 0.000 0.000 0.000 0.000 ## 15 DietSE ~~ Risk 0.000 0.000 NA NA 0.000 0.000 0.000 0.000 0.000 ## 16 Bulimia ~~ Restrictive 0.000 0.000 NA NA 0.000 0.000 0.000 0.000 0.000 ## 17 Bulimia ~~ Risk 0.000 0.000 NA NA 0.000 0.000 0.000 0.000 0.000 ## 18 Restrictive ~~ Risk 0.000 0.000 NA NA 0.000 0.000 0.000 0.000 0.000 ## 19 DietSE ~~ DietSE 0.946 0.037 25.875 0.000 0.874 1.018 0.946 0.980 0.980 ## 20 Bulimia ~~ Bulimia 0.890 0.034 25.875 0.000 0.822 0.957 0.890 0.859 0.859 ## 21 Restrictive ~~ Restrictive 0.955 0.037 25.875 0.000 0.883 1.028 0.955 0.940 0.940 ## 22 Risk ~~ Risk 0.979 0.038 25.875 0.000 0.905 1.054 0.979 0.931 0.931 ## 23 BMI ~~ BMI 1.073 0.041 25.875 0.000 0.992 1.154 1.073 1.000 1.073 ## 24 BMI ~~ SelfEsteem -0.138 0.029 -4.828 0.000 -0.194 -0.082 -0.138 -0.133 -0.138 ## 25 BMI ~~ Accu -0.021 0.028 -0.744 0.457 -0.075 0.034 -0.021 -0.020 -0.021 ## 26 SelfEsteem ~~ SelfEsteem 1.001 0.039 25.875 0.000 0.926 1.077 1.001 1.000 1.001 ## 27 SelfEsteem ~~ Accu 0.035 0.027 1.298 0.194 -0.018 0.088 0.035 0.035 0.035 ## 28 Accu ~~ Accu 0.971 0.038 25.875 0.000 0.897 1.045 0.971 1.000 0.971 For standardized solutions, there is also this function: standardizedSolution(ex1fit_noCov_freeX, type = &quot;std.all&quot;) ## lhs op rhs est.std se z pvalue ci.lower ci.upper ## 1 DietSE ~ BMI -0.092 0.027 -3.395 0.001 -0.146 -0.039 ## 2 DietSE ~ SelfEsteem 0.095 0.027 3.496 0.000 0.042 0.148 ## 3 Bulimia ~ DietSE -0.179 0.025 -7.093 0.000 -0.228 -0.129 ## 4 Bulimia ~ BMI 0.097 0.026 3.811 0.000 0.047 0.148 ## 5 Bulimia ~ SelfEsteem -0.279 0.025 -11.284 0.000 -0.328 -0.231 ## 6 Restrictive ~ DietSE -0.162 0.026 -6.115 0.000 -0.213 -0.110 ## 7 Restrictive ~ BMI -0.158 0.027 -5.962 0.000 -0.210 -0.106 ## 8 Restrictive ~ SelfEsteem -0.122 0.027 -4.593 0.000 -0.175 -0.070 ## 9 Risk ~ DietSE 0.098 0.027 3.702 0.000 0.046 0.150 ## 10 Risk ~ BMI 0.053 0.027 2.003 0.045 0.001 0.106 ## 11 Risk ~ SelfEsteem -0.223 0.026 -8.536 0.000 -0.274 -0.172 ## 12 Risk ~ Accu -0.091 0.026 -3.462 0.001 -0.143 -0.039 ## 13 DietSE ~~ Bulimia 0.000 0.000 NA NA 0.000 0.000 ## 14 DietSE ~~ Restrictive 0.000 0.000 NA NA 0.000 0.000 ## 15 DietSE ~~ Risk 0.000 0.000 NA NA 0.000 0.000 ## 16 Bulimia ~~ Restrictive 0.000 0.000 NA NA 0.000 0.000 ## 17 Bulimia ~~ Risk 0.000 0.000 NA NA 0.000 0.000 ## 18 Restrictive ~~ Risk 0.000 0.000 NA NA 0.000 0.000 ## 19 DietSE ~~ DietSE 0.980 0.008 129.769 0.000 0.965 0.995 ## 20 Bulimia ~~ Bulimia 0.859 0.018 48.727 0.000 0.824 0.894 ## 21 Restrictive ~~ Restrictive 0.940 0.013 74.768 0.000 0.915 0.965 ## 22 Risk ~~ Risk 0.931 0.013 69.534 0.000 0.904 0.957 ## 23 BMI ~~ BMI 1.000 0.000 NA NA 1.000 1.000 ## 24 BMI ~~ SelfEsteem -0.133 0.027 -4.958 0.000 -0.186 -0.080 ## 25 BMI ~~ Accu -0.020 0.027 -0.744 0.457 -0.074 0.033 ## 26 SelfEsteem ~~ SelfEsteem 1.000 0.000 NA NA 1.000 1.000 ## 27 SelfEsteem ~~ Accu 0.035 0.027 1.300 0.194 -0.018 0.089 ## 28 Accu ~~ Accu 1.000 0.000 NA NA 1.000 1.000 How does it work? ?standardizedSolution 3.6 Plotting SEM model # install.packages(&quot;semPlot&quot;) library(semPlot) # Plot! semPaths(ex1fit_noCov_freeX) # estimates instead of paths only semPaths(ex1fit_noCov_freeX, what=&#39;est&#39;, edge.label.cex=1.25, curvePivot = TRUE, fade=FALSE) # standardized solutions semPaths(ex1fit_noCov_freeX, what=&#39;std&#39;, edge.label.cex=1.25, curvePivot = TRUE, fade=FALSE) semPaths(ex1fit_noCov_freeX, what=&#39;est&#39;, rotation = 2, # default rotation = 1 with four options edge.label.cex=1.25, curvePivot = TRUE, fade=FALSE) 3.6.1 customize it your way semPaths(ex1fit_noCov_freeX, whatLabels=&quot;est&quot;, # plot model not parm ests rotation = 2, # default rotation = 1 with four options asize = 5, # arrows&#39; size esize = 2, # width of paths&#39; lines / curves edge.label.cex = 0.8, # font size of regr&#39;n coeffs sizeMan = 10, # font size of manifest variable names nCharNodes = 0, nCharEdges = 0, # don&#39;t limit variable name lengths fade = FALSE, # don&#39;t weight path width to reflect strength curvePivot = TRUE, # make straight edges instead of round ones curve = 2, # pull covariances&#39; curves out a little style = &quot;lisrel&quot;, # no variances vs. # &quot;ram&quot;&#39;s 2-headed for variances color = &quot;green&quot;, # color of variables edge.color = &quot;black&quot;, # color of edges/paths layout = &quot;tree2&quot;, # tree, spring, circle, circle2 residuals = TRUE) # residuals variances included in the path diagram semPaths(ex1fit_noCov_freeX, what=&#39;est&#39;, rotation = 2, # default rotation = 1 with four options curve = 2, # pull covariances&#39; curves out a little nCharNodes = 0, nCharEdges = 0, # don&#39;t limit variable name lengths sizeMan = 8, # font size of manifest variable names style = &quot;lisrel&quot;, # single-headed arrows vs. # &quot;ram&quot;&#39;s 2-headed for variances edge.label.cex=1.2, curvePivot = TRUE, fade=FALSE) 3.7 Exercise: How would you fit the model in Saunders et al. (2016)? "],["week4_2-lavaan-lab-2-mediation-and-indirect-effects.html", "Chapter 4 Week4_2: Lavaan Lab 2 Mediation and Indirect Effects 4.1 Reading-In and Working With Realistic Datasets In R 4.2 Using Lavaan For Mediation Models - Preacher &amp; Hayes’s 4.3 PART I: # Follow the two equations of M (DietSE) &amp; Y (Bulimia) 4.4 PART II Let’s run our model! 4.5 PART III: Summarizing Our Analysis: 4.6 PART IV: Bootstrap confidence intervals 4.7 In-Class Exercise: Use Lavaan to estimate and interpret the following model 4.8 Exercise: Eating Disorder Mediation Analysis", " Chapter 4 Week4_2: Lavaan Lab 2 Mediation and Indirect Effects In this lab, we will learn how to: perform a simple mediation analysis using Preacher &amp; Hayes (2004) + Bootstrap test mediation effects in the eating disorder path model 4.1 Reading-In and Working With Realistic Datasets In R If your data (eatingDisorderSimData.csv) is stored in you current working directory, then simply load your data by typing the name of the .csv file: labData &lt;- read.csv(file = &quot;eatingDisorderSimData.csv&quot;, header = T, sep = &quot;,&quot;) 4.2 Using Lavaan For Mediation Models - Preacher &amp; Hayes’s Load the package: library(lavaan) Part I: Writing the Model Syntax Part II: Analyzing the Model Using Your Dataset Part III: Examining the results. 4.3 PART I: # Follow the two equations of M (DietSE) &amp; Y (Bulimia) Diet Self-Efficacy = BMI + Disturbance Bulimic Symptoms = BMI + Diet Self-Efficacy + Disturbance Let’s write some model syntax: ex1MediationSyntax &lt;- &quot; #opening a quote #Regressions DietSE ~ BMI #M ~ X regression (a path) Bulimia ~ BMI + DietSE #Y ~ X + M regression (c prime and b) &quot; No need to fix disturbance covariances in simple mediation as none was estimated 4.4 PART II Let’s run our model! let fixed.x=FALSE to print more lines ex1fit_freeX &lt;- lavaan::sem(model = ex1MediationSyntax, data = labData, fixed.x = FALSE) summary(ex1fit_freeX) ## lavaan 0.6-10 ended normally after 1 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## ## Number of observations 1339 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## DietSE ~ ## BMI -0.100 0.026 -3.861 0.000 ## Bulimia ~ ## BMI 0.129 0.026 4.960 0.000 ## DietSE -0.213 0.028 -7.725 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .DietSE 0.955 0.037 25.875 0.000 ## .Bulimia 0.968 0.037 25.875 0.000 ## BMI 1.073 0.041 25.875 0.000 note that there are six parameter estimates and df = 0. But the output does not include the mediation effect a*b? 4.4.1 Label the mediation effect Let’s learn how to label parameters great tutorial example: http://lavaan.ugent.be/tutorial/mediation.html To label a parameter, include the coefficient label and an asterisk * before the variable to be labelled. E.g., y ~ b1x + b2m This would give x the label b1 and m the label b2 in the y regression. ex2MediationSyntax &lt;- &quot; #opening a quote #Regressions DietSE ~ a*BMI #Label the a coefficient in the M regression. Bulimia ~ cPrime*BMI + b*DietSE #Label the direct effect (cPrime) of X and direct effect of M (b) in the Y regression. &quot; What does this do? ex2fit &lt;- lavaan::sem(model = ex2MediationSyntax, data = labData, fixed.x=FALSE) summary(ex2fit) ## lavaan 0.6-10 ended normally after 1 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## ## Number of observations 1339 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## DietSE ~ ## BMI (a) -0.100 0.026 -3.861 0.000 ## Bulimia ~ ## BMI (cPrm) 0.129 0.026 4.960 0.000 ## DietSE (b) -0.213 0.028 -7.725 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .DietSE 0.955 0.037 25.875 0.000 ## .Bulimia 0.968 0.037 25.875 0.000 ## BMI 1.073 0.041 25.875 0.000 The regression coefficients have labels now! 4.4.2 Define a new term for the mediation effect a*b …using the labels we just created in ex2MediationSyntax The := operator in lavaan defines new terms to be tested: (name of a new term) := operator ex3MediationSyntax &lt;- &quot; #opening a quote #Regressions DietSE ~ a*BMI #Label the a coefficient in the M regression. Bulimia ~ cPrime*BMI + b*DietSE #Label the direct effect (cPrime) of X and direct effect of M (b) in the Y regression. #Define New Parameters ab := a*b #the product term is computed as a*b c := cPrime + ab #having defined ab, we can use this here. &quot; ex3fit &lt;- lavaan::sem(model = ex3MediationSyntax, data = labData, fixed.x=FALSE) summary(ex3fit) ## lavaan 0.6-10 ended normally after 1 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## ## Number of observations 1339 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## DietSE ~ ## BMI (a) -0.100 0.026 -3.861 0.000 ## Bulimia ~ ## BMI (cPrm) 0.129 0.026 4.960 0.000 ## DietSE (b) -0.213 0.028 -7.725 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .DietSE 0.955 0.037 25.875 0.000 ## .Bulimia 0.968 0.037 25.875 0.000 ## BMI 1.073 0.041 25.875 0.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ## ab 0.021 0.006 3.454 0.001 ## c 0.151 0.027 5.678 0.000 Now there are two significance tests of the indirect effect ab and the total effect c! Question: why didn’t the #parameters change? Note: defining a new term is NOT equivalent to adding a new parameter! You can create as many terms as your want without changing the #parameters and the df 4.5 PART III: Summarizing Our Analysis: We can request standardized coefficients very easily by adding a statement to the summary command. summary(ex3fit, standardized = TRUE) #This includes standardized estimates. std.all contains usual regression standardization. ## lavaan 0.6-10 ended normally after 1 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## ## Number of observations 1339 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## DietSE ~ ## BMI (a) -0.100 0.026 -3.861 0.000 -0.100 -0.105 ## Bulimia ~ ## BMI (cPrm) 0.129 0.026 4.960 0.000 0.129 0.132 ## DietSE (b) -0.213 0.028 -7.725 0.000 -0.213 -0.205 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .DietSE 0.955 0.037 25.875 0.000 0.955 0.989 ## .Bulimia 0.968 0.037 25.875 0.000 0.968 0.935 ## BMI 1.073 0.041 25.875 0.000 1.073 1.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## ab 0.021 0.006 3.454 0.001 0.021 0.022 ## c 0.151 0.027 5.678 0.000 0.151 0.153 summary(ex3fit, ci = T) #Include confidence intervals ## lavaan 0.6-10 ended normally after 1 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## ## Number of observations 1339 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## DietSE ~ ## BMI (a) -0.100 0.026 -3.861 0.000 -0.150 -0.049 ## Bulimia ~ ## BMI (cPrm) 0.129 0.026 4.960 0.000 0.078 0.181 ## DietSE (b) -0.213 0.028 -7.725 0.000 -0.267 -0.159 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## .DietSE 0.955 0.037 25.875 0.000 0.882 1.027 ## .Bulimia 0.968 0.037 25.875 0.000 0.895 1.041 ## BMI 1.073 0.041 25.875 0.000 0.992 1.154 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## ab 0.021 0.006 3.454 0.001 0.009 0.033 ## c 0.151 0.027 5.678 0.000 0.099 0.203 or both! summary(ex3fit, standardized = TRUE, ci = T) ## lavaan 0.6-10 ended normally after 1 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## ## Number of observations 1339 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper Std.lv Std.all ## DietSE ~ ## BMI (a) -0.100 0.026 -3.861 0.000 -0.150 -0.049 -0.100 -0.105 ## Bulimia ~ ## BMI (cPrm) 0.129 0.026 4.960 0.000 0.078 0.181 0.129 0.132 ## DietSE (b) -0.213 0.028 -7.725 0.000 -0.267 -0.159 -0.213 -0.205 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper Std.lv Std.all ## .DietSE 0.955 0.037 25.875 0.000 0.882 1.027 0.955 0.989 ## .Bulimia 0.968 0.037 25.875 0.000 0.895 1.041 0.968 0.935 ## BMI 1.073 0.041 25.875 0.000 0.992 1.154 1.073 1.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper Std.lv Std.all ## ab 0.021 0.006 3.454 0.001 0.009 0.033 0.021 0.022 ## c 0.151 0.027 5.678 0.000 0.099 0.203 0.151 0.153 Important: the default significance tests of defined parameters in lavaan is Sobel’s test. 4.6 PART IV: Bootstrap confidence intervals 4.6.1 The default one is boot.ci.type = “perc” You can request bootstrap standard errors in sem() using se = “bootstrap” and bootstrap = 1000 set.seed(2022) ex3Boot &lt;- lavaan::sem(model = ex3MediationSyntax, data = labData, se = &quot;bootstrap&quot;, bootstrap = 1000, fixed.x=FALSE) This requires the full dataset - need more than the covariance matrix. se = “bootstrap” requests bootstrap standard errors. bootstrap = 1000 requests 1000 bootstrap samples. Request bootstrap CI: summary(ex3Boot, ci = TRUE) ## lavaan 0.6-10 ended normally after 1 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## ## Number of observations 1339 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Bootstrap ## Number of requested bootstrap draws 1000 ## Number of successful bootstrap draws 1000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## DietSE ~ ## BMI (a) -0.100 0.026 -3.779 0.000 -0.152 -0.048 ## Bulimia ~ ## BMI (cPrm) 0.129 0.025 5.099 0.000 0.080 0.177 ## DietSE (b) -0.213 0.027 -7.820 0.000 -0.269 -0.159 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## .DietSE 0.955 0.035 26.909 0.000 0.884 1.031 ## .Bulimia 0.968 0.038 25.378 0.000 0.890 1.041 ## BMI 1.073 0.044 24.482 0.000 0.991 1.165 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## ab 0.021 0.006 3.319 0.001 0.010 0.035 ## c 0.151 0.026 5.814 0.000 0.099 0.200 Now we have bootstrap standard error and percentile confidence interval for ab! 4.6.2 BC (bias-corrected) confidence interval What about other types of bootstrap confidence intervals? You can request a BC (bias-corrected) by adding an argument boot.ci.type = “bca.simple” to parameterEstimates(): parameterEstimates(ex3Boot, level = 0.95, boot.ci.type=&quot;bca.simple&quot;) ## lhs op rhs label est se z pvalue ci.lower ci.upper ## 1 DietSE ~ BMI a -0.100 0.026 -3.779 0.000 -0.154 -0.048 ## 2 Bulimia ~ BMI cPrime 0.129 0.025 5.099 0.000 0.076 0.176 ## 3 Bulimia ~ DietSE b -0.213 0.027 -7.820 0.000 -0.264 -0.157 ## 4 DietSE ~~ DietSE 0.955 0.035 26.909 0.000 0.888 1.035 ## 5 Bulimia ~~ Bulimia 0.968 0.038 25.378 0.000 0.898 1.045 ## 6 BMI ~~ BMI 1.073 0.044 24.482 0.000 0.990 1.165 ## 7 ab := a*b ab 0.021 0.006 3.319 0.001 0.011 0.036 ## 8 c := cPrime+ab c 0.151 0.026 5.814 0.000 0.097 0.198 which returns a 95% BC confidence interval. This approach will yield similar results to the PROCESS Macro in SPSS with bias-corrected standard errors. 4.7 In-Class Exercise: Use Lavaan to estimate and interpret the following model ex4MediationSyntax &lt;- &quot; #Regressions DietSE ~ a*SelfEsteem Risk ~ cPrime*SelfEsteem + b*DietSE #Define New Parameters ab := a*b #the product term is computed as a*b c := cPrime + ab #having defined ab, we can use this here. &quot; ex4fit &lt;- lavaan::sem(model = ex4MediationSyntax, data = labData, fixed.x=FALSE) summary(ex4fit, ci = T) ## lavaan 0.6-10 ended normally after 1 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## ## Number of observations 1339 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## DietSE ~ ## SlfEstm (a) 0.105 0.027 3.949 0.000 0.053 0.158 ## Risk ~ ## SlfEstm (cPrm) -0.239 0.027 -8.728 0.000 -0.292 -0.185 ## DietSE (b) 0.100 0.028 3.583 0.000 0.045 0.154 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## .DietSE 0.954 0.037 25.875 0.000 0.882 1.027 ## .Risk 0.991 0.038 25.875 0.000 0.916 1.066 ## SelfEsteem 1.001 0.039 25.875 0.000 0.926 1.077 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ci.lower ci.upper ## ab 0.011 0.004 2.653 0.008 0.003 0.018 ## c -0.228 0.027 -8.352 0.000 -0.282 -0.175 Bootstrap confidence intervals: set.seed(2022) ex4Boot &lt;- lavaan::sem(model = ex4MediationSyntax, data = labData, se = &quot;bootstrap&quot;, bootstrap = 1000, fixed.x=FALSE) parameterEstimates(ex4Boot, level = 0.95, boot.ci.type=&quot;bca.simple&quot;) ## lhs op rhs label est se z pvalue ci.lower ci.upper ## 1 DietSE ~ SelfEsteem a 0.105 0.024 4.364 0.000 0.055 0.151 ## 2 Risk ~ SelfEsteem cPrime -0.239 0.026 -9.162 0.000 -0.291 -0.189 ## 3 Risk ~ DietSE b 0.100 0.028 3.609 0.000 0.049 0.156 ## 4 DietSE ~~ DietSE 0.954 0.035 26.887 0.000 0.888 1.032 ## 5 Risk ~~ Risk 0.991 0.038 25.844 0.000 0.919 1.072 ## 6 SelfEsteem ~~ SelfEsteem 1.001 0.040 25.164 0.000 0.928 1.083 ## 7 ab := a*b ab 0.011 0.004 2.752 0.006 0.004 0.020 ## 8 c := cPrime+ab c -0.228 0.026 -8.693 0.000 -0.281 -0.176 4.8 Exercise: Eating Disorder Mediation Analysis Give it a try before peaking the answers! Hints: Label the regression coefficients: b1 - b12; Fix all disturbance covariances at 0; Define mediation effects and total effects for each of the six mediation models using the labels; Request bootstrap standard errors using se = “bootstrap”; Print and interpret the mediation effects; (Optional) Identify and interpret the inconsistent mediation effects. I’ll get you started: 4.8.1 Step 1: Labeling and defining the parameters 4.8.2 Step 2: Fix all disturbance covariances at 0 ex5PathSyntax_noCov &lt;- &quot; #opening a quote DietSE ~ b1*BMI + b5*SelfEsteem #DietSE is predicted by BMI and SelfEsteem Bulimia ~ b10*DietSE + b2*BMI + b6*SelfEsteem Restrictive ~ b11*DietSE + b3*BMI + b7*SelfEsteem Risk ~ b12*DietSE + b4*BMI + b8*SelfEsteem + b9*Accu #Disturbance covariances (fixed at 0): DietSE ~~ 0*Bulimia # ~~ indicates a two-headed arrow (variance or covariance) DietSE ~~ 0*Restrictive # 0* in front of the 2nd variable fixes the covariance at 0 DietSE ~~ 0*Risk # These lines say that all endogenous variables have no correlated disturbance variances Bulimia ~~ 0*Restrictive Bulimia ~~ 0*Risk Restrictive ~~ 0*Risk &quot; 4.8.3 Step 3: Define new terms for mediation effects Recall: Define New Parameters ab := ab #the product term is computed as ab ex5MediationSyntax &lt;- &quot; DietSE ~ b1*BMI + b5*SelfEsteem #DietSE is predicted by BMI and SelfEsteem Bulimia ~ b10*DietSE + b2*BMI + b6*SelfEsteem Restrictive ~ b11*DietSE + b3*BMI + b7*SelfEsteem Risk ~ b12*DietSE + b4*BMI + b8*SelfEsteem + b9*Accu #Disturbance covariances (fixed at 0): DietSE ~~ 0*Bulimia # ~~ indicates a two-headed arrow (variance or covariance) DietSE ~~ 0*Restrictive # 0* in front of the 2nd variable fixes the covariance at 0 DietSE ~~ 0*Risk # These lines say that all endogenous variables have no correlated disturbance variances Bulimia ~~ 0*Restrictive Bulimia ~~ 0*Risk Restrictive ~~ 0*Risk #Define New Parameters med1 := b1*b10 total1 := b2 + med1 med2 := b1*b11 total2 := b3 + med2 med3 := b1*b12 total3 := b4 + med3 med4 := b5*b10 total4 := b6 + med4 med5 := b5*b11 total5 := b7 + med5 med6 := b5*b12 total6 := b8 + med6 &quot; ex5fit &lt;- lavaan::sem(model = ex5MediationSyntax, data = labData, fixed.x=FALSE) summary(ex5fit, ci = T) 4.8.4 Step 4: Bootstrap confidence intervals: 4.8.5 Step 5: Print and interpret the mediation effects; set.seed(2022) ex5Boot &lt;- lavaan::sem(model = ex5MediationSyntax, data = labData, se = &quot;bootstrap&quot;, bootstrap = 1000, fixed.x=FALSE) parameterEstimates(ex5Boot, level = 0.95, boot.ci.type=&quot;bca.simple&quot;) ## lhs op rhs label est se z pvalue ci.lower ci.upper ## 1 DietSE ~ BMI b1 -0.088 0.026 -3.336 0.001 -0.141 -0.036 ## 2 DietSE ~ SelfEsteem b5 0.093 0.024 3.862 0.000 0.044 0.139 ## 3 Bulimia ~ DietSE b10 -0.185 0.026 -7.001 0.000 -0.237 -0.128 ## 4 Bulimia ~ BMI b2 0.096 0.025 3.844 0.000 0.047 0.142 ## 5 Bulimia ~ SelfEsteem b6 -0.284 0.025 -11.284 0.000 -0.338 -0.237 ## 6 Restrictive ~ DietSE b11 -0.166 0.027 -6.192 0.000 -0.217 -0.109 ## 7 Restrictive ~ BMI b3 -0.154 0.025 -6.173 0.000 -0.203 -0.107 ## 8 Restrictive ~ SelfEsteem b7 -0.123 0.026 -4.668 0.000 -0.174 -0.071 ## 9 Risk ~ DietSE b12 0.102 0.027 3.737 0.000 0.050 0.157 ## 10 Risk ~ BMI b4 0.053 0.026 2.037 0.042 0.003 0.104 ## 11 Risk ~ SelfEsteem b8 -0.228 0.026 -8.654 0.000 -0.281 -0.178 ## 12 Risk ~ Accu b9 -0.095 0.028 -3.399 0.001 -0.151 -0.041 ## 13 DietSE ~~ Bulimia 0.000 0.000 NA NA 0.000 0.000 ## 14 DietSE ~~ Restrictive 0.000 0.000 NA NA 0.000 0.000 ## 15 DietSE ~~ Risk 0.000 0.000 NA NA 0.000 0.000 ## 16 Bulimia ~~ Restrictive 0.000 0.000 NA NA 0.000 0.000 ## 17 Bulimia ~~ Risk 0.000 0.000 NA NA 0.000 0.000 ## 18 Restrictive ~~ Risk 0.000 0.000 NA NA 0.000 0.000 ## 19 DietSE ~~ DietSE 0.946 0.035 27.052 0.000 0.880 1.024 ## 20 Bulimia ~~ Bulimia 0.890 0.036 24.842 0.000 0.826 0.963 ## 21 Restrictive ~~ Restrictive 0.955 0.036 26.606 0.000 0.892 1.033 ## 22 Risk ~~ Risk 0.979 0.038 25.718 0.000 0.912 1.062 ## 23 BMI ~~ BMI 1.073 0.044 24.482 0.000 0.990 1.165 ## 24 BMI ~~ SelfEsteem -0.138 0.029 -4.802 0.000 -0.197 -0.083 ## 25 BMI ~~ Accu -0.021 0.027 -0.755 0.450 -0.079 0.030 ## 26 SelfEsteem ~~ SelfEsteem 1.001 0.040 25.164 0.000 0.928 1.083 ## 27 SelfEsteem ~~ Accu 0.035 0.027 1.304 0.192 -0.016 0.090 ## 28 Accu ~~ Accu 0.971 0.037 26.425 0.000 0.905 1.052 ## 29 med1 := b1*b10 med1 0.016 0.006 2.925 0.003 0.007 0.029 ## 30 total1 := b2+med1 total1 0.112 0.025 4.439 0.000 0.060 0.159 ## 31 med2 := b1*b11 med2 0.015 0.005 2.825 0.005 0.006 0.026 ## 32 total2 := b3+med2 total2 -0.139 0.025 -5.495 0.000 -0.192 -0.091 ## 33 med3 := b1*b12 med3 -0.009 0.004 -2.536 0.011 -0.018 -0.003 ## 34 total3 := b4+med3 total3 0.044 0.026 1.681 0.093 -0.005 0.096 ## 35 med4 := b5*b10 med4 -0.017 0.005 -3.399 0.001 -0.029 -0.009 ## 36 total4 := b6+med4 total4 -0.301 0.026 -11.652 0.000 -0.356 -0.253 ## 37 med5 := b5*b11 med5 -0.015 0.005 -3.238 0.001 -0.026 -0.007 ## 38 total5 := b7+med5 total5 -0.139 0.027 -5.154 0.000 -0.191 -0.085 ## 39 med6 := b5*b12 med6 0.010 0.004 2.641 0.008 0.004 0.018 ## 40 total6 := b8+med6 total6 -0.219 0.027 -8.227 0.000 -0.273 -0.168 4.8.6 Plot it! library(semPlot) semPaths(ex5Boot, what=&#39;est&#39;, rotation = 2, # default rotation = 1 with four options curve = 2, # pull covariances&#39; curves out a little nCharNodes = 0, nCharEdges = 0, # don&#39;t limit variable name lengths sizeMan = 8, # font size of manifest variable names style = &quot;lisrel&quot;, # single-headed arrows vs. # &quot;ram&quot;&#39;s 2-headed for variances edge.label.cex=1.2, curvePivot = TRUE, fade=FALSE) "],["week5_1-lavaan-lab-3-moderation-and-conditional-effects.html", "Chapter 5 Week5_1: Lavaan Lab 3 Moderation and Conditional Effects 5.1 Reading-In Datasets 5.2 Interactions in Regression Using lm() 5.3 Interactions in Lavaan 5.4 Visial inspection of interactions 5.5 Centering Continuous Moderator 5.6 Interactions in Lavaan (Continuous Moderator) 5.7 Simple Slopes Analysis 5.8 Visual inspection of interactions (lm approach) 5.9 JOHNSON-NEYMAN INTERVAL 5.10 Exercise: How Framing Affects Justifications for Giving or Withholding Aid to Disaster Victims", " Chapter 5 Week5_1: Lavaan Lab 3 Moderation and Conditional Effects In this lab, we will learn how to: how to perform moderation using regression and sem test the moderation effects of binary and continuous moderators visualize moderation effects. 5.1 Reading-In Datasets Let’s read this dataset in. Change the file path to whatever directory where you saved the file! cbtData &lt;- read.csv(file = &quot;dataInClass.csv&quot;, header = T) Let’s examine this dataset: head(cbtData) ## ID CBT CBTDummy NeedCog NegThoughts Depression NeedCogCont ## 1 1 CBT Treatment 1 0 -4.1453029 -5.802172 0.0182802 ## 2 2 Information Only 0 1 2.1775218 5.496665 1.4238703 ## 3 3 CBT Treatment 1 0 -1.5551349 -1.950566 -1.0151726 ## 4 4 Information Only 0 0 0.1679286 2.655801 -0.8547152 ## 5 5 Information Only 0 1 2.5103192 6.855488 0.6759705 ## 6 6 CBT Treatment 1 0 -3.1626670 -2.968198 -0.9123426 str(cbtData) ## &#39;data.frame&#39;: 1000 obs. of 7 variables: ## $ ID : int 1 2 3 4 5 6 7 8 9 10 ... ## $ CBT : chr &quot;CBT Treatment&quot; &quot;Information Only&quot; &quot;CBT Treatment&quot; &quot;Information Only&quot; ... ## $ CBTDummy : int 1 0 1 0 0 1 1 1 1 0 ... ## $ NeedCog : int 0 1 0 0 1 0 0 0 0 0 ... ## $ NegThoughts: num -4.145 2.178 -1.555 0.168 2.51 ... ## $ Depression : num -5.8 5.5 -1.95 2.66 6.86 ... ## $ NeedCogCont: num 0.0183 1.4239 -1.0152 -0.8547 0.676 ... colSums(is.na(cbtData)) ## ID CBT CBTDummy NeedCog NegThoughts Depression NeedCogCont ## 0 0 0 0 0 0 0 Notice that the first two columns are not model variables col 1 is a case ID variable. col 2 is a factor variable indicating CBT vs. Info-Only treatment. Besides, col 5 is a variable that measures negative thoughts. col 7 is a continuous measure of NeedCog. In the first part of this demo, we will work with three variables: CBTDummy, NeedCog, and Depression Let’s look at the covariance matrix of the three variables Multiple ways to accomplish this: cov(cbtData[,-c(1,2,5,7)]) ## CBTDummy NeedCog Depression ## CBTDummy 0.250250250 -0.008508509 -2.3372519 ## NeedCog -0.008508509 0.213732733 0.4371738 ## Depression -2.337251860 0.437173798 31.9301427 cov(cbtData[,c(3,4,6)]) ## CBTDummy NeedCog Depression ## CBTDummy 0.250250250 -0.008508509 -2.3372519 ## NeedCog -0.008508509 0.213732733 0.4371738 ## Depression -2.337251860 0.437173798 31.9301427 cov(cbtData[,c(&quot;CBTDummy&quot;, &quot;NeedCog&quot;, &quot;Depression&quot;)]) ## CBTDummy NeedCog Depression ## CBTDummy 0.250250250 -0.008508509 -2.3372519 ## NeedCog -0.008508509 0.213732733 0.4371738 ## Depression -2.337251860 0.437173798 31.9301427 let’s round this to two decimals round(cov(cbtData[,c(&quot;CBTDummy&quot;, &quot;NeedCog&quot;, &quot;Depression&quot;)]), digits = 2) ## CBTDummy NeedCog Depression ## CBTDummy 0.25 -0.01 -2.34 ## NeedCog -0.01 0.21 0.44 ## Depression -2.34 0.44 31.93 What about the means? round(apply(cbtData[,c(&quot;CBTDummy&quot;, &quot;NeedCog&quot;, &quot;Depression&quot;)], 2, mean), 2) ## CBTDummy NeedCog Depression ## 0.50 0.31 -1.59 Although they are not centered, we will proceed because CBTDummy and NeedCog are both binary. 5.2 Interactions in Regression Using lm() In regression course we learned the lm() function, which stands for linear model. To include an interaction in regression, simply use an : to create a product in the formula: interactionModel &lt;- lm(formula = Depression ~ CBTDummy + NeedCog + CBTDummy:NeedCog, data = cbtData) NOTE: R is very helpful, in that if you just put an asterisk *, it includes all lower-order terms! interactionModel &lt;- lm(formula = Depression ~ CBTDummy*NeedCog, data = cbtData) Let’s look at this interaction model: summary(interactionModel) ## ## Call: ## lm(formula = Depression ~ CBTDummy * NeedCog, data = cbtData) ## ## Residuals: ## Min 1Q Median 3Q Max ## -12.7785 -1.4280 0.0662 1.6252 6.8283 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.2684 0.1345 9.428 &lt;2e-16 *** ## CBTDummy -6.8119 0.1880 -36.240 &lt;2e-16 *** ## NeedCog 5.5586 0.2356 23.590 &lt;2e-16 *** ## CBTDummy:NeedCog -8.0093 0.3384 -23.666 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.47 on 996 degrees of freedom ## Multiple R-squared: 0.8095, Adjusted R-squared: 0.809 ## F-statistic: 1411 on 3 and 996 DF, p-value: &lt; 2.2e-16 Let’s interpret this … (In class) 5.3 Interactions in Lavaan Now let us write the same model using lavaan. Load the package: library(lavaan) 5.3.1 IMPORTANT NOTE Because lavaan uses the * for assigning coefficient labels, this cannot be used to create interaction terms. Instead, we have to create the product term in the dataset first, before running our model. This is easy to do. General Format: existingDataFrame$variableName &lt;- vectorToBeAssignedAsNewVariable cbtData$CBTxNeedCog &lt;- cbtData$CBTDummy * cbtData$NeedCog You can name the product term arbitrarily: cbtData$fourth &lt;- cbtData$CBTDummy * cbtData$NeedCog Let’s look at cbtData again: head(cbtData) ## ID CBT CBTDummy NeedCog NegThoughts Depression NeedCogCont CBTxNeedCog ## 1 1 CBT Treatment 1 0 -4.1453029 -5.802172 0.0182802 0 ## 2 2 Information Only 0 1 2.1775218 5.496665 1.4238703 0 ## 3 3 CBT Treatment 1 0 -1.5551349 -1.950566 -1.0151726 0 ## 4 4 Information Only 0 0 0.1679286 2.655801 -0.8547152 0 ## 5 5 Information Only 0 1 2.5103192 6.855488 0.6759705 0 ## 6 6 CBT Treatment 1 0 -3.1626670 -2.968198 -0.9123426 0 Now you have a new variable called CBTxNeedCog at the end. 5.3.2 Follow the equation of Y (Depression): Depression = CBTDummy + NeedCog + CBTDummy*NeedCog + Disturbance Let’s write some model syntax (with the labels): interactionSyntax &lt;- &quot; #Regression with interaction #with labels Depression ~ b1*CBTDummy + b2*NeedCog + b3*CBTxNeedCog &quot; let fixed.x=FALSE to print more lines: inter_fit1 &lt;- sem(model = interactionSyntax, data = cbtData, fixed.x = FALSE) If you’d like lavaan to print means and intercepts, we need to ask sem() to include the meanstructure: inter_fit1 &lt;- sem(model = interactionSyntax, data = cbtData, fixed.x =FALSE, meanstructure = TRUE) summary(inter_fit1) ## lavaan 0.6-10 ended normally after 41 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## ## Number of observations 1000 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## Depression ~ ## CBTDummy (b1) -6.812 0.188 -36.312 0.000 ## NeedCog (b2) 5.559 0.235 23.637 0.000 ## CBTxNedCg (b3) -8.009 0.338 -23.713 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## CBTDummy ~~ ## NeedCog -0.008 0.007 -1.163 0.245 ## CBTxNeedCog 0.073 0.006 12.083 0.000 ## NeedCog ~~ ## CBTxNeedCog 0.101 0.006 16.630 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .Depression 1.268 0.134 9.446 0.000 ## CBTDummy 0.500 0.016 31.623 0.000 ## NeedCog 0.309 0.015 21.147 0.000 ## CBTxNeedCog 0.146 0.011 13.075 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .Depression 6.076 0.272 22.361 0.000 ## CBTDummy 0.250 0.011 22.361 0.000 ## NeedCog 0.214 0.010 22.361 0.000 ## CBTxNeedCog 0.125 0.006 22.361 0.000 How does this compare to our regression model? summary(interactionModel) ## ## Call: ## lm(formula = Depression ~ CBTDummy * NeedCog, data = cbtData) ## ## Residuals: ## Min 1Q Median 3Q Max ## -12.7785 -1.4280 0.0662 1.6252 6.8283 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.2684 0.1345 9.428 &lt;2e-16 *** ## CBTDummy -6.8119 0.1880 -36.240 &lt;2e-16 *** ## NeedCog 5.5586 0.2356 23.590 &lt;2e-16 *** ## CBTDummy:NeedCog -8.0093 0.3384 -23.666 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.47 on 996 degrees of freedom ## Multiple R-squared: 0.8095, Adjusted R-squared: 0.809 ## F-statistic: 1411 on 3 and 996 DF, p-value: &lt; 2.2e-16 Same…but sem is more verbose. 5.4 Visial inspection of interactions One way to plot the interactions is to use the interact_plot() function on the lm() object. Install and load the package interactions first: library(interactions) interact_plot(interactionModel, pred = &quot;CBTDummy&quot;, modx = &quot;NeedCog&quot;) 5.5 Centering Continuous Moderator Now let’s work with the continuous measure of NeedCog directly: mean(cbtData$NeedCogCont) ## [1] 0.005925852 sd(cbtData$NeedCogCont) ## [1] 0.9974319 NeedCogCont has been standardized already, which is helpful. If not, we use scale() function to center a continuous variable Usage: scale(x, center = TRUE, scale = TRUE) If you just need to center a variable, you disable scale=FALSE centeredNeedCog &lt;- scale(cbtData$NeedCogCont, center = TRUE, scale = TRUE) hist(centeredNeedCog) For now, we will leave these variables as is in our dataset. But the scale() function is good to know. 5.6 Interactions in Lavaan (Continuous Moderator) Just like for binary NeedCog moderator, we have to manually create a product term in the dataset first before running our model. This is easy to do: cbtData$CBTxNeedCogCont &lt;- cbtData$CBTDummy * cbtData$NeedCogCont Let’s look at cbtData again: head(cbtData) ## ID CBT CBTDummy NeedCog NegThoughts Depression NeedCogCont CBTxNeedCog CBTxNeedCogCont ## 1 1 CBT Treatment 1 0 -4.1453029 -5.802172 0.0182802 0 0.0182802 ## 2 2 Information Only 0 1 2.1775218 5.496665 1.4238703 0 0.0000000 ## 3 3 CBT Treatment 1 0 -1.5551349 -1.950566 -1.0151726 0 -1.0151726 ## 4 4 Information Only 0 0 0.1679286 2.655801 -0.8547152 0 0.0000000 ## 5 5 Information Only 0 1 2.5103192 6.855488 0.6759705 0 0.0000000 ## 6 6 CBT Treatment 1 0 -3.1626670 -2.968198 -0.9123426 0 -0.9123426 Time to write some lavaan model syntax (with labels): interactionSyntax2 &lt;- &quot; #Regression Depression ~ b1*CBTDummy + b2*NeedCogCont + b3*CBTxNeedCogCont &quot; Let’s ask sem() to include the meanstructure: inter_fit2 &lt;- sem(model = interactionSyntax2, data = cbtData, fixed.x =FALSE, meanstructure = TRUE) summary(inter_fit2) ## lavaan 0.6-10 ended normally after 35 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## ## Number of observations 1000 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## Depression ~ ## CBTDummy (b1) -9.245 0.113 -82.096 0.000 ## NeedCgCnt (b2) 3.305 0.079 42.064 0.000 ## CBTxNdCgC (b3) -4.967 0.113 -43.943 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## CBTDummy ~~ ## NeedCogCont -0.020 0.016 -1.249 0.212 ## CBTxNeedCogCnt -0.008 0.011 -0.764 0.445 ## NeedCogCont ~~ ## CBTxNeedCogCnt 0.480 0.027 18.055 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .Depression 2.931 0.080 36.794 0.000 ## CBTDummy 0.500 0.016 31.623 0.000 ## NeedCogCont 0.006 0.032 0.188 0.851 ## CBTxNeedCogCnt -0.017 0.022 -0.764 0.445 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .Depression 3.166 0.142 22.361 0.000 ## CBTDummy 0.250 0.011 22.361 0.000 ## NeedCogCont 0.994 0.044 22.361 0.000 ## CBTxNeedCogCnt 0.480 0.021 22.361 0.000 5.7 Simple Slopes Analysis pick-a-point (Rogosa, 1980) and plot the simple slopes of X at designated levels of Z: mean(cbtData$NeedCogCont) #0 ## [1] 0.005925852 sd(cbtData$NeedCogCont) # almost 1 ## [1] 0.9974319 mean(cbtData$NeedCogCont) - sd(cbtData$NeedCogCont) # 1sd below the mean ## [1] -0.991506 mean(cbtData$NeedCogCont) + sd(cbtData$NeedCogCont) # 1sd above the mean ## [1] 1.003358 interactionSyntax3 &lt;- &quot; #Regression Depression ~ b1*CBTDummy + b2*NeedCogCont + b3*CBTxNeedCogCont #regression coefficient labels #Simple Slopes SSHigh := b1+b3*1 #Since sd(NeedCogCont) = approximately 1, this is +1 SD SSMod := b1+b3*0 #at the mean of (centered) NeedCogCont SSLow := b1+b3*(-1) #Low Simple Slope is at -1 (1 SD below since SD = 1) &quot; inter_fit3 &lt;- sem(model = interactionSyntax3, data = cbtData, fixed.x =FALSE, meanstructure = TRUE) summary(inter_fit3) ## lavaan 0.6-10 ended normally after 35 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## ## Number of observations 1000 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## Depression ~ ## CBTDummy (b1) -9.245 0.113 -82.096 0.000 ## NeedCgCnt (b2) 3.305 0.079 42.064 0.000 ## CBTxNdCgC (b3) -4.967 0.113 -43.943 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## CBTDummy ~~ ## NeedCogCont -0.020 0.016 -1.249 0.212 ## CBTxNeedCogCnt -0.008 0.011 -0.764 0.445 ## NeedCogCont ~~ ## CBTxNeedCogCnt 0.480 0.027 18.055 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .Depression 2.931 0.080 36.794 0.000 ## CBTDummy 0.500 0.016 31.623 0.000 ## NeedCogCont 0.006 0.032 0.188 0.851 ## CBTxNeedCogCnt -0.017 0.022 -0.764 0.445 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .Depression 3.166 0.142 22.361 0.000 ## CBTDummy 0.250 0.011 22.361 0.000 ## NeedCogCont 0.994 0.044 22.361 0.000 ## CBTxNeedCogCnt 0.480 0.021 22.361 0.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ## SSHigh -14.212 0.159 -89.281 0.000 ## SSMod -9.245 0.113 -82.096 0.000 ## SSLow -4.279 0.160 -26.755 0.000 Now we have tests of the simple slopes at low, moderate, and high values of the moderator! Along with significance tests. 5.8 Visual inspection of interactions (lm approach) Interactions in Regression Using lm() To include ab interaction in regression, simply use an * to create a product in the formula. interactionModel2 &lt;- lm(Depression ~ CBTDummy*NeedCogCont, cbtData) summary(interactionModel2) ## ## Call: ## lm(formula = Depression ~ CBTDummy * NeedCogCont, data = cbtData) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7282 -1.1381 0.0649 1.2229 4.4762 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.93065 0.07981 36.72 &lt;2e-16 *** ## CBTDummy -9.24546 0.11284 -81.93 &lt;2e-16 *** ## NeedCogCont 3.30525 0.07873 41.98 &lt;2e-16 *** ## CBTDummy:NeedCogCont -4.96674 0.11325 -43.85 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.783 on 996 degrees of freedom ## Multiple R-squared: 0.9008, Adjusted R-squared: 0.9005 ## F-statistic: 3013 on 3 and 996 DF, p-value: &lt; 2.2e-16 pick-a-point (Rogosa, 1980) and plot the simple slopes of X at designated levels of Z: library(interactions) interact_plot(interactionModel2, pred = &quot;CBTDummy&quot;, modx = &quot;NeedCogCont&quot;) 5.9 JOHNSON-NEYMAN INTERVAL interactions::johnson_neyman(interactionModel2, pred = &quot;CBTDummy&quot;, modx = &quot;NeedCogCont&quot;, alpha = 0.05) ## JOHNSON-NEYMAN INTERVAL ## ## When NeedCogCont is OUTSIDE the interval [-1.96, -1.77], the slope of CBTDummy is p &lt; .05. ## ## Note: The range of observed values of NeedCogCont is [-2.83, 3.31] 5.10 Exercise: How Framing Affects Justifications for Giving or Withholding Aid to Disaster Victims For this exercise, we will use a real dataset in a study by Chapman and Lickel (2016). This study was interested in examining the relation between Climate Change and Disasters: How Framing Affects Justifications for Giving or Withholding Aid to Disaster Victims? Researchers hypothesizes that Framing a natural disaster as the product of climate change impacts attitudes toward disaster victims and humanitarian relief. The predictor is X/Frame: Participants read a story about a humanitarian crisis caused by a drought in Africa. X = 1: Half of the participants were told that the drought was caused by climate change (the climate change condition) X = 0: The other half were not told anything about the specific cause of the drought and thus had no reason to believe it wasn’t the result of natural causes (the natural causes condition). The outcome is Y/Donate: the participants’ willingness to donate to the victims was assessed using a set of questions. Responses were made on a set of 7-point scales, with higher scores reflecting a greater willingness to donate to the victims The moderator is W/Skeptic: The belief whether climate change is a real phenomenon was also measured. The moderation model looks at whether the attribution frame manipulation (X) might have had a different effect on people’s willingness to donate (Y) depending on their climate change skepticism (M) 5.10.1 Data Prep The following example data are from Chapman and Lickel (2016) Also example data in Chapter 12 of Hayes (2017) Simply load the .rda into R: load(&quot;disaster.rda&quot;) head(disaster) ## id frame donate justify skeptic ## 1 1 1 5.6 2.95 1.8 ## 2 2 1 4.2 2.85 5.2 ## 3 3 1 4.2 3.00 3.2 ## 4 4 1 4.6 3.30 1.0 ## 5 5 1 3.0 5.00 7.6 ## 6 6 0 5.0 3.20 4.2 str(disaster) ## &#39;data.frame&#39;: 211 obs. of 5 variables: ## $ id : num 1 2 3 4 5 6 7 8 9 10 ... ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F8.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 6 ## $ frame : num 1 1 1 1 1 0 0 1 0 0 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Experimental condition&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F8.2&quot; ## ..- attr(*, &quot;labels&quot;)= Named num [1:2] 0 1 ## .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;naturally caused disaster&quot; &quot;climate change caused disaster&quot; ## $ donate : num 5.6 4.2 4.2 4.6 3 5 4.8 6 4.2 4.4 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Positive attitudes toward donating&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F8.2&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ justify: num 2.95 2.85 3 3.3 5 3.2 2.9 1.4 3.25 3.55 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Negative justifications&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F8.2&quot; ## ..- attr(*, &quot;display_width&quot;)= int 10 ## $ skeptic: num 1.8 5.2 3.2 1 7.6 4.2 4.2 1.2 1.8 8.8 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Climate change skepticism&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F8.2&quot; If you are able to install package processR, you can also view its help page: install.packages(&quot;processR&quot;) library(processR) data(disaster) # take a look at the dataset: ?disaster You probably have to go to https://www.xquartz.org/ to download and install X11, which is a server required by many R packages, including processR. Now, disaster is a data.frame with 211 obs. of 5 variables: id frame: Experimental condition. 0 = naturally caused disaster, 1 = climate change caused disaster donate: Positive attitudes toward donating justify: Negative justifications skeptic: Climate change skepticism 5.10.2 Moderation with a binary moderator Let me first manually create a binary moderator based on the continuous version of skeptic: disaster$skeptic_b &lt;- ifelse(disaster$skeptic&lt;3, 0, 1) # low and high levels of skeptism of climate change table(disaster$skeptic_b) ## ## 0 1 ## 112 99 Next, can you test the moderation effect of skeptic_b on the path from frame to donate? (you can use either lm or lavaan) Please interpret the coefficients in the model above and visualize the interaction using interact_plot(). "]]
